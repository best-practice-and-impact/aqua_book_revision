::: {.callout-important}
This version of the AQuA book is a preliminary ALPHA draft.  It is still in development, and we are still working to ensure that it meets user needs. 

The draft currently has no official status. It is a work in progress and is subject to further revision and reconfiguration (possibly substantial change) before it is finalised. 
:::

# Analysis

## Introduction and summary

The analysis stage is where planned analysis is undertaken and assured, and progress and relevance are monitored. During this stage, the design may be amended to account for changing circumstances, emerging information or unexpected difficulties or limitations encountered. This stage also includes maintaining appropriate and traceable records of the analysis and assurance activities conducted, changes, decisions and assumptions made. In some cases, changes or limitations encountered may necessitate a return to either the design or scoping stage. 




### The Analyst's responsibilities during the analysis stage

As the analyst manages their analysis and follows their analytical plan, they must provide documentation of the data and methods used to the assurers. The analyst shall ensure these are sufficient for the assurer to understand the approach.

The analyst must record any changes to the analytical plan if they encounter difficulties or unexpected limitations. 

The analyst will also follow the assurance plan, and conduct the specified verification and validation. They shall provide traceable documentation of the assurance they have undertaken. They shall act on any findings from the assurer. 

Analysts shall maintain regular and agreed contact with the commissioner, for example through regular update reports on large projects. This provides an opportunity for the commissioner to advise on whether the analysis is still meeting their needs or whether there are any new requirements.

When conducting the analysis, it is important that it is transparent that the Analytical Plan has been followed and, any changes have been recorded. The analyst shall inform the commissioner and approver of such changes. The commissioner and approver can then comment on whether the analysis is still meeting the needs of the commission. Best practice includes:

* Maintaining a record of the work in a report;
* Logging the data, assumptions and inputs used in the analysis (see ADD HYPERLINK TO LOGS);
* Recording the verification and validation that has been undertaken, documenting any activities that are outstanding and noting what remedial action has been taken and its impact on the analysis.

### The Assurer's responsibilities during the analysis stage

The assurer shall review the assurance completed by the analyst, carry out any further validation and verification they may see as appropriate, and report errors and areas for improvement to the analyst. The assurer may then need to re-review the analytical work completed, as required. 


### The Commissioner's responsibilities during the analysis stage

The Commissioner’s role is to review any changes in design or methodology that the Analyst brings to their attention. The Commissioner should be available to provide input and clarifications to the Analyst. The aim is for the Commissioner to be aware of and accept changes to the design or methodology providing they meet their requirements. 

### The Approver's responsibilities during the analysis stage

The Approver should be aware of the progress of the analysis and ensure that they are available for approving the work at the Delivery stage.

## Assurance during the analysis stage

### Verification and validation

TBC

### Handling Uncertainty during the analysis stage

While the Scoping and Design stages identified and described risks and uncertainties, the Analysis stage aims to assess and quantify the impact of uncertainty on the analytical outcome and their contribution to the range and likelihoods of possible outcomes. Guidance on how to identify, mitigate, measure and communicate uncertainty can be found in the [Uncertainty Toolkit for Analysts](https://analystsuncertaintytoolkit.github.io/UncertaintyWeb/index.html). The verification and validation by the analyst and assurer should assure the appropriate treatment of uncertainty.

## Multi-use models and the analysis stage

In multi-use models, analysis and edits may be carried out on individual elements of the model at differing times. This calls for mechanisms for assuring that the changes integrate into the larger model as expected, for example, through the use of test-suites.

## Artificial Intellingence and Machine Learning (Black Box) models and the analysis stage

AI and ML models are not as transparent as traditionally coded models. This adds challenge to the assurance of these models as compared to other forms of analysis. Assurance activities during this stage include performance testing and formal verification. See the [Introduction to AI Assurance](https://www.gov.uk/government/publications/introduction-to-ai-assurance) for further details.

## Working with third parties


## Limitations of data

It is important to consider how well available data meet the needs of the analysis. It is rare to have the perfect dataset for an analytical commission. Reasons for this include:

* The data is not available in the time frame required for the ideal analysis;    
* The data definition does not perfectly align with the commission;    
* There are data or coverage gaps;    
* The data may be experimental or there are other reasons why it is not ‘mature’.    

Often, no data are available that are directly and precisely relevant to the parameter and conditions of interest. In such cases, it is often possible to use surrogate data. These are measurements of another parameter, or of the parameter of interest under different conditions, that are related to the parameter and conditions of interest. This implies an extrapolation between parameters, or between conditions for the same parameter, which introduces further uncertainty, additional to that associated with the data themselves. It may be possible to quantify this additional uncertainty using expert knowledge of the relationship between the surrogate and the parameter of interest.

The impact of using a proxy dataset should be explored and, if the uncertainty associated with the dataset has a large impact on the analysis, its appropriateness should be revisited. This exploration, and the decision to use a particular dataset or input, should be recorded for the benefit of the analytical assurer. 
