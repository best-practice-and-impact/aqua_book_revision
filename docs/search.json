[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The AQuA Book",
    "section": "",
    "text": "Important\n\n\n\nThis version of the AQuA book is a preliminary ALPHA draft. It is still in development, and we are still working to ensure that it meets user needs.\nThe draft currently has no official status. It is a work in progress and is subject to further revision and reconfiguration (possibly substantial change) before it is finalised.\n\n\n\nPreface\nPlaceholder text\n\n\nAcknowledgements\nThe AQuA Book is the work of many authors from across the Government Analytical Function. The original version of the book was compiled by the Quality Assurance Working Group set up after Sir Nicholas Macpherson’s review of modelling in government.\nThis revised edition of the book was produced by a task and finish group drawn from across the Government Analytical Function. We would like to thank everybody who has given of their time and expertise to produce the revised edition and give a special mention to the task and finish group who gave their time and expertise to the book:\n\nFaye Clancy\n\nWill England\nAndrew Friedman\n\nNick Harris\nJordan Low\n\nJames McGlade\nIan Mitchell\nIris Oren\nAdam Powell\nMartin Ralphs\nPhilippa Robinson\nSarjeet Soni\nLorna Wilson\nRebecca Wodcke\n\nAlec Waterhouse Date Month Year",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "foreword.html",
    "href": "foreword.html",
    "title": "Foreword",
    "section": "",
    "text": "Important\n\n\n\nThis version of the AQuA book is a preliminary ALPHA draft. It is still in development, and we are still working to ensure that it meets user needs.\nThe draft currently has no official status. It is a work in progress and is subject to further revision and reconfiguration (possibly substantial change) before it is finalised.\n\n\nPlaceholder text",
    "crumbs": [
      "Foreword"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Who is the AQuA Book for?\nThe AQuA book provides guidance on producing quality analysis for government. It aims to support well informed decision making to create better outcomes and improve the lives of citizens.\nThe AQuA Book has made a significant contribution to the cultural change in assurance practices in government. It is about the process for assuring analytical evidence in all forms. It sets out the core framework for assuring all forms of analytical evidence.\nThe last version of the Analytical Quality Assurance (AQuA) Handbook was published in 2015, following Sir Nicholas Macpherson’s Review of quality assurance of government models. Since then, assurance has become part of the fabric of good practice for developing evidence to support policy development, implemenation and operational excellence.\nThe world of analysis has developed since we published the first edition of the AQuA Book.\nIncreasingly in our data driven world, insights from analysis underpin almost all policies and support operational excellence. This underlines the continuing importance of assuring our evidence. In parallel our working practices have developed. The dominant analytical tools when we wrote the last edition were spreadsheets and proprietary software. Since then we have broadened the range of methods to include open-source software, machine learning and artificial intelligence.\nUsers of the AQuA book have pointed out some things we did not cover in the first edition and areas where guidance was unclear or insufficient. In this edition we have added guidance on:\nWe provide improved guidance on what a proportionate approach to assurance means and have made the whole guide applicable to all types of analysis.\nThe AQuA Book describes what you need to do but not how to do it, although it does contain many worked examples. Large organisations will have their own processes and practices covering “the how”.\nFor those of you who do not work in places with bespoke guidance you will find a collection of helpful resources in chapter 10.\nThe AQuA Book is a vital supporting guide for the Analysis Function Standard. This Standard refers extensively to the AQuA book and notes that “detailed guidance on the analytical cycle and management of analysis, included in the Aqua Book should be followed.”\nIt is also referred to by the Green Book, the Magenta Book and other Functional Standards, such as the Finance Function Standards.\nIn this edition we have tried to make our guidance relevant to anyone who commissions, uses, undertakes or assures analysis. It is about the whole process of producing analysis that is fit for purpose and not just about the checks after the analysis has been completed.\nWe would like to see producers and users of analysis from all backgrounds using this book, especially those producing analysis, evidence and research to support decision making in government. Our intended audience includes:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#who-is-the-aqua-book-for",
    "href": "intro.html#who-is-the-aqua-book-for",
    "title": "1  Introduction",
    "section": "",
    "text": "Users of analysis – helping you to get the most out of your commission;\nThose who carry out analysis such as members of the government analytical professions, including:\n\noperational researchers, statisticians and economists;\ngeographers;\nfinance professionals;\nactuaries;\nsocial researchers carrying out qualitative research;\ndata scientists developing advanced analytics;\nand anyone else carrying out analysis.\n\nSenior leaders with an interest in analytical assurance.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#why-should-i-pay-attention-to-this-guidance",
    "href": "intro.html#why-should-i-pay-attention-to-this-guidance",
    "title": "1  Introduction",
    "section": "1.2 Why should I pay attention to this guidance?",
    "text": "1.2 Why should I pay attention to this guidance?\nHere are a few reasons why.\n\nYour analytical insights will be used for major decisions and operations. You need to do your best to get them right, thus minimising the risk of being complicit in causing operational, business or reputational damage;\nTrust is hard to obtain but easy to lose. A simple error that could have been prevented by assurance could lead to your and your team’s work being doubted;\nPrevention is better than cure. Analysis is more likely to be right first time when you consider quality from the start. Having appropriate quality assurance in place helps to manage mistakes, handle changes to requirements and ensure appropriate re-use;\nProviding quality analysis provides the confidence that is needed for transparency and public openness;\nAssurance is required for audit purposes2; and\n\nProfessional pride in your work.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#how-to-use-this-book",
    "href": "intro.html#how-to-use-this-book",
    "title": "1  Introduction",
    "section": "1.3 How to use this book",
    "text": "1.3 How to use this book\nThe first four chapters of this book cover definitions and themes, whilst the second half of the book goes into more detail on the analytical life cycle. This can be pictured as follows: \nEach chapter in the second half of the book is structured as follows:\n\nIntroduction and overview\nRoles and responsibilities\nAssurance activities\nDocumentation\nUncertainty\nBlack box models\nMulti-use models\nAny other elements specific to the stage of the life cycle\n\nThis guidance uses the following terms to indicate whether recommendations are mandatory or advisory.\nThe terms are:\n\n‘shall’ denotes a requirement, a mandatory element, which applies in all circumstances, at all times\n‘should’ denotes a recommendation, an advisory element, to be met on a ‘comply or explain’ basis\n‘may’ denotes approval\n‘might’ denotes a possibility\n‘can’ denotes both capability and possibility\nis/are is used for a description\n\nThese are the same terms as those in the UK Government Functional Standards.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#principles-of-analytical-quality-assurance",
    "href": "intro.html#principles-of-analytical-quality-assurance",
    "title": "1  Introduction",
    "section": "Principles of analytical quality assurance",
    "text": "Principles of analytical quality assurance\nNo single piece of guidance provides a definitive assessment of whether a piece of analysis is of sufficient quality for an intended purpose. However, the following principles support commissioning and production of fit-for-purpose analysis:\nProportionate: Quality assurance effort should be appropriate to the risk associated with the intended use of the analysis and the complexity of the analytical approach. These risks include financial, legal, operational and reputational effects. More details can be found in chapter [3]\nAssurance throughout development: Quality assurance should be considered throughout the life cycle of the analysis and not just at the end. Effective communication is crucial when understanding the problem, designing the analytical approach, conducting the analysis and relaying the outputs. More details on the analysis life cycle can be seen in chapter [5].\nVerification and validation: Analytical quality assurance is more than checking that the analysis is error-free and satisfies its specification (verification). It should also include checks that the analysis is appropriate, i.e. fit for the purpose for which it is being used (validation). Validation and verification are covered in more depth in chapters [5-9].\nAccept that uncertainty is inherent in the inputs and outputs of any piece of analysis. Chapter [8] covers assurance of the analytical phase of the project, including the treatment of uncertainty . Further support can be found in the Uncertainty Toolkit for Analysts in Government (analystsuncertaintytoolkit.github.io)\nAnalysis with RIGOUR: One acronym some users find helpful to consider when completing analysis is RIGOUR. This is described in the box below.\n\n\n\n\n\n\nRIGOUR\n\n\n\n\n\nThroughout all the stages of an analytical project, the analyst should ask questions of their own analysis. The helpful mnemonic “RIGOUR” may assist:\n\nRepeatable\nIndependent\nGrounded in reality\nObjective\nUncertainty-managed\nRobust\n\nRepeatable: For an analytical process to be considered valid we might reasonably expect that the analysis produces the same outputs for the same inputs and constraints. Different analysts might approach the analytical problem in different ways, while methods might include randomised processes. In such cases, exact matches are not guaranteed or expected. Taking this into account, repeatability means that if an approach is repeated the results should be as expected.\nIndependent: Analysis should be free of prejudice or bias. Care should be taken to balance views appropriately across all stakeholders and experts.\nGrounded in reality: Quality analysis takes the Commissioner and Analyst on a journey as views and perceptions are challenged and connections are made between the analysis and its real consequences. Connecting with reality like this guards against failing to properly grasp the context of the problem that is being analysed.\nObjective: Effective engagement and suitable challenge reduce the risk of bias and enables the Commissioner and the Analyst to be clear about the interpretation of results.\nUncertainty-managed: Uncertainty is identified, managed and communicated throughout the analytical process.\nRobust: Analytical results are error free in the context of residual uncertainty and accepted limitations that make sure the analysis is used appropriately.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "Black box: system which can be viewed in terms of its inputs and outputs (or transfer characteristics), without any knowledge of its internal workings.↩︎\nManaging Public Money, Annex 4.2 Use of models↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html",
    "href": "definitions_and_key_concepts.html",
    "title": "2  Definitions and concepts",
    "section": "",
    "text": "Analysis\nThis chapter sets out definitions and concepts that are used throughout the rest of the book.\nAnalysis is the collection, manipulation and interpretation of information and data for use in decision making. Analysis can vary widely between situations and many different types of analysis may be used to form the evidence base that supports the decision-making process.\nExamples of types of analysis that are frequently encountered in government are:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#analysis",
    "href": "definitions_and_key_concepts.html#analysis",
    "title": "2  Definitions and concepts",
    "section": "",
    "text": "actuarial\n\ndata science\neconomic\nfinancial\n\ngeographical\noperational research\nscientific, technical and engineering research\n\nstatistical\n\nsocial research",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#assurance",
    "href": "definitions_and_key_concepts.html#assurance",
    "title": "2  Definitions and concepts",
    "section": "Assurance",
    "text": "Assurance\nAnalytical assurance is the process and set of practices to ensure that the analysis is fit for purpose.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#assurance-activities",
    "href": "definitions_and_key_concepts.html#assurance-activities",
    "title": "2  Definitions and concepts",
    "section": "Assurance activities",
    "text": "Assurance activities\nAssurance activities are any actions carried out in order to validate and verify analysis.\nFor example:\n\nanalyst testing\n\npeer review\n\nreconciliation of results to independent sources",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#artificial-intelligence",
    "href": "definitions_and_key_concepts.html#artificial-intelligence",
    "title": "2  Definitions and concepts",
    "section": "Artificial Intelligence",
    "text": "Artificial Intelligence\nArtificial intelligence (AI) attempts to simulate human intelligence using techniques and methods such as machine learning, natural language processing, and robotics. AI aims to perform tasks that typically require human intelligence, such as problem-solving, decision-making, and language understanding. Artificial Intelligence models are a subset of black box models",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#black-box-models",
    "href": "definitions_and_key_concepts.html#black-box-models",
    "title": "2  Definitions and concepts",
    "section": "Black box models",
    "text": "Black box models\nBlack box models internal workings are not visible or easily understood. These models take input and produce output without providing clarity about the process used to arrive at the output. Artificial Intelligence models (including Machine Learning) are the most common type of black box models used today. Other forms of black box models may arise in future.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#business-critical-analysis",
    "href": "definitions_and_key_concepts.html#business-critical-analysis",
    "title": "2  Definitions and concepts",
    "section": "Business critical analysis",
    "text": "Business critical analysis\nBusiness critical analysis is analysis which plays such a role in decision making that it influences significant financial and funding decisions, is necessary to the achievement of a Departmental business plan, or where an error could have a significant reputational, economic or legal implications.\nThe first edition of the AQuA book described business critical models. This has been generalised to business critical analysis, as it is possible for analysis to be business critical without including a model. Some departments may continue to use the term business critical models (BCM).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#documentation",
    "href": "definitions_and_key_concepts.html#documentation",
    "title": "2  Definitions and concepts",
    "section": "Documentation",
    "text": "Documentation\n\nSpecification documentation\nSpecifications capture initial engagements with the commissioner. They describe the question, the context, and any boundaries of the analysis. This provides a definition of the scope and a mechanism for agreeing project constraints such as deadlines, available resources, and capturing what level of assurance is required by the commissioner.\n\n\nDesign documentation\nDesign documents describe the analytical plan, including the methodology, inputs, and software. They also contain details of the planned verification and validation of the analysis. They provide a basis for the Analytical Assurer to verify whether the analysis meets the specified requirements. For more information on the design documentation, see the Design chapter.\n\n\nAssumptions log\nA register of assumptions, whether provided by the Commissioner or derived by the analysis, that have been risk assessed and signed off by an appropriate governance group or stakeholder. Assumption logs should describe each assumption, quantify its effect and reliability and set out when it was made, why it was made, who made it and who signed it off.\n\n\nDecisions log\nA register of decisions, whether provided by the Commissioner or derived by the analysis. Decisions logs should describe each decision and set out when it was made, why it was made, who made it and who signed it off.\n\n\nData log\nA register of data provided by the Commissioner or derived by the analysis that has been risked assessed and signed-off by an appropriate governance group or stakeholder.\n\n\nUser / technical documentation\nAll analysis shall have user-documentation, even if the user is only the analyst leading the analysis. This is to ensure that they have captured sufficient material to assist them if the analysis is revisited in due course. For analysis that is likely to be revisited or updated in the future, documentation should be provided to assist a future analyst and should be more comprehensive. This documentation should include a summary of the analysis including the context to the question being asked, what analytical methods were considered, what analysis was planned and why, what challenges were encountered and how they were overcome and what verification and validation steps were performed. In addition, guidance on what should be considered if the analysis is to be revisited or updated is beneficial. For modelling, the Analyst may include a model map that describes data flows and transformations.\n\n\nAssurance statement\nA brief description of the analytical assurance that have been performed to assure the analysis. The statement should refer to known limitations and conditions associated with the analysis.\n\n\n\n\n\n\nExample of publishing quality assurance tools\n\n\n\nThe Department for Energy Security and Net Zero and Department for Business and Trade have published a range of quality assurance tools and guidance to help people with Quality Assurance of analytical models. Modelling Quality Assurance tools and guidance are used across the two departments to ensure analysis meets the standards set out in the AQuA book and provide assurance to users of the analysis that proportionate quality assurance has been completed.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#multi-use-models",
    "href": "definitions_and_key_concepts.html#multi-use-models",
    "title": "2  Definitions and concepts",
    "section": "Multi-use models",
    "text": "Multi-use models\nSome models, often complex and large, are used by more than one user or group of users for related but differing purposes, these are known as multi-use models.\nOften, a Steering Group is created to oversee the analysis. This Steering Group would be chaired by the senior officer in charge of the area that maintains the model, and contain senior, ideally empowered, representatives of each major user area.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#quality-analysis",
    "href": "definitions_and_key_concepts.html#quality-analysis",
    "title": "2  Definitions and concepts",
    "section": "Quality analysis",
    "text": "Quality analysis\nQuality analysis is analysis which is fit for the purpose(s) it was commissioned to meet. It should be accurate, have undergone appropriate assurance, be evidenced, proportionate to its effect, adequately communicated, documented and accepted by its commissioners.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#roles-and-responsibilities",
    "href": "definitions_and_key_concepts.html#roles-and-responsibilities",
    "title": "2  Definitions and concepts",
    "section": "Roles and responsibilities",
    "text": "Roles and responsibilities\nThe AQuA book defines the following roles:\n\nCommissioner\nAnalyst\n\nAssurer\nApprover\n\nSee Roles and Responsibilities for details.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#third-party",
    "href": "definitions_and_key_concepts.html#third-party",
    "title": "2  Definitions and concepts",
    "section": "Third party",
    "text": "Third party\nAny individual, or group of individuals that is not a member of the same group as the those commissioning analysis. E.g. working for a different government department, a different function or an outside company.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#uncertainty",
    "href": "definitions_and_key_concepts.html#uncertainty",
    "title": "2  Definitions and concepts",
    "section": "Uncertainty",
    "text": "Uncertainty\nUncertainties are things that are not known, or are in a state of doubt, or are things whose effect is difficult to know. They have the potential to have major consequences for a project, programme, piece of analysis meeting its objectives.1\nThere are different types of uncertainty. A common classification divides uncertainty into known knowns, known unknowns, and unknown unknowns. The type of uncertainty will influence the analytical approach and assurance activities required.\nThe Uncertainty Toolkit for Analysts in Government is a tool produced by a cross government group to help assessing and communicating uncertainty.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#validation",
    "href": "definitions_and_key_concepts.html#validation",
    "title": "2  Definitions and concepts",
    "section": "Validation ",
    "text": "Validation \nEnsuring the analysis meets the needs of its intended users and the intended use environment. See Glover (2014) for more information.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#verification",
    "href": "definitions_and_key_concepts.html#verification",
    "title": "2  Definitions and concepts",
    "section": "Verification",
    "text": "Verification\nEnsuring the analysis meets it specified design requirements. See Glover (2014) for more information.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#version-control",
    "href": "definitions_and_key_concepts.html#version-control",
    "title": "2  Definitions and concepts",
    "section": "Version control",
    "text": "Version control\nIt is important to ensure that changes that have been made to analysis can be easily seen and quality assured by the analytical assurer, and the latest version of the analysis is being used. Tools and templates can be used to support with evidencing updates and the checks completed throughout a project providing a log of changes that have occurred, why, when, and by whom.\n\n\n\n\nGlover, Paul. 2014. Verification and Validation for the AQuA Book. DSTL Portsdown West Portsdown Hill Road Fareham PO17 6AD: HM Government. https://www.gov.uk/government/publications/verification-and-validation-for-the-aqua-book.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#footnotes",
    "href": "definitions_and_key_concepts.html#footnotes",
    "title": "2  Definitions and concepts",
    "section": "",
    "text": "https://www.nao.org.uk/wp-content/uploads/2023/08/Good-practice-guide-Managing-uncertainty.pdf↩︎",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and concepts</span>"
    ]
  },
  {
    "objectID": "proportionality.html",
    "href": "proportionality.html",
    "title": "3  Proportionality",
    "section": "",
    "text": "3.1 Introduction\nAll analysis shall be assured, and the assurance should be proportionate to the potential effect it will have, size and complexity of the analysis. The level of assurance should be guided by a structured assessment of the business risks.\nThe assurer and the analyst shall be independent. The degree of separation depends on many factors including the importance of the output, and the size and complexity of the analysis. This does not mean that the analyst should not undertake assurance, rather that there shall also be some formal independent assurance.\nThink about and deliver appropriate (proportionate) levels of assurance for your analysis. There is a need to be confident in analysis delivered, but there is no point spending months assuring simple analysis that will have a minor influence on a decision.\nTable 3-1 provides a list of factors that should be considered when determining what level of assurance is appropriate.\nFurther detail and considerations may be found on the Data Quality Hub’s Quality Questions and Red Flags page.\nFigure 3-1 shows some assurance techniques that might be considered for different levels of analysis complexity and business risk. The important point is, the need for more assurance interventions increases with the complexity of, and the business risk associated with analysis.\nThe interventions in Figure 3-1 must not be viewed in isolation. The interventions should build on each other, for example some complex and risky analysis that would benefit from an external review should also use interventions closer to the axes, for example version control and analyst led testing.\nThe total elimination of risk will never be achievable, so a balance needs to be found that reduces the overall business risk to an acceptable level. The diagram indicates a few practical assurance techniques. In practice there are many different techniques that need to be considered and implemented as appropriate.\nMany of these interventions are mentioned elsewhere in the AQUA Book, and are not repeated here.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "proportionality.html#introduction",
    "href": "proportionality.html#introduction",
    "title": "3  Proportionality",
    "section": "",
    "text": "Table 3-1 - Factors for determining appropriate assurance\n\n\n\n\n\n\nFactor\nComments\n\n\n\n\nBusiness criticality\nDifferent issues will affect business criticality such as financial, legal, operational, political and reputational effects.\n\n\nRelevance of the analysis to the decision making process\nWhen analysis forms only one component of a broad evidence base, less assurance is required for that specific analysis than if the decision is heavily dependent on the analysis alone. Significant assurance is still likely to be required for the evidence base.\n\n\nType and complexity of analysis\nHighly complex analysis requires more effort to assure. The nature of that analysis may also require the engagement of appropriate subject matter experts.\n\n\nNovelty of approach\nA previously untried method requires more assurance. Confidence will grow as the technique is repeatedly tested.\n\n\nReusing or repurposing existing work\nReusing work that was carried out previously may require validation and verification to confirm that original approach - method, assumptions data etc. are still appropriate for the new requirement.\n\n\nLevel of precision required in outputs\nLower precision analysis often uses simplified assumption, models and data. The assurance approach is the same but will take less time than more precise analysis.\n\n\nAmount of resource available for the analysis and assurance\nThe value for money of any additional assurance must be balanced alongside the benefits and risk appetite that exists. Analysis that is used for many purposes (e.g. population projections) may require greater levels of QA than might be suggested by any individual decision they support.\n\n\nLongevity of the analysis\nOngoing analysis will require robust change control and regular review.\n\n\nAffects on the public\nAnalysis which will have a significant affect on the public may require more assurance.\n\n\nRepeat runs for the same analysis\nConcentrate on version control and assurance of data and parameters for each run.\n\n\n\n\n\n\n\nFigure 3-1 - Types of quality assurance - darker shades indicate the need for need for extra assurance activities and greater separation between the analyst and the assurer. The contours indicate the groups of activities that may be carried out for a particular level of business risk/complexity.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "proportionality.html#structured-assessment-of-business-risk-and-complexity",
    "href": "proportionality.html#structured-assessment-of-business-risk-and-complexity",
    "title": "3  Proportionality",
    "section": "3.2 Structured assessment of business risk and complexity",
    "text": "3.2 Structured assessment of business risk and complexity\nTo guide what assurance is needed it is necessary to take a structured approach when reviewing business risks. Business risk should be viewed as the combination of the potential affect of analytical errors, and the likelihood of errors occurring. In situations where the potential effect is high, it is more important that the likelihood of errors is reduced.\nThis can be visualised by considering the situation as a risk matrix, illustrated in Table 3-2. The effect analysis will have is usually be beyond the control of the analyst to change, so there will be few options to move an assessment down the table. However, there will usually be treatments (or mitigations), involving additional assurance measures, that will allow the assessed business risk to move to the left.\n\n\nTable 3-2 - Example of a risk matrix\n\n\n\n\n\n\n\nLikelihood of errors occurring\n\n\n\nAffect from errors occurring\n\n\n\n\n\n\nHighly unlikely\n\n\nUnlikely\n\n\nRealistic possibility\n\n\nLikely or probably\n\n\nHighly likely\n\n\n\n\n\n\nCritical\n\n\nMedium\n\n\nMedium\n\n\nHigh\n\n\nHigh\n\n\nHigh\n\n\n\n\n\n\nSevere\n\n\nLow\n\n\nMedium\n\n\nMedium\n\n\nHigh\n\n\nHigh\n\n\n\n\n\n\nMajor\n\n\nLow\n\n\nMedium\n\n\nMedium\n\n\nMedium\n\n\nHigh\n\n\n\n\n\n\nModerate\n\n\nVery Low\n\n\nLow\n\n\nMedium\n\n\nMedium\n\n\nMedium\n\n\n\n\n\n\nMinor\n\n\nVery Low\n\n\nVery Low\n\n\nLow\n\n\nLow\n\n\nMedium\n\n\n\nTable 3-3 shows appropriate responses to a risk assessment. Where business risk is high, appropriate treatment(s) must be considered to reduce the probability of errors occurring. The choice of treatment will depend on the mitigations already in place and on the complexity of the analysis (see Figure 3-1).\nFor a situation where simple analysis is being employed, a review by an appropriate expert may be sufficient as the additional mitigation. However, for complex analysis that is already employing a wide range internal assurance measures, options like external peer review may be necessary.\nIn cases where there is a need for analysis, but there are also significant time and/or resource constraints, it may not be possible to do as much assurance as usual. In these situations, concentrate on areas of greatest risk. These risks and limitations must also be communicated, along with appropriate caveats.\n\nTable 3-3 - Responses to risk assessment levels\n\n\n\n\n\n\nAssessed risk\nMitigations to consider\n\n\n\n\nHigh\nThe risk should not be tolerated. New assurance measures must be considered to treat (mitigate) the likelihood of errors occurring. If treatment isn’t an option, consideration must be given to terminating or transferring the (analysis) risk. If it remains necessary to tolerate the risk the SRO needs to fully understand the risk.\n\n\nMedium\nThe risk should not be tolerated without SRO agreement. New assurance measures should be put in place to treat (mitigate) the likelihood of errors occurring. Continue with planned or existing mitigations.\n\n\nLow\nThe risk can be tolerated. Existing or planned mitigations should be continued, and new treatments may be considered.\n\n\nVery Low\nThe risk can be tolerated. Existing/planned mitigations measures should be continued.\n\n\n\nFor further guidance on risk management, refer to the Orange book which covers risk management principles and risk control frameworks.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "proportionality.html#externally-commissioned-work",
    "href": "proportionality.html#externally-commissioned-work",
    "title": "3  Proportionality",
    "section": "3.3 Externally commissioned work",
    "text": "3.3 Externally commissioned work\nProportionate assurance of externally commissioned work is just as important as for internally produced analysis. For the commissioner, to use the work they should be fully informed of the business risk associated with it. This should be provided by an appropriate mix of documented risk assessments provided as part of the work, and by joint risk assessments planned throughout the life of the project. For commissioned work the options for mitigation will be similar to those for internal analysis.\nThe difference will be in ensuring the assessment of risks and the applied mitigations are fully understood by the commissioner.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "proportionality.html#black-box-models-and-business-risk",
    "href": "proportionality.html#black-box-models-and-business-risk",
    "title": "3  Proportionality",
    "section": "3.4 Black-box models and business risk",
    "text": "3.4 Black-box models and business risk\nIncreasingly analysis may be underpinned by artificial intelligence or other forms of black-box models. With such models, the need to understand business risk remains, and the same structured approach to assessing business risk should be taken. The challenges in providing this assessment will be in ensuring the transparency of the analysis, availability of a suitable mix of experts, and developing understanding of what mitigations are possible.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html",
    "href": "quality_assurance_culture.html",
    "title": "4  Quality assurance culture",
    "section": "",
    "text": "4.1 Leadership\nCreating and maintaining a strong culture of quality assurance is a vital element of ensuring analysis is high quality and robust.\nThis chapter particularly addresses senior leaders and describes their role in developing a strong culture of quality assurance. It outlines processes and approaches to support and embed quality assurance that senior leaders should consider for their teams. However, everyone has a role to play in creating a strong quality assurance culture. As such, the approaches outlined are useful for everyone to understand, regardless of their role in a given team.\nFor purposes of this chapter, culture is defined as the shared ways of working, beliefs and habits of an organisation.\nA strong culture of quality assurance means that quality assurance is understood, expected, and valued across all those involved in the analytical process, including commissioners, analysts, users of analysis, managers, senior leaders and stakeholders.\nCulture enables the risk management described elsewhere in this document.\nA quality assurance culture starts with senior leaders. They are accountable for the quality of analysis carried out in their departments. A important element of discharging this accountability is to clearly set out the priority of quality within their teams and create processes for embedding quality assurance.\nThe guidance in Annex 4.2 of Managing Public Money assigns accountability for ensuring appropriate assurance processes are in place to the Accounting Officer. In practice the Accounting Officer may assign the responsibility to a senior leader reporting to the senior management board. The Accounting Officer may collect information on the state of assurance processes and include this in their annual report. The Department of Energy Strategy and Net Zero reports this annually - page 91 of DESNZ Annual report.\nSenior leaders should ensure there is clear messaging and standards on quality assurance, through guidance, training, and regular updates. Senior leaders can demonstrate the importance of quality assurance through long term initiatives, like setting up and embedding quality assurance processes within the team and creating roles and teams to support quality assurance. Senior leaders should also regularly talk about quality with their teams and highlight quality successes.\nAs part of a strong quality assurance culture, senior leaders should empower all those in the analytical process to identify any risks to the quality of the work, ensure people at any level can raise any quality concerns, and be able to discuss and constructively challenge each other if they feel those standards are not being met. To underpin this, senior leaders should ensure teams have a common understanding of the quality standards required for their work.\nCreating transparency at all levels can help embed a culture of quality assurance. This includes peer review, open source of code (where possible), external publication of models or methods and publication of the register of Business Critical Analysis.\nSenior leaders should also develop processes so teams can report when things go wrong, be open and honest when issues occur, carry out reviews to understand the failures in the assurance process and share the lessons learnt across the analytical community.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#leadership",
    "href": "quality_assurance_culture.html#leadership",
    "title": "4  Quality assurance culture",
    "section": "",
    "text": "Sharing best practice on quality assurance\n\n\n\nHM Revenue and Customs have developed a Quality Champions network, made up of analysts from across the department. The network discuss quality assurance initiatives, quality issues and how they were resolved and shares wider best practice.\n\n\n\n\n\n\n\n\n\n\n\nAn open culture when things go wrong\n\n\n\nWhen the Department for Education made an error producing the schools national funding formula allocations for 2024-25, they ran a detailed internal review to understand what went wrong and why it was not detected by the QA process. The department also commissioned and published an external, independent review to assess the error and put forward recommendations. The independent review praised the team for its open learning culture and a culture of taking responsibility for mistakes.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#capacity-and-capability",
    "href": "quality_assurance_culture.html#capacity-and-capability",
    "title": "4  Quality assurance culture",
    "section": "4.2 Capacity and capability",
    "text": "4.2 Capacity and capability\nSenior leaders should create the conditions in which quality assurance processes can operate effectively, by ensuring staff have sufficient time for all stages of the analytical lifecycle, including design, quality assurance and documentation. The culture should also ensure staff can draw on expertise and experience from others, and have the access to the tools and data they need.\n\n4.2.1 Capacity\nThere is a risk that work, and time pressures mean teams cut corners on quality or mistakes are made as analysis is rushed. Senior leaders can mitigate this through strong prioritisation, supporting teams to push back on lower value work or by making tough choices on team wide priorities. Through this prioritisation, senior leaders can emphasise the importance of quality. Senior leaders can support quality assurance, by ensuring it is considered throughout the lifecycle of a project, by all parties involved (analytical and non-analytical), and not simply considered at the end. They should support all parties to make time for adequate quality assurance, even when timescales are tight, as described in later chapters of this book.\nIf time constraints mean insufficient assurance has taken place, senior leaders should ensure this is explicitly acknowledged and reported. This should be reported via an assurance statement that sets out the known limitations and conditions associated with the analysis.\nWhere analysis requires peer review, this should be carried out by independent, skilled and competent individuals or groups. However, it can be difficult to identify available experts who are able to provide a review. There are several approaches to support and embed independent review, such as setting up specific teams to review and audit a sample of analytical projects, developing assurance networks of analysts who can provide reviews when needed, partnering with another Department, or procuring an independent review from an independent source such as the Government Actuary’s Department (GAD), an academic institution or contractor. Team leaders can support this by making time for analysts to carry out peer reviews and ensuring analysts are clear that supporting peer reviews is part of their role.\n\n\n\n\n\n\nHM Revenue and Customs independent review team\n\n\n\nHMRC has a small analytical team which independently reviews analysis from across the department, including a sample of HMRC’s business-critical models. The reviews provide assurance for high profile analysis and support the sharing of best practice.\n\n\n\n\n4.2.2 Capability\nThere is a risk that errors occur because of a lack of skills or experience. Senior leaders can identify common skills gaps, creating training or mentoring to help fill gaps in analysts’ knowledge. Processes to support knowledge sharing, innovation and dissemination of best practice will all help develop capability. Rolling out training on departmental assurance processes can also mitigate this risk.\nThere are various cross-government resources designed to provide support and guidance for commissioners and users of analysis. For example, the Analysis Function’s Advice for policy professionals using statistics and analysis aims to help policy professionals to work effectively with analysts and analysis. It introduces some important statistical ideas and concepts to help policy professionals ask the right questions when working with statistical evidence.\n\n\n\n\n\n\nBuilding assurance capability\n\n\n\nThe Department for Energy Security and Net Zero are building assurance capacity with a programme of quality assurance Colleges. The Colleges run regular virtual sessions, open to colleagues across Government and Partner Organisations.\nThese sessions include an interactive activity looking at a purposefully sabotaged model, used to introduce and familiarise colleagues with the quality assurance logbook and the departmental system of actively monitoring models through these logbooks.\nCollege participants also join the Modelling Integrity Network, as potential Assuring Analysts where these cannot be found by Lead Analysts in their own policy areas.\n\n\n\n\n4.2.3 Quality assurance champions\nIn an organisations with large analytical community, it is good practice for the senior leaders to appoint a quality assurance champion/s. This person/group can share best practice in implementation of quality assurance and provide advice on issues such as proportionality and communication of assurance.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#tools",
    "href": "quality_assurance_culture.html#tools",
    "title": "4  Quality assurance culture",
    "section": "4.3 Tools",
    "text": "4.3 Tools\nThere are risks of technology or analytical tools being out of date. This means that analysts cannot follow best practice or must spend time fixing processing issues instead of concentrating on quality. Senior leaders can support teams by: * making funding available for new tools or improving existing tools;\n* gathering common issues; and, * working with escalate them to appropriate points in their organisation.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#data",
    "href": "quality_assurance_culture.html#data",
    "title": "4  Quality assurance culture",
    "section": "4.4 Data",
    "text": "4.4 Data\nThere is a risk that data quality and data understanding cause quality issues with analysis. Senior leaders can escalate data quality issues with wider data teams, and champion and oversee changes to improve data quality.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#uncertainty-in-analysis",
    "href": "quality_assurance_culture.html#uncertainty-in-analysis",
    "title": "4  Quality assurance culture",
    "section": "4.5 Uncertainty in analysis",
    "text": "4.5 Uncertainty in analysis\nUncertainty is intrinsic to government work. Analysis should support government decision making by appropriate treatment of uncertainty. Senior leaders are responsible for instilling a culture in which the proportionate handling of uncertainty is part of all analytical work. To do so, senior leaders should gain an understanding of how to identify uncertainty, how uncertainty can be analysed, and how to plan for uncertainty. The National Audit Office has created guidance for decision makers and senior leaders on managing uncertainty. It is the responsibility of decision makers to challenge analysts, as well as other members of a project team, on whether uncertainties have been considered, treated appropriately, and communicated.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#governance-and-control",
    "href": "quality_assurance_culture.html#governance-and-control",
    "title": "4  Quality assurance culture",
    "section": "4.6 Governance and control",
    "text": "4.6 Governance and control\nGovernance supports a strong quality assurance culture, by overseeing the management and assurance of analysis. The Analysis Function Standard sets out the requirements for a governance framework for analysis. Each organisation should have a defined and established approach to assurance, which should be applied proportionately to the risk and value of the activity and integrated with the organisation’s overall assurance framework. \nProject level governance can provide oversight over a particular model or work area, allowing the Approver to ensure the analysis is fit for purpose. For example, formally agreeing assumptions (which may be recorded in an assumptions log) will reduce the need for reworking the analysis providing more time for assurance. Projects governance can also fit within wider programme level governance. \nAnalytical governance boards for new, high-profile or complex pieces of analysis, can allow senior analytical leaders and experts to provide oversight and challenge of analysis and ensure best practice is followed. These groups are multi-disciplinary and can cover a range of analytical approaches based on their expertise and experience. This can help ensure that innovations and new approaches are disseminated across teams, and standards are applied equally across similar work.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#transparency",
    "href": "quality_assurance_culture.html#transparency",
    "title": "4  Quality assurance culture",
    "section": "4.7 Transparency",
    "text": "4.7 Transparency\nTransparency at all levels can help embed a culture of quality assurance. For example peer review, sharing lessons learnt, and making analysis open (where possible), all contribute to an open culture of high quality work.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#externally-commissioned-analysis",
    "href": "quality_assurance_culture.html#externally-commissioned-analysis",
    "title": "4  Quality assurance culture",
    "section": "4.8 Externally commissioned analysis",
    "text": "4.8 Externally commissioned analysis\nAnalysis may be commissioned externally such as qualitative or quantitative research, or the production of models. In this case the commissioning department is accountable for analytical quality. The commissioning analyst should ensure that quality standards are clear and being met and that these standards are documented.\nFor Arm’s Length Bodies1 (ALBs), the Commissioner of analysis is accountable for ensuring the requirements set out in the AQuA Book are met.\nThe guidance mentioned above also applies to Arms Length Bodies. They may set out in a framework document how their Accounting Officer will demonstrate compliance with Annex 4.2 of Managing Public Money and the Analysis Function Standard\nThird parties may set out in a framework document how they will demonstrate compliance with Annex 4.2 of Managing Public Money and the Analysis Function Standard\nWhen working with third parties (e.g Arm’s Length Bodies (ALBs)), the commissioning department shall ensure it is clear which role or roles in which stages of the analytical lifecycle that third party is responsible for. See Roles and Responsibilities for details on the roles.\nFor example, the third party may only undertake the Analyst role in the analysis phase or they may undertake the Analyst, Assurer and Approver roles in all stages of the lifecycle.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#footnotes",
    "href": "quality_assurance_culture.html#footnotes",
    "title": "4  Quality assurance culture",
    "section": "",
    "text": "ALBs include executive agencies, non-departmental public bodies and non-ministerial departments, please see Cabinet Office guidance on Classification of Public Bodies↩︎",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "analytical_lifecycle.html",
    "href": "analytical_lifecycle.html",
    "title": "5  Roles and the analytical lifecycle",
    "section": "",
    "text": "5.1 Roles and responsibilities\nAn analytical project can be viewed as a variation on an archetypal project defined by roles and stages. This chapter gives an overview of the roles and the project stages in the analytical lifecycle. Subsequent chapters go into the details of each stage, and the responsibilities of each role during a given stage.\nOrganisations may have their own titles for the main functional roles involved in analysis that are set out here.\nEach role may be fulfilled by a team or committee of people. However, a single individual will have overall accountability (such as the chair of a committee) for each role.\nThe AQuA book defines the following roles:\nThe roles of Analyst and Assurer shall be distinct from each other. The Analyst should carry out their own assurance but responsibility for formal assurance to the Approver and Commissioner lies with the Assurer. In some instances, particularly for quick and / or simple analysis, an individual may deliver more than one of the roles apart from the Assurer and Analyst roles which shall be separate from one another in all cases.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Roles and the analytical lifecycle</span>"
    ]
  },
  {
    "objectID": "analytical_lifecycle.html#roles-and-responsibilities",
    "href": "analytical_lifecycle.html#roles-and-responsibilities",
    "title": "5  Roles and the analytical lifecycle",
    "section": "",
    "text": "Commissioner (may be known as customer)\n\nRequests the analysis and sets out their requirements\n\nAgrees what the analyst is going to do will satisfy the need\n\nAccepts the analysis and assurance as fit for purpose\n\nAnalyst\n\nDesigns the approach, including the assurance, to meet the commissioner’s requirements\nAgrees the approach with the Commissioner\nCarries out the analysis\nCarries out their own assurance\n\nActs on findings from the Assurer\nCan be a group of analysts, in which case the lead analyst is responsible\n\nAssurer (may be known as Analytical Assurer, Assuring Analyst)\n\nReviews the assurance completed by the Analyst\n\nCarries out any further validation and verification they may see as appropriate\nReports errors and areas for improvement to the analyst\n\nRe-reviews as required\n\nConfirms the work has been appropriately scoped, executed, validated and verified and documented to the Approver\n\nCan be a group of assurers. In which case the leader of the group is responsible. They must be independent from the analysts.\n\nApprover (may be known as Senior Analyst or Senior Responsible Officer (“SRO”))\n\nScrutinises the work of the Analyst and Assurer\n\nConfirms (if necessary) to the Analyst, Assurer and Commissioner that the work has been appropriately assured",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Roles and the analytical lifecycle</span>"
    ]
  },
  {
    "objectID": "analytical_lifecycle.html#the-analytical-lifecycle",
    "href": "analytical_lifecycle.html#the-analytical-lifecycle",
    "title": "5  Roles and the analytical lifecycle",
    "section": "5.2 The analytical lifecycle",
    "text": "5.2 The analytical lifecycle\nQuality assurance activities should take place throughout all stages of an analytical project. An effective quality assurance process involves ongoing engagement between the commissioner and the analyst to ensure an appropriate balance is maintained between time, resource and quality, and to ensure a shared understanding of the assurance activities required and risks involved.\n\n\n\nFigure 2 - The analytical cycle\n\n\nFigure 2 is adapted from the Government Functional Standard for Analysis. Analytical quality assurance activities should take place during every phase of the cycle and should consider proportionality, although analytical quality considerations may vary depending on project governance and the specific phase of the cycle. All projects will involve some element of every phase of the cycle, even if this is not clearly defined.\nIt is important that proportionality is considered and that there is transparency of the analytical decisions, process, limitations and changes made at each stage to enable effective assurance and communication. This should be enabled by:\n\nClear documentation of the analysis, assumptions and data,\nClear records of the analytical decisions made; and\nClear records of the quality assurance processes and checks completed.\n\n\n5.2.1 Engagement and scoping\nAnalytical projects typically start with customer engagement although other events may trigger analytical projects. Scoping ensures that an appropriate, common understanding of the problem is defined and that expectations are aligned with what can be delivered. During this phase the Commissioner plays an important role in communicating the questions to be addressed and working with the Analyst to ensure the requirements and scope are defined and understood.\nWhere analysis requires multiple cycles, for example to develop, use and update analytical models, this phase may follow on from the Delivery and Communication phase. In these cases, the phase will concentrate on the scope of the questions to be addressed in the next stage of the analytical project.\nMore effort may be needed to define the requirements and scope in this phase for research, evaluation or other projects that may need to seek a wider range of perspectives or for which subsequent phases and work may be delivered through a product or service.\n\n\n5.2.2 Design\nDuring the design phase, the Analyst will convert the commission into an analytical plan, including the assurance required and ensuring it is sufficient to answer the questions posed. This phase includes the communication and approval of plans produced, and some iteration between the Commissioner and the Analyst is to be expected as the analytical solution is developed and limitations understood.\nFor larger projects or those that require multiple cycles, the design phase may include consideration of the staging of work over the whole scope of the project as well as work required in each stage. Analysis plans for work that is dependent on insights from earlier stages may be high-level and necessitate a return to the design phase at a later date.\n\n\n5.2.3 Analysis\nThe analysis phase is where planned analysis is undertaken, and progress and relevance are monitored. During work, the design and plan may be amended to account for changing circumstances, emerging information or unexpected difficulties or limitations encountered, and this phase also includes maintaining appropriate records of the analysis conducted, changes, decisions and assumptions made. In some cases, changes or limitations encountered may necessitate a return to either the scoping or design phase.\nThroughout this phase, traceable documentation of the assurance activities undertaken shall also be produced.\nIn larger analytical projects, some outputs of the analysis may be completed at different times as work develops, and aspects of other phases may therefore take place concurrently.\n\n\n5.2.4 Delivery, communication and sign-off\nDuring the delivery stage, insights and analytical assurances are communicated to the Approver and the Commissioner. The aim is ensuring that these are sufficiently understood in order for the Approver and Commissioner to determine whether the work has been appropriately assured and meets their requirements. This may then trigger additional analysis and further assurance as analytical projects frequently need further iteration or extension to satisfy the Commissioner’s needs.\nWork in this stage can vary considerably depending on the commission, impact, approval processes and the nature of the project. Delivery and communication activities may include producing summary packs and reports, launching dashboards or websites and presentations to boards.\nAfter analysis results have been determined to meet the requirements, they are formally approved for dissemination during sign-off. Sign-off includes confirmation that the commission was met, documentation and evidence was captured, and appropriate assurance was conducted. This approval may be phased as work develops and insights are produced.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Roles and the analytical lifecycle</span>"
    ]
  },
  {
    "objectID": "analytical_lifecycle.html#maintenance-and-continuous-review",
    "href": "analytical_lifecycle.html#maintenance-and-continuous-review",
    "title": "5  Roles and the analytical lifecycle",
    "section": "5.3 Maintenance and continuous review",
    "text": "5.3 Maintenance and continuous review\nThe analytical lifecycle is not a linear process. Where analysis is used on an ongoing basis, all aspects of the lifecycle should be regularly updated. For example, consideration should be made whether\nThe inputs used remain appropriate The initial communication methods remain the best way to deliver the information Any software relied on continues to be supported and up to date The model continues to be calibrated appropriately (this is particularly important for black box models)\nAdditionally, a robust version control process should be in place to ensure any changes to the analysis are appropriately assured.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Roles and the analytical lifecycle</span>"
    ]
  },
  {
    "objectID": "analytical_lifecycle.html#urgent-analysis",
    "href": "analytical_lifecycle.html#urgent-analysis",
    "title": "5  Roles and the analytical lifecycle",
    "section": "5.4 Urgent analysis",
    "text": "5.4 Urgent analysis\nIn some cases there may be a need for urgent analysis that cannot follow all the steps in this guide i.e. where the need for analysis outweighs the risk of poor quality. In this case analysts should follow the Urgent data quality assurance guidance.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Roles and the analytical lifecycle</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html",
    "href": "engagement_and_scoping.html",
    "title": "6  Engagement and scoping",
    "section": "",
    "text": "6.1 Introduction and overview\nThe first stage of the analytical lifecycle is initial engagement and scoping out what the Commissioner requires. This information constrains what is relevant for the analysis. The Analyst works with the Commissioner to develop sufficient understanding of the problem to design a requisite analysis.\nDuring engagement and scoping, the Commissioner and the Analyst shape the analysis by developing a shared understanding of the problem and the context. This shared understanding will be used as the basis for designing analysis that suits the Commissioner’s requirements.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#roles-and-responsibilities-in-the-engagement-and-scoping-stage",
    "href": "engagement_and_scoping.html#roles-and-responsibilities-in-the-engagement-and-scoping-stage",
    "title": "6  Engagement and scoping",
    "section": "6.2 Roles and responsibilities in the engagement and scoping stage",
    "text": "6.2 Roles and responsibilities in the engagement and scoping stage\n\n6.2.1 The Commissioner’s responsibilities during the engagement and scoping stage\nThe Commissioner should:\n\ncommunicate to the Analyst the important aspects of the problem, scope, and programme constraints;\n\nbe available to engage with the Analyst to appropriately shape the work;\nensure that they understand risks where time and resource pressures constrain the approach;\ncommunicate to the Analyst any sources of uncertainty they have identified as part of their wider considerations;\nsign-off on the specification document produced by the analyst; and,\nif possible, indicate the consequences for decision-making of different degrees of uncertainty, as this may enable the Analyst to conduct their analysis at a proportionate level.\n\n\n\n6.2.2 The Analyst’s responsibilities during the engagement and scoping stage\nThe Analyst:\n\nShould engage with the Commissioner to identify the question, the context, and the boundaries of the analysis, as well as constraints (e.g. deadlines, available resource), assumptions, risks, identified uncertainties and business-criticality.\nShould create a specification document which captures the Commissioner’s requirements. It should provide a definition of the scope and project constraints. It should state the acceptable level of risk, the required level of assurance. It may also state the degree of uncertainty allowed for decision-making, and record identified sources of uncertainty. The Analyst should share this specification with the Commissioner for sign-off.\n\n\n\n6.2.3 The Assurer’s responsibilities during the engagement and scoping stage\nThe Assurer may confirm that the engagement process has been sufficient to fully understand the problem. For more business critical projects, they may wish to confirm that the specification document adequately captures the outcomes of the engagement process.\n\n\n6.2.4 The Approver’s responsibilities during the engagement and scoping stage\nThe Approver should note the new project, confirm that resources and plans are in place for the appropriate assurance to take place. For example, they should ensure that the Analyst and Assurer are aware of local assurance protocols. The Approver might provide support in securing a sufficiently qualified and experienced Assurer.\nThe Approver should ensure that there is sufficient governance in place to support the analyst and their role in the wider project or programme. This is particularly important if the analysis supports business critical decisions. This may need to be revisited at the design stage if a novel or riskier approach is required (for example if AI models are used).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#assurance-activities-in-the-engagement-and-scoping-stage",
    "href": "engagement_and_scoping.html#assurance-activities-in-the-engagement-and-scoping-stage",
    "title": "6  Engagement and scoping",
    "section": "6.3 Assurance activities in the engagement and scoping stage",
    "text": "6.3 Assurance activities in the engagement and scoping stage\nThe engagement and scoping stage provides the Analyst with an understanding of the Commissioner’s requirements. In some cases, the Commissioner may present a well-defined problem, while in other instances, the engagement stage may require problem structuring methods. Techniques such as the Strategic Choice Approach, Rich Pictures and Systems Thinking can help the Analyst and Commissioner to reach a joint understanding of the problem (see the Systems Thinking Toolkit for further information). The engagement will lead to the Analyst and Commissioner being able to define the scope of the project in terms of the context and bounds of the analysis. In cases where the engagement and scoping techniques are complex and/or the project is deemed business critical, the Assurer might provide assurance of the engagement methodology (https://publications.tno.nl/publication/100301/Zs2SUz/wijnmalen-2012-natoclient.pdf)\nIn addition to understanding the problem, the engagement and scoping stage should lead to agreement between the Analyst and Commissioner about the outputs to be delivered, including acceptable levels of accuracy, precision and margins of error. This will inform the handling of uncertainty and the assurance thereof in later stages.\nThe Commissioner should communicate to the Analyst what is known about data sources and data quality. This will be used to guide the design of data processing.\nThe Analyst and Commissioner should also clarify risks and potential effects on the outcomes to inform the decisions around proportionate assurance. Constraints around resource and timelines should also be clarified and agreed.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#documentation-in-the-engagement-and-scoping-stage",
    "href": "engagement_and_scoping.html#documentation-in-the-engagement-and-scoping-stage",
    "title": "6  Engagement and scoping",
    "section": "6.4 Documentation in the engagement and scoping stage",
    "text": "6.4 Documentation in the engagement and scoping stage\nThe output of this stage should be a specification document that captures the joint understanding of the task between the Commissioner and Analyst. This document provides a reference for later validation assurance activities (i.e. that the analysis meets the specification). This document also provides evidence for the Approver during the delivery stage that the analysis meets the specification. The document should be signed off by the Commissioner, and might be reviewed by the Assurer.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#treatment-of-uncertainty-in-the-engagement-and-scoping-stage",
    "href": "engagement_and_scoping.html#treatment-of-uncertainty-in-the-engagement-and-scoping-stage",
    "title": "6  Engagement and scoping",
    "section": "6.5 Treatment of uncertainty in the engagement and scoping stage",
    "text": "6.5 Treatment of uncertainty in the engagement and scoping stage\nThe following aspects of the engagement and scoping stage will inform the treatment of uncertainty:\n\nA clear definition of the analytical question\nIdentification of sources of high and/or intractable uncertainty\nEstablishing an understanding of how the analysis will inform decisions\n\nFurther details on Uncertainty in engagement and scoping can be found in the Uncertainty Toolkit",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#black-box-models-and-the-engagement-and-scoping-stage",
    "href": "engagement_and_scoping.html#black-box-models-and-the-engagement-and-scoping-stage",
    "title": "6  Engagement and scoping",
    "section": "6.6 Black box models and the engagement and scoping stage",
    "text": "6.6 Black box models and the engagement and scoping stage\nWhere the Commissioner has engaged with the Analyst to deliver black box models models such as AI/ML, the engagement and scoping stage should include discussions around ethics and risks in order to assess whether such models would be appropriate for addressing the given problem. For example, discussions might include considerations of regulations such as UK GDPR, organisational skills, and internal governance and risk management. For further details see https://www.gov.uk/government/publications/introduction-to-ai-assurance/introduction-to-ai-assurance.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#multi-use-models-and-the-engagement-and-scoping-stage",
    "href": "engagement_and_scoping.html#multi-use-models-and-the-engagement-and-scoping-stage",
    "title": "6  Engagement and scoping",
    "section": "6.7 Multi-use models and the engagement and scoping stage",
    "text": "6.7 Multi-use models and the engagement and scoping stage\nIn the case of multi-use models, the Analyst may be required to engage with a group of end-users to develop an understanding of their respective requirements. As requirements might differ or contradict, techniques such as Strategic Options Development and Analysis (SODA) and [Soft Systems Methodology] (https://en.wikipedia.org/wiki/Soft_systems_methodology) may be used to develop a shared understanding across multiple groups.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "design.html",
    "href": "design.html",
    "title": "7  Design",
    "section": "",
    "text": "7.1 Introduction and overview\nThe design stage is where the Analyst translates the scope for the analysis agreed with the Commissioner into an actionable analytical plan. This chapter sets out recommended practices around designing the analysis and associated assurance activities, documenting the design and assuring the design. It also discusses considerations around the treatment of uncertainty in design, and design of multi-use and AI models.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#introduction-and-overview",
    "href": "design.html#introduction-and-overview",
    "title": "7  Design",
    "section": "",
    "text": "7.1.1 The analytical plan\nThe development of the analytical plan should consider:\n\nMethodology for producing results, including the treatment of uncertainty;\nProject management approach (for example Agile, Waterfall or a combination of approaches);\nSourcing of inputs and assumptions;\nData and file management;\nChange management and version control;\nProgramming language and/or software;\nCode management, documentation and testing;\nCommunication between stakeholders;\nVerification and validation procedures during the project lifetime;\nDocumentation to be delivered;\nProcess for updating the analytical plan;\nProcess for ongoing review and maintenance of models, including reviewing inputs and calibrations and ensuring that software relied on continues to be supported and up to date;\nEthics;\nReporting;\nDownstream application.\n\nThe use of Reproducible Analytical Pipelines (RAP) is encouraged as a means of effective project design.\nIteration between the Commissioner and the Analyst is normal and expected whilst the analytical design develops.\n\n\n\n\n\n\nReproducible analytical pipelines\n\n\n\nThe recommended approach for developing analysis in code is to use a Reproducible Analytical Pipeline (RAP). Reproducible Analytical Pipelines shall:\n\nFollow the practices set out in the Analysis Function Quality Assurance of Code for Analysis and Research manual.\nMeet the requirements of the Reproducible Analytical Pipelines minimum viable product.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#roles-and-responsibilities-in-the-design-stage",
    "href": "design.html#roles-and-responsibilities-in-the-design-stage",
    "title": "7  Design",
    "section": "7.2 Roles and responsibilities in the design stage",
    "text": "7.2 Roles and responsibilities in the design stage\n\n7.2.1 The Commissioner’s responsibilities during the design stage\nThe Commissioner should confirm that the analytical approach will satisfy their needs. To assist in this, the Commissioner may review the analytical plan.\nThe Commissioner’s domain expertise can be a useful resource for the analyst in the design stage. The Commissioner might provide information regarding the input assumptions, data requirements and the most effective ways to present the outputs, all of which can inform the design.\n\n\n7.2.2 The Analyst’s responsibilities during the design stage\nThe Analyst should:\n\ndevelop the method and plan to address the Commissioner’s needs;\nestablish assurance requirements;\ndevelop the plan for proportionate verification and validation - see National Audit Office Framework to review models;\nplan in sufficient time for the assurance activity;\ndocument the analytical plan in a proportionate manner; and,\nfollow any organisation governance procedures for project design.\n\n\n\n7.2.3 The Assurer’s responsibilities during the design stage\nThe Assurer should review the analytical plan to ensure that they are able to conduct the required assurance activities. They may provide feedback on the analytical plan. The Assurer should plan sufficient time for the assurance activity.\n\n\n7.2.4 The Approver’s responsibilities during the design stage\nIn smaller projects, the Approver may not be heavily involved in the design stage. However, for business critical analysis, the Approver may want to confirm that organisational governance procedures for design have been followed.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#assurance-activities-in-the-design-stage",
    "href": "design.html#assurance-activities-in-the-design-stage",
    "title": "7  Design",
    "section": "7.3 Assurance activities in the design stage",
    "text": "7.3 Assurance activities in the design stage\nOn completion of the design stage, the Assurer should be aware of the quality assurance tasks that will be required of them during the project lifetime and have assured the necessary elements of the analytical plan.\nThe assurance of the design stage should consider whether the analytical plan is likely to:\n\nAddress commissioner’s requirements - validation;\nDeliver as intended - verification;\nBe robust i.e. well-structured, data driven, with a sound overall design.\n\nThe assurance of the design stage may be carried out by the Assurer. For more complex analysis, it is good practice to engage subject matter experts to provide independent assurance, and to ensure the accuracy and limitations of the chosen methods are understood, ideally with tests baselining their response against independent reference cases.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#documentation-in-the-design-stage",
    "href": "design.html#documentation-in-the-design-stage",
    "title": "7  Design",
    "section": "7.4 Documentation in the design stage",
    "text": "7.4 Documentation in the design stage\nThe design process should be documented in a proportionate manner. A design document that records the analytical plan should be produced by the Analyst and signed-off by the Commissioner. The design document may be reviewed by the Assurer.\nFor modelling, an initial model map may be produced that describes data flows and transformations. This can be updated as the project progresses through the Analysis stage.\nIt is best practice to use formal version control to track changes in the design document.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#treatment-of-uncertainty-in-the-design-stage",
    "href": "design.html#treatment-of-uncertainty-in-the-design-stage",
    "title": "7  Design",
    "section": "7.5 Treatment of uncertainty in the design stage",
    "text": "7.5 Treatment of uncertainty in the design stage\nDuring the design stage, Analysts should examine the planned analysis systematically for possible sources and types of uncertainty, to maximise the chance of identifying all that are sufficiently large to breach the acceptable margin of error. This is discussed in Chapter 3 of the Uncertainty Toolkit for Analysts",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#black-box-models-and-the-design-stage",
    "href": "design.html#black-box-models-and-the-design-stage",
    "title": "7  Design",
    "section": "7.6 Black box models and the design stage",
    "text": "7.6 Black box models and the design stage\nUsing black box models places greater weight on the design of the analysis and the assurance and validation of outputs by domain experts.\nThis guidance on AI assurance outlines considerations for the design of AI models, including risk assessment, impact assessment, bias audits and compliance audits.\nIn the Design of AI/ML models, the Analyst should:\n\ndefine the situation they wish to model;\nthe prediction they wish to make;\nthe data that could be used to make the prediction;\ncarry out a literature review to identify appropriate modelling, valuation verification methods and document the rationale for selecting their approach;\nconsider how to separate the data for the design and testing of models - it’s usual to design a model with a fraction of the data and then test it with the data that was not used in the design;\nconsider developing automatic checks to identify if the model is behaving unexpectedly, this is important if the model is likely to be used frequently to make regular decisions; and,\nconsider whether to refer the model to their ethics committee, or a similar group - see the Data Ethics Framework.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#multi-use-models-and-the-design-stage",
    "href": "design.html#multi-use-models-and-the-design-stage",
    "title": "7  Design",
    "section": "7.7 Multi-use models and the design stage",
    "text": "7.7 Multi-use models and the design stage\nDesigning multi-use models should take into account the needs of all users of the analysis. An Analysis Steering Group may be an effective means for communication about the design with a range of user groups.\nThe design of multi-use models may entail a modular structure with different Analysts and Assurers responsible for different elements. The design of assurance activities should capture both the assurance of individual modules and their integration.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "8  Analysis",
    "section": "",
    "text": "8.1 Introduction and overview\nThe analysis stage is where planned analysis is undertaken and assured, and progress and relevance are monitored. During this stage, the design may be amended to account for changing circumstances, emerging information or unexpected difficulties or limitations encountered. This stage also includes maintaining appropriate and traceable records of the analysis and assurance activities conducted, changes, decisions and assumptions made. In some cases, changes or limitations encountered may necessitate a return to either the design or scoping stage.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#roles-and-responsibilities-in-the-analysis-stage",
    "href": "analysis.html#roles-and-responsibilities-in-the-analysis-stage",
    "title": "8  Analysis",
    "section": "8.2 Roles and responsibilities in the analysis stage",
    "text": "8.2 Roles and responsibilities in the analysis stage\n\n8.2.1 The Commissioner’s responsibilities during the analysis stage\n\nThe Commissioner should be available to provide input and clarifications to the Analyst.\nThe Commissioner’s should review any changes in design or methodology that the Analyst brings to their attention.\n\n\n\n8.2.2 The Analyst’s responsibilities during the analysis stage\n\nThe Analyst shall follow the conduct the verification and validation activities that were designed as part of the analytical plan in the design stage. They shall provide traceable documentation of the assurance they have undertaken. They shall respond to recommendations from the Assurer and act on them as appropriate.\nWhen the analysis includes coding, the Analyst shall proportionately follow best practice for code development.\nThe Analyst shall produce documentation of the data (see The Government Data Quality Framework) and methods used. The Analyst shall ensure these are sufficient for the Assurer to understand the approach.\nThe Analyst shall document any changes to the analytical plan in a proportionate manner.\nThe Analyst shall maintain appropriate contact with Commissioner and Assurer. This provides and opportunity for them to advise on whether the analysis is still meeting the Commissioner’s needs or whether there are any new requirements.\n\n\n\n8.2.3 The Assurer’s responsibilities during the analysis stage\n\nThe Assurer shall review the assurance completed by the Analyst, carry out any further validation and verification they may see as appropriate, and report errors and areas for improvement to the Analyst. The Assurer may then need to re-review the analytical work completed, as required.\nWhen the analysis includes coding, the Assurer shall review that the work proportionately adheres to best practice for code development.\nThe Assurer may be required to provide feedback on changes to the analytical plan, and consider whether they are qualified to provide rigorous assurance on the revised methodology.\n\n\n\n8.2.4 The Approver’s responsibilities during the analysis stage\nThe Approver should be aware of the progress of the analysis and ensure that they are available for approving the work at the delivery stage.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#assurance-activities-in-the-analysis-stage",
    "href": "analysis.html#assurance-activities-in-the-analysis-stage",
    "title": "8  Analysis",
    "section": "8.3 Assurance activities in the analysis stage",
    "text": "8.3 Assurance activities in the analysis stage\n\n8.3.1 Verification and validation\nVerification that the implemented methodology meets the design requirements should be incorporated as part the analysis. Whitener and Balci (1989) reviewed verification techniques in relation to simulation modelling. These techniques extend to analysis more broadly. These include:\n\nInformal analysis: techniques that rely on human reasoning and subjectivity.\nStatic analysis: tests that the implementation of the analysis before it is run. For example, checking that code adheres to code conventions, structural analysis of the code by examining graphs of control and data flows, .\nDynamic analysis: tests the behaviour of the system, model or code to find errors that arise during execution. This includes unit testing, integration testing and stress testing\nSymbolic analysis: particularly relevant to modelling and tests the transformation of symbolic proxies of model inputs into outputs during the execution of a model. Includes path tracing and cause-effect testing (see Whitener and Balci (1989) )\nConstraint analysis: particularly relevant to modelling and tests the implementation of constraints during model execution. This includes checking the assertions of the model and boundary analysis.\nFormal analysis: tests logical correctness through formal verification such as logic or mathematical proofs.\n\nValidation refers to testing whether the product meets the requirements of users. Hence, it is important to involve the users in the process. Methods for validation include quantification and judgment of acceptable sensitivity, specificity, accuracy, precision and reproducibility.\nValidation of models includes testing the validity of the conceptual model, and testing the operational validity of any computerized model. Techniques that may be useful in validation of models are reviewed by Sargent (2011).\nThe Analyst has primary responsibility for conducting verification and validation. The Assurer is responsible for reviewing the verification and validation that is carried out by the Analyst, and for conducting or recommending additional verification and validation as required. The Assurer may refer to the specification document to assure that the analysis meets the specification.\n\n\n8.3.2 Data validity and data considerations\nTesting data validity (i.e. that data meet the specification for which they are used) is a vital part of analysis. Procedures for assuring data validity include testing for internal consistency, screening for data characteristics (outliers, trends, expected distributions etc), and assuring robust data management practices (e.g. automating data creation and data sourcing).\nIt is rare to have the perfect dataset for an analytical commission. Reasons for this include:\n\nThe data is not available in the time frame required for the ideal analysis;\n\nThe data definition does not perfectly align with the commission;\n\nThere are data or coverage gaps;\n\nThe data may be experimental or there are other reasons why it is not ‘mature’.\n\nOften, no data is available that are directly and precisely relevant to the parameter and conditions of interest. In such cases, it is often possible to use surrogate data. This is measurements of another parameter, or of the parameter of interest under different conditions, that is related to the parameter and conditions of interest. This implies an extrapolation between parameters, or between conditions for the same parameter. The use of surrogate data introduces further uncertainty, additional to that associated with the data itself. It may be possible to quantify this additional uncertainty using expert knowledge of the relationship between the surrogate and the parameter of interest.\nThe effect of using a proxy dataset should be explored and, if the uncertainty associated with the dataset has a large bearing on the analysis, its appropriateness should be revisited. This exploration, and the decision to use a particular dataset or input, should be recorded for the benefit of the Assurer.\n\n\n8.3.3 Assurance of code\nThe Duck Book provides detailed guidance on developing and assurance for delivering quality code. This includes guidance on structuring code, producing documentation, using version control, data management, testing, peer review, and automation. The Analyst shall follow the guidance for good quality code development in a proportionate manner, and the Assurer shall review this accordingly.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#documentation-in-the-analysis-stage",
    "href": "analysis.html#documentation-in-the-analysis-stage",
    "title": "8  Analysis",
    "section": "8.4 Documentation in the analysis stage",
    "text": "8.4 Documentation in the analysis stage\nThe Analyst should:\n\nMaintain appropriate records of the work;\nFully document any code following agreed standards;\nLog the data, assumptions and inputs used in the analysis, and decisions made (see documentation);\nRecord the verification and validation that has been undertaken, documenting any activities that are outstanding and noting what remedial action has been taken and its effect on the analysis;\nProduce user and technical documentation. For modelling, the Analyst may include a model map that describes data flows and transformations.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#treatment-of-uncertainty-in-the-analysis-stage",
    "href": "analysis.html#treatment-of-uncertainty-in-the-analysis-stage",
    "title": "8  Analysis",
    "section": "8.5 Treatment of uncertainty in the analysis stage",
    "text": "8.5 Treatment of uncertainty in the analysis stage\nWhile the Scoping and Design stages identified and described risks and uncertainties, the Analysis stage aims to assess and quantify how uncertainty may influence the analytical outcome and their contribution to the range and likelihoods of possible outcomes. The Uncertainty Toolkit for Analysts reviews methods of quantifying uncertainty. The verification and validation by the Analyst and Assurer should assure the appropriate treatment of uncertainty.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#black-box-models-and-the-analysis-stage",
    "href": "analysis.html#black-box-models-and-the-analysis-stage",
    "title": "8  Analysis",
    "section": "8.6 Black box models and the analysis stage",
    "text": "8.6 Black box models and the analysis stage\nBlack box models such as AI and ML models are not as transparent as traditionally coded models. This adds challenge to the assurance of these models as compared to other forms of analysis.\nAssurance activities during the Analysis stage:\n\nmay include performance testing in a live environment and\nshould include the verification steps set out in the Design Phase\nshould include validation and verification of automatic tests to ensure the model behave as expected See the Introduction to AI Assurance for further details.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#multi-use-models-and-the-analysis-stage",
    "href": "analysis.html#multi-use-models-and-the-analysis-stage",
    "title": "8  Analysis",
    "section": "8.7 Multi-use models and the analysis stage",
    "text": "8.7 Multi-use models and the analysis stage\nIn multi-use models, analysis and edits may be carried out on individual elements of the model at differing times. This calls for mechanisms for assuring that the changes integrate into the larger model as expected, for example, through the use of test-suites.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html",
    "href": "delivery_and_communication.html",
    "title": "9  Delivery, communication and sign-off",
    "section": "",
    "text": "9.1 Introduction and overview\nThe successful delivery of analysis to its Commissioner marks its transition from being a product under development to one that is fit and ready to be used to inform decision making in your organisation and possibly inform the public.\nThis chapter provides information on the processes around assurance of communication of analysis and delivery of analytical output.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#roles-and-responsibilities-in-delivery-communication-and-sign-off",
    "href": "delivery_and_communication.html#roles-and-responsibilities-in-delivery-communication-and-sign-off",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.2 Roles and responsibilities in delivery, communication and sign-off",
    "text": "9.2 Roles and responsibilities in delivery, communication and sign-off\n\n9.2.1 The Commissioner’s responsibilities during delivery, communication and sign-off\nThe Commissioner shall * confirm that the analysis is likely to meet their needs; * use the analysis as specified; and, * understand and apply any limitations to its use.\n\n\n9.2.2 The Analyst’s responsibilities during delivery, communication and sign-off\nThe Analyst - shall follow organisational governance procedures for delivery and sign-off, including, where appropriate, updating the business-critical analysis register, and making the analysis publicly available; - shall decribe any limitations to using the analysis; - should ensure that communication meets audience requirements e.g. on accessibility; - should be prepared to respond to challenge from the Approver e.g. scruitiny from project or programme boards; - may be required to communicate the assurance state to the Approver, if not done directly by the Assurer.\n\n\n9.2.3 The Assurer’s responsibilities during delivery, communication and sign-off\nThe Assurer shall communicate the assurance state to the Approver. This includes confirmation that the work has been appropriately scoped, executed, validated, verified, documented, and provides adequate handling of uncertainty. This communication may go via the Analyst.\n\n\n9.2.4 The Approver’s responsibilities during delivery, communication and sign-off\n\nThe Approver shall review the assurance evidence that has been provided to them.\nThe Approver should provide sufficient challenge to the analysts to gain assurance that the analysis is fit for purpose.\nThe Approver shall be confident that the analysis meets the design requirements, is of sufficient quality and is adequately and proportionately documented.\nWhen they are satisfied with the validity and robustness of the analysis, the Approver should provide the Analyst with evidence that the analysis outputs have been properly reviewed and formally approved.\nThe Approver shall follow organisation governance procedures for sign-off, including updating of the business-critical analysis register, where appropriate.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#assurance-activities-in-the-delivery-communication-and-sign-off-stage",
    "href": "delivery_and_communication.html#assurance-activities-in-the-delivery-communication-and-sign-off-stage",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.3 Assurance activities in the delivery, communication and sign-off stage",
    "text": "9.3 Assurance activities in the delivery, communication and sign-off stage\n\n9.3.1 Delivery\nWhen delivering a piece of analysis, the Analyst and/or Assurer should communicate its assurance state to the Approver and provide evidence that the analysis and associated outputs have undergone proportionate quality assurance and to demonstrate that the analysis is ready for delivery, for example:\n\nIt uses suitable data and assumptions;\n\nIt has provisions for regular review;\nIt meets the purpose of its commission;\n\nIt has been carried out correctly and to its agreed specification;\n\nIt has a risk assessment and statement against the programme risk register;\nIt meets analytical standards, such as those around coding standards and documentation;\nIt adheres to any professional codes of practice (e.g. The Code of Practice for Statistics\nWhere appropriate the analysis is accompanied by a completed assurance statement.\n\nThough not strictly assurance, the analyst should also consider areas such as security ratings, retention policies, intellectual property, ethics and related concerns.\nThe Approver should scrutinise the evidence delivered and approve the work if the analysis meets the required standard, which considers the proportionality of the work. The Approver should then feedback the outcome of any approval activities to the analyst so that the analysis can be updated if required.\nThe exact nature of any scrutiny made by the Approver should be proportionate to the effect the analysis is likely to have, the governance process of their programme/ organisation, and follow the principles of proportionality described in Chapter 3 of this document.\nTo ensure that the analysis is used as intended, the Commissioner should use the analysis as specified at the start of the analytical cycle, applying any limitations to its use as described by the Analyst.\n\n\n9.3.2 Communication\nThe effective and transparent communication is essential to enable analysis to be adopted and trusted by the Commissioner and onward users. Depending on its final use and likelihood of publication, any analysis may be communicated to a wide audience including:\n\nCommissioners and users of the analysis;\n\nExternal scrutiny including the Public Accounts Committee, the National Audit Office, internal and external audit;\n\nThe public, through publications and Freedom of Information Act requests;\n\nAcademic experts, possibly through a departmental Areas of Research Interest document.\nGovernmental partners - both national and international\n\nThe form of communication should be tailored to the audience. The communication should be quality assured in a proportionate manner to ensure an accurate reflection of the analytical results.\nThe Analysis Function’s Making Analytical Publications Accessible Toolkit gives guidance to help ensure that any that websites, tools, and technologies produced from analysis are designed and developed so that people with disabilities can use them. More specifically, people can: perceive, understand, navigate, and interact with the web.\nIf publishing the outcome of any analysis is required, the Analyst should follow departmental and statutory guidance. Some examples are given below:\n\nIf you are publishing statistics you will need to follow your organisation’s guidance and the regulatory guidance for publishing official statistics and national statistics ;\n\nIf you are publishing research, you shall follow your organisations guidance and the Government Social Research Publication protocol;\n\nIf you are publishing an evaluation, refer to any recommendations from the Evaluation Task Force;\n\n\n\n9.3.3 Sign-off\nThe exact nature of the approval process may vary depending on:\n\nThe effect the analysis is likely to have;\n\nThe approval process of the organisation, and\n\nThe nature of the programme, project or board approving the analysis.\n\nThe formality of the sign-off process should be governed by organisational procedures, and be proportionate to the analysis.\nThe Approver should provide the Analyst with evidence that the analysis outputs have been properly reviewed and formally approved. For example, through the notes of a project / programme board where the decision to approve the analysis was made or similar.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#documentation-in-the-delivery-communication-and-sign-off-stage",
    "href": "delivery_and_communication.html#documentation-in-the-delivery-communication-and-sign-off-stage",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.4 Documentation in the delivery, communication and sign-off stage",
    "text": "9.4 Documentation in the delivery, communication and sign-off stage\nWhen the Analyst and Assurer are satisfied that the analysis is ready to hand over to the Commissioner, they should ensure that any associated documentation supporting the analysis is ready and has also undergone quality assurance. Supporting documentation may include:\n\nSpecification and design documentation\nLogs of data, assumptions and decisions including their source, ownership, reliability and any sensitivity analysis carried out;\nUser and technical documentation\nAdvice on uncertainty and its affect on the outputs of the analysis;\n\nA description of the limits of the analysis and what it can and cannot be used for;\n\nAny materials for presenting the analysis to the Commissioner, for example slide decks or reports;\n\nA record of the analysis including methods used, dependencies, process maps, change and version control logs and error reporting;\n\nThe code-base, when it has been agreed to publish the analysis openly\nThe test plan and results of the tests made against that plan;\n\nA statement of assurance;\n\nA statement that ethical concerns have been addressed, especially in cases that include the application of black-box models;",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#treatment-of-uncertainty-in-the-delivery-communication-and-sign-off-stage",
    "href": "delivery_and_communication.html#treatment-of-uncertainty-in-the-delivery-communication-and-sign-off-stage",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.5 Treatment of uncertainty in the delivery, communication and sign-off stage",
    "text": "9.5 Treatment of uncertainty in the delivery, communication and sign-off stage\nGovernment has produced a range of guidance to support analysts in presenting and communicating uncertainty in analysis. This includes:\n\nThe Office for Statistical Regulation’s Approaches to presenting uncertainty in the statistical system;\nThe Uncertainty Toolkit for Analysts;\n\nThe Government Analysis Function guidance note Communicating quality, uncertainty and change;\n\nEach provides valuable advice on how to estimate and present uncertainty when describing the limitations of use of a piece of analysis.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#black-box-models-and-the-delivery-communication-and-sign-off-stage",
    "href": "delivery_and_communication.html#black-box-models-and-the-delivery-communication-and-sign-off-stage",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.6 Black-box models and the delivery, communication and sign-off stage",
    "text": "9.6 Black-box models and the delivery, communication and sign-off stage\nThe Approver is responsible for signing-off that all risks and ethical considerations around the use of black-box models have been addressed. This may include * formal consultation and approval by an ethics committee or similar * provisions for regular review * communicating the “health” of the model at regular intervals to the commissioner i.e. is it continuing to behave as expected The aspects to be considered are detailed in the Introduction to AI assurance.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#multi-use-models-and-the-delivery-communication-and-sign-off-stage",
    "href": "delivery_and_communication.html#multi-use-models-and-the-delivery-communication-and-sign-off-stage",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.7 Multi-use models and the delivery, communication and sign-off stage",
    "text": "9.7 Multi-use models and the delivery, communication and sign-off stage\nThere is a greater risk that multi-use models may be used for purposes outside the intended scope. This places a greater onus on the Analyst to clearly communicate to all users the limitations and intended use. The Analyst may consider testing communication with different user groups to ensure that the analytical outputs are used as intended.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#analytical-transparency",
    "href": "delivery_and_communication.html#analytical-transparency",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.8 Analytical transparency",
    "text": "9.8 Analytical transparency\nEnabling the public to understand and scrutinise analysis promotes public confidence in decisions. This includes providing the public with information on models used for business-critical decisions and making analysis open. Further guidance on transparency can be found here.\n\n9.8.1 Business-critical analysis register\nThis section applies to publishing lists of business critical analysis (BCA), including models.\n\nDepartments and Arm’s Length Bodies1 (ALBs) should publish a list of BCA in use within their organisations at least annually.\nEach department and ALB should decide what is defined as business critical based on the extent to which they influence significant financial and funding decisions; are necessary to the achievement of a departmental business plan, or where an error could lead to serious financial, legal or reputational damage.\nDepartments and ALBs should align their definitions and thresholds of business criticality with their own risk framework respectively. The thresholds should be agreed by the Director of Analysis or equivalent.\nALB’s are responsible for publishing their own BCA list, unless agreed otherwise with the department. The ALB’s Accounting Officer is accountable for ensuring publication and the sponsor department’s AO oversees this.\nThe BCA lists should include all business-critical analysis unless there is an internally documented reason that the analysis should be excluded, agreed with the Director of Analysis (or equivalent) and the agreement documented.\nJustification for not publishing a model in the list may include exemptions under the Freedom of Information (FOI) Act 2000 where relevant, for example, including, but not limited to: National Security, policy under development or prejudicing commercial interests.\nIn addition to these exemptions, there may be further reasons where the risk of negative consequence is deemed to outweigh the potential benefits resulting from publication of the model. One example is where population behaviour may change in response to awareness of a model or modelling.\nFor clarity, the name of model/analysis and what it is used for should be included, alongside links to published material.\nTo ensure the list is accessible, content and structure should follow guidance for writing plainly\n\n\n\n9.8.2 Open publishing of analysis\nTo facilitate public scrutiny, departments may choose to make analysis/models (e.g. source code or spreadsheets) and details which may include data, assumptions, methodology and outputs open to the public. Open publishing source code and other elements of analysis allows others to reuse and build on the work (https://www.gov.uk/service-manual/service-standard/point-12-make-new-source-code-open). Practical guidance to open coding can be found here.\nPublication of analysis should also draw on the guidance for BCA lists related to accessibility and justification for when publication may not be appropriate. For analysis that is extremely complex in nature, it may be more appropriate to publish summary information instead, to aid the accessibility.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#footnotes",
    "href": "delivery_and_communication.html#footnotes",
    "title": "9  Delivery, communication and sign-off",
    "section": "",
    "text": "ALBs include executive agencies, non-departmental public bodies and non-ministerial departments, please see Cabinet Office guidance on Classification of Public Bodies↩︎",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "resources.html",
    "href": "resources.html",
    "title": "10  Resources",
    "section": "",
    "text": "10.1 Written resources\nThe key additional resources referred to within the AQuA Book are collated here for easy reference.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#written-resources",
    "href": "resources.html#written-resources",
    "title": "10  Resources",
    "section": "",
    "text": "The Analysis Function Standard\nThe Green Book\nThe Magenta Book\nThe Orange Book\n\n\n10.1.1 Guidance and advice for performing analysis\n\nUncertainty Toolkit for Analysts in Government provides support for handling uncertainty in analysis.\n\nAdvice for policy professionals using statistics and analysis aims to help policy professionals work effectively with statisticians and other analysts. It introduces some important statistical ideas and concepts to help policy professionals ask the right questions when working with statistical evidence.\n\nThe Data Ethics Framework guides appropriate and responsible data use in government and the wider public sector. It helps public servants understand ethical considerations, address these within their projects, and encourages responsible innovation.\n\nThe Government Data Quality Framework supports the production of sustainable high quality data.\n\nThe Reproducible Analytical Pipelines guidance sets out what a Reproducible Analytical Pipeline is and points to resources for analysts who need to build them.\n\n\n\n10.1.2 Guidance and advice for performing assurance\n\nThe National Audit Office Framework to review models provides a structured approach to review models which organisations can use to determine whether the modelling outputs they produce are reasonable, robust and have a minimal likelihood of errors being made;\nDepartment for Energy Security and Net Zero modelling tools and QA guidance provides resources to help quality assure new and existing models, including those developed by third parties;\n\nIntroduction to AI assurance outlines considerations for the design and assurance of AI models, including risk assessment, bias audits and considering the ongoing ‘health’ of the model.\nThe Duck Book provides guidance on assuring code.\n\n\n\n10.1.3 Guidance and advice for communicating analysis\n\nThe Office for Statistical Regulation’s Approaches to presenting uncertainty in the statistical system;\n\nThe Government Analysis Function guidance note Communicating quality, uncertainty and change;\n\nThe Analysis Function’s Making Analytical Publications Accessible Toolkit gives guidance to help ensure that any that websites, tools, and technologies produced from analysis are designed and developed so that people with disabilities can use them. More specifically, people can: perceive, understand, navigate, and interact with the web.\nIf you are publishing statistics you shall follow your organisation’s guidance and the regulatory guidance for publishing official statistics and national statistics;\n\nIf you are publishing research, you shall follow your organisations guidance and the Government Social Research Publication protocol;\n\nIf you are publishing an evaluation, refer to any recommendations from the Evaluation Task Force;",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "resources.html#external-sources-of-quality-assurance",
    "href": "resources.html#external-sources-of-quality-assurance",
    "title": "10  Resources",
    "section": "10.2 External sources of quality assurance",
    "text": "10.2 External sources of quality assurance\nThe Government Actuary’s Department (GAD) can provide expert quality assurance reviews of models across the public sector. GAD are a team of financial risk professionals and are experts in reviewing models on all modern platforms, including Excel, R, and Python. As a non-ministerial department, GAD can offer unique support from within government.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Resources</span>"
    ]
  },
  {
    "objectID": "improving_the_book.html",
    "href": "improving_the_book.html",
    "title": "Improving the book",
    "section": "",
    "text": "Important\n\n\n\nThis version of the AQuA book is a preliminary ALPHA draft. It is still in development, and we are still working to ensure that it meets user needs. At this stage, the site does not fully incorporate requirements from accessibility legislation.\nThe draft currently has no official status. It is a work in progress and is subject to further revision and reconfiguration (possibly substantial change) before it is finalised.\n\n\n\nAccessibility\nThe AQuA Book, when final, will comply with the www.gov.uk accessibility statement. Compliance does not extend to third-party content outside the www.gov.uk domain that is referenced from the guidance.\n\n\nHelp us improve this book\nWe are always looking to improve our guidance. If you have comments or suggestions about the content of the AQuA Book or suggestions for how it might be improved, you can contact us by emailing AQUA Book.",
    "crumbs": [
      "Improving the book"
    ]
  }
]