[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The AQuA Book",
    "section": "",
    "text": "Important\n\n\n\nThis version of the AQuA book is a preliminary ALPHA draft. It is still in development, and we are still working to ensure that it meets user needs.\nThe draft currently has no official status. It is a work in progress and is subject to further revision and reconfiguration (possibly substantial change) before it is finalised.\n\n\n\nPreface\nPlaceholder text",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "forward.html",
    "href": "forward.html",
    "title": "Foreword",
    "section": "",
    "text": "Important\n\n\n\nThis version of the AQuA book is a preliminary ALPHA draft. It is still in development, and we are still working to ensure that it meets user needs.\nThe draft currently has no official status. It is a work in progress and is subject to further revision and reconfiguration (possibly substantial change) before it is finalised.\n\n\nPlaceholder text",
    "crumbs": [
      "Foreword"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Who is the AQuA Book for?\nIn this edition we have tried to make our guidance relevant to anyone who commissions, uses, undertakes or assures analysis. It is about the whole process of producing analysis that is fit for purpose and not just about the checks after the analysis has been completed.\nWe would like to see producers and users of analysis from all backgrounds using this book, especially those producing analysis, evidence and research to support decision making in government. Our intended audience includes:",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#who-is-the-aqua-book-for",
    "href": "intro.html#who-is-the-aqua-book-for",
    "title": "1  Introduction",
    "section": "",
    "text": "Users of analysis – helping you to get the most out of your commission;\nThose who carry out analysis such as members of the government analytical professions, including:\n\noperational researchers, statisticians and economists;\ngeographers;\nfinance professionals making spending forecasts;\nactuaries;\nsocial researchers carrying out qualitative research;\ndata scientists developing advanced analytics;\nand anyone else carrying out analysis.\n\nSenior leaders with an interest in analytical assurance.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#why-should-i-pay-attention-to-this-guidance",
    "href": "intro.html#why-should-i-pay-attention-to-this-guidance",
    "title": "1  Introduction",
    "section": "1.2 Why should I pay attention to this guidance?",
    "text": "1.2 Why should I pay attention to this guidance?\nHere are a few reasons why.\n\nYour analytical insights will be used for major decisions and operations. You need to do your best to get them right, thus minimising the risk of being complicit in causing operational, business or reputational damage;\nTrust is hard to obtain but easy to lose. A simple error that could have been prevented by assurance could lead to your and your team’s work being doubted;\nPrevention is better than cure. Analysis is more likely to be right first time when you consider quality from the start. Having appropriate quality assurance in place helps to manage mistakes, handle changes to requirements and ensure appropriate re-use;\nDelivering quality analysis provides the confidence that is needed for transparency and public openness;\nAssurance is required for audit purposes2; and\n\nProfessional pride in your work.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#how-to-use-this-book",
    "href": "intro.html#how-to-use-this-book",
    "title": "1  Introduction",
    "section": "1.3 How to use this book",
    "text": "1.3 How to use this book\nThe first four chapters of this book cover definitions and overarching themes, whilst the second half of the book goes into more detail on the analytical life cycle. Each chapter in the second half of the book is structured as follows: * Introduction and overview * Roles and responsibilities, * Assurance activities, * Documentation * Uncertainty, * Black box models * Multi-use models * Any other elements specific to the stage of the life cycle\nThis guidance uses the following terms to indicate whether recommendations are mandatory or advisory.\nThe terms are:\n\n‘shall’ denotes a requirement, a mandatory element, which applies in all circumstances, at all times\n‘should’ denotes a recommendation, an advisory element, to be met on a ‘comply or explain’ basis\n‘may’ denotes approval\n‘might’ denotes a possibility\n‘can’ denotes both capability and possibility\nis/are is used for a description\n\nThese are the same terms as those in the UK Government Functional Standards.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "Black box: system which can be viewed in terms of its inputs and outputs (or transfer characteristics), without any knowledge of its internal workings.↩︎\nManaging Public Money, Annex 4.2 Use of models↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html",
    "href": "definitions_and_key_concepts.html",
    "title": "2  Definitions and key concepts",
    "section": "",
    "text": "Analysis\nAnalysis is the collection, manipulation and interpretation of information and data for use in decision making. Analysis can vary widely between situations and many different types of analysis may be used to form the evidence base that supports the decision-making process.\nExamples of types of analysis that are frequently encountered in government are:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#analysis",
    "href": "definitions_and_key_concepts.html#analysis",
    "title": "2  Definitions and key concepts",
    "section": "",
    "text": "actuarial\n\ndata science\neconomic\nfinancial\n\ngeographical\noperational research\nscientific, technical and engineering research\n\nstatistical\n\nsocial research",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#assurance",
    "href": "definitions_and_key_concepts.html#assurance",
    "title": "2  Definitions and key concepts",
    "section": "Assurance",
    "text": "Assurance\nAnalytical assurance is the process and set of practices to ensure that the analysis is fit for purpose.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#assurance-activities",
    "href": "definitions_and_key_concepts.html#assurance-activities",
    "title": "2  Definitions and key concepts",
    "section": "Assurance activities",
    "text": "Assurance activities\nAssurance activities are any actions carried out in order to validate and verify analysis.\nFor example:\n\nanalyst testing\n\npeer review\n\nreconciliation of results to independent sources",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#artificial-intelligence",
    "href": "definitions_and_key_concepts.html#artificial-intelligence",
    "title": "2  Definitions and key concepts",
    "section": "Artificial Intelligence",
    "text": "Artificial Intelligence\nArtificial intelligence (AI) attempts to simulate human intelligence using techniques and methods such as machine learning, natural language processing, and robotics. AI aims to perform tasks that typically require human intelligence, such as problem-solving, decision-making, and language understanding. Artificial Intelligence models are a subset of black box models",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#black-box-models",
    "href": "definitions_and_key_concepts.html#black-box-models",
    "title": "2  Definitions and key concepts",
    "section": "Black box models",
    "text": "Black box models\nBlack box models internal workings are not visible or easily understood. These models take input and produce output without providing clarity about the process used to arrive at the output. Artificial Intelligence models (including Machine Learning) are the most common type of black box models used today. Other forms of black box models may arise in future.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#business-critical-analysis",
    "href": "definitions_and_key_concepts.html#business-critical-analysis",
    "title": "2  Definitions and key concepts",
    "section": "Business critical analysis",
    "text": "Business critical analysis\nBusiness critical analysis is analysis which plays such a role in decision making that it influences significant financial and funding decisions, is necessary to the achievement of a Departmental business plan, or where an error could have a significant reputational, economic or legal impact for the public sector.\nThe first edition of the AQuA book described business critical models. This has been generalised to business critical analysis, as it is possible for analysis to be business critical without including a model. Some departments may continue to use the term business critical models (BCM).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#change-control",
    "href": "definitions_and_key_concepts.html#change-control",
    "title": "2  Definitions and key concepts",
    "section": "Change control",
    "text": "Change control\nChange control is the set of processes followed when changes are made to a piece of analysis. For example, authorising and accepting changes, version numbering, documentation, assurance of changes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#documentation",
    "href": "definitions_and_key_concepts.html#documentation",
    "title": "2  Definitions and key concepts",
    "section": "Documentation",
    "text": "Documentation\n\nSpecification documentation\nSpecifications capture initial engagements with the commissioner. They describe the question, the context, and any boundaries of the analysis. This provides a definition of the scope and a mechanism for agreeing project constraints such as deadlines, available resources, and capturing what level of assurance is required by the commissioner.\n\n\nDesign documentation\nDesign documents describe the analytical plan, including the methodology, inputs, and software. They also contain details of the planned verification and validation of the analysis. They provide a basis for the Analytical Assurer to verify whether the analysis meets the specified requirements. For more information on the design documentation, see the Design chapter.\n\n\nAssumptions log\nA register of assumptions, whether provided by the Commissioner or derived by the analysis, that have been risk assessed and signed off by an appropriate governance group or stakeholder. Assumption logs should describe each assumption, quantify its impact and reliability and set out when it was made, why it was made, who made it and who signed it off.\n\n\nDecisions log\nA register of decisions, whether provided by the Commissioner or derived by the analysis. Decisions logs should describe each decision and set out when it was made, why it was made, who made it and who signed it off.\n\n\nData log\nA register of data provided by the Commissioner or derived by the analysis that has been risked assessed and signed-off by an appropriate governance group or stakeholder.\n\n\nUser / technical documentation\nAll analysis shall have user-documentation, even if the user is only the analyst leading the analysis. This is to ensure that they have captured sufficient material to assist them if the analysis is revisited in due course. For analysis that is likely to be revisited or updated in the future, documentation should be provided to assist a future analyst and should be more comprehensive. This documentation should include a summary of the analysis including the context to the question being asked, what analytical methods were considered, what analysis was planned and why, what challenges were encountered and how they were overcome and what verification and validation steps were performed. In addition, guidance on what should be considered if the analysis is to be revisited or updated is beneficial.\n\n\nAssurance statement\nA brief description of the analytical assurance that have been performed to assure the analysis. The statement should refer to known limitations and conditions associated with the analysis.\n\n\n\n\n\n\nExample of publishing quality assurance tools\n\n\n\nThe Department for Energy Security and Net Zero and Department for Business and Trade have published a range of quality assurance tools and guidance to help people with Quality Assurance of analytical models. Modelling Quality Assurance tools and guidance are used across the two departments to ensureanalysis meets the standards set out in the AQuA book and provide assurance to users of the analysis that proportionate quality assurance has been completed.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#materiality",
    "href": "definitions_and_key_concepts.html#materiality",
    "title": "2  Definitions and key concepts",
    "section": "Materiality",
    "text": "Materiality\nMateriality is a concept or convention in auditing and accounting relating to the importance of a feature. Information is said to be material if omitting it or misstating it could influence decisions that users make. Materiality is “an entity-specific aspect of relevance, based on size, magnitude or both”.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#multi-use-models",
    "href": "definitions_and_key_concepts.html#multi-use-models",
    "title": "2  Definitions and key concepts",
    "section": "Multi-use models",
    "text": "Multi-use models\nSome models, often complex and large, are used by more than one user or group of users for related but differing purposes, these are known as multi-use models.\nOften, a Steering Group is created to oversee the analysis. This Steering Group would be chaired by the senior officer in charge of the area that maintains the model, and contain senior, ideally empowered, representatives of each major user area.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#principles-of-analytical-quality-assurance",
    "href": "definitions_and_key_concepts.html#principles-of-analytical-quality-assurance",
    "title": "2  Definitions and key concepts",
    "section": "Principles of analytical quality assurance",
    "text": "Principles of analytical quality assurance\nNo single piece of guidance provides a definitive assessment of whether a piece of analysis is of sufficient quality for an intended purpose. However, the following principles support commissioning and production of fit-for-purpose analysis:\nProportionate: Quality assurance effort should be appropriate to the risk associated with the intended use of the analysis and the complexity of the analytical approach. These risks include financial, legal, operational and reputational impacts. More details can be found in chapter [3]\nAssurance throughout development: Quality assurance should be considered throughout the life cycle of the analysis and not just at the end. Effective communication is crucial when understanding the problem, designing the analytical approach, conducting the analysis and relaying the outputs. More details on the analysis life cycle can be seen in chapter [5].\nVerification and validation: Analytical quality assurance is more than checking that the analysis is error-free and satisfies its specification (verification). It should also include checks that the analysis is appropriate, i.e. fit for the purpose for which it is being used (validation). Validation and verification are covered in more depth in chapters [5-9].\nAccept that uncertainty is inherent in the inputs and outputs of any piece of analysis. Chapter [8] covers assurance of the analytical phase of the project, including the treatment of uncertainty . Further support can be found in the Uncertainty Toolkit for Analysts in Government (analystsuncertaintytoolkit.github.io)\nAnalysis with RIGOUR: One acronym some users find helpful to consider when completing analysis is RIGOUR. This is described in the box below.\n\n\n\n\n\n\nRIGOUR\n\n\n\n\n\nThroughout all the stages of an analytical project, the analyst should ask questions of their own analysis. The helpful mnemonic “RIGOUR” may assist:\n\nRepeatable\nIndependent\nGrounded in reality\nObjective\nUncertainty-managed\nRobust\n\nRepeatable: For an analytical process to be considered valid we might reasonably expect that the analysis produces the same outputs for the same inputs and constraints. Different analysts might approach the analytical problem in different ways, while methods might include randomised processes. In such cases, exact matches are not guaranteed or expected. Taking this into account, repeatability means that if an approach is repeated the results should be as expected.\nIndependent: Analysis should be free of prejudice or bias. Care should be taken to balance views appropriately across all stakeholders and experts.\nGrounded in reality: Quality analysis takes the Commissioner and Analyst on a journey as views and perceptions are challenged and connections are made between the analysis and its real consequences. Connecting with reality like this guards against failing to properly grasp the context of the problem that is being analysed.\nObjective: Effective engagement and suitable challenge reduce the risk of bias and enables the Commissioner and the Analyst to be clear about the interpretation of results.\nUncertainty-managed: Uncertainty is identified, managed and communicated throughout the analytical process.\nRobust: Analytical results are error free in the context of residual uncertainty and accepted limitations that make sure the analysis is used appropriately.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#quality-analysis",
    "href": "definitions_and_key_concepts.html#quality-analysis",
    "title": "2  Definitions and key concepts",
    "section": "Quality analysis",
    "text": "Quality analysis\nQuality analysis is analysis which is fit for the purpose(s) it was commissioned to meet. It should be accurate, have undergone appropriate assurance, be evidenced, proportionate to its impact, adequately communicated, documented and accepted by its commissioners.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#reproducible-analytical-pipelines",
    "href": "definitions_and_key_concepts.html#reproducible-analytical-pipelines",
    "title": "2  Definitions and key concepts",
    "section": "Reproducible analytical pipelines",
    "text": "Reproducible analytical pipelines\nReproducible Analytical Pipelines (RAPs) are automated analytical processes. They incorporate elements of software engineering best practice to ensure that the pipelines are reproducible, auditable, efficient, and high quality.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#roles-and-responsibilities",
    "href": "definitions_and_key_concepts.html#roles-and-responsibilities",
    "title": "2  Definitions and key concepts",
    "section": "Roles and responsibilities",
    "text": "Roles and responsibilities\nThe AQuA book defines the following roles:\n\nCommissioner\nAnalyst\n\nAssurer\nApprover\n\nSee Roles and Responsibilities for details.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#third-party",
    "href": "definitions_and_key_concepts.html#third-party",
    "title": "2  Definitions and key concepts",
    "section": "2.1 Third party",
    "text": "2.1 Third party\nAny individual, or group of individuals that is not a member of the same group as the those commissioning analysis. E.g. working for a different government department, a different function or an outside company.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#uncertainty",
    "href": "definitions_and_key_concepts.html#uncertainty",
    "title": "2  Definitions and key concepts",
    "section": "Uncertainty",
    "text": "Uncertainty\nThe outcome of a decision is never known perfectly in advance. For each option within analysis, a range of real outcomes is possible: the outcome is uncertain.\n\n\n\n\n\n\nDefining uncertainty\n\n\n\nWikipedia defines uncertainty as referring to epistemic situations involving imperfect or unknown information. It applies to predictions of future events, to physical measurements that are already made, or to the unknown.\n\n\nThere are different types of uncertainty. A common classification divides uncertainty into known knowns, known unknowns, and unknown unknowns. The type of uncertainty will impact the analytical approach and assurance activities required.\nThe Uncertainty Toolkit for Analysts in Government is a tool produced by a cross government group to help assessing and communicating uncertainty.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#validation",
    "href": "definitions_and_key_concepts.html#validation",
    "title": "2  Definitions and key concepts",
    "section": "Validation ",
    "text": "Validation \nEnsuring the analysis meets the needs of its intended users and the intended use environment. See Glover (2014) for more information.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#verification",
    "href": "definitions_and_key_concepts.html#verification",
    "title": "2  Definitions and key concepts",
    "section": "Verification",
    "text": "Verification\nEnsuring the analysis meets it specified design requirements. See Glover (2014) for more information.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#version-control",
    "href": "definitions_and_key_concepts.html#version-control",
    "title": "2  Definitions and key concepts",
    "section": "Version control",
    "text": "Version control\nIt is important to ensure that changes that have been made to analysis can be easily seen and quality assured by the analytical assurer, and the latest version of the analysis is being used. Tools and templates can be used to support with evidencing updates and the checks completed throughout a project providing a log of changes that have occurred, why, when, and by whom.\n\n\n\n\nGlover, Paul. 2014. Verification and Validation for the AQuA Book. DSTL Portsdown West Portsdown Hill Road Fareham PO17 6AD: HM Government. https://www.gov.uk/government/publications/verification-and-validation-for-the-aqua-book.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "proportionality.html",
    "href": "proportionality.html",
    "title": "3  Proportionality",
    "section": "",
    "text": "3.1 Introduction\nThink about and deliver appropriate (proportionate) levels of assurance for your analysis. There is a need to be confident in analysis delivered, but there is no point spending months assuring simple analysis that will inform a decision that will make minimal impact.\nTable 3-1 provides a list of key factors that should be considered when determining what level of assurance is appropriate.\nFurther detail and considerations may be found on the Data Quality Hub’s Quality Questions and Red Flags page.\nFigure 3-1 shows some assurance techniques that might be considered for different levels of analysis complexity and business risk. The key message is the need for more assurance interventions increases with the complexity of, and the business risk associated with analysis.\nThe interventions in Figure 3-1 must not be viewed in isolation. The interventions should build on each other, for example some complex and risky analysis that would benefit from an external review should also use interventions closer to the axes, for example version control and analyst led testing.\nThe total elimination of risk will never be achievable, so a balance needs to be found that reduces the overall business risk to an acceptable level. The diagram indicates a few practical assurance techniques. In practice there are many different techniques that need to be considered and implemented as appropriate.\nMany of these interventions are mentioned elsewhere in the AQUA Book, and are not repeated here.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "proportionality.html#introduction",
    "href": "proportionality.html#introduction",
    "title": "3  Proportionality",
    "section": "",
    "text": "Table 3-1 - Factors for determining appropriate assurance\n\n\n\n\n\n\nFactor\nComments\n\n\n\n\nBusiness criticality\nDifferent issues will impact on business criticality such as financial, legal, operational, political and reputational impacts.\n\n\nRelevance of the analysis to the decision making process\nWhen analysis forms only one component of a broad evidence base, less assurance is required for that specific analysis than if the decision is heavily dependent on the analysis alone. Significant assurance is still likely to be required for the evidence base.\n\n\nType and complexity of analysis\nHighly complex analysis requires more effort to assure. The nature of that analysis may also require the engagement of appropriate subject matter experts.\n\n\nNovelty of approach\nA previously untried method requires more assurance. Confidence will grow as the technique is repeatedly tested.\n\n\nReusing or repurposing existing work\nReusing work that was carried out previously may require validation and verification to confirm that original apporach - method, assumptions data etc. are still appropropriate for the new requirement\n\n\nPrecision of the analysis outputs\nImprecise analysis can require different assurance than precise analysis, e.g. because of inherent limitations of the analytical technique, or lack of data on assumptions.\n\n\nAmount of resource available for the analysis and assurance\nThe value for money of any additional assurance must be balanced alongside the benefits and risk appetite that exists.Analysis that is used for many purposes (e.g. population projections) may require greater levels of QA than might be suggested by any individual decision they support.\n\n\nLongevity of the analysis\nOngoing analysis will require robust change control.\n\n\nPublic impact\nAnalysis which will have a significant impact on the public may require more assurance than it otherwise would.\n\n\nRepeat runs for the same analysis\nThe focus for repeat analysis will be on version control and assurance of data and parameters for each run.\n\n\n\n\n\n\n\nFigure 3-1 - Types of quality assurance",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "proportionality.html#structured-assessment-of-business-risk-and-complexity",
    "href": "proportionality.html#structured-assessment-of-business-risk-and-complexity",
    "title": "3  Proportionality",
    "section": "3.2 Structured assessment of business risk and complexity",
    "text": "3.2 Structured assessment of business risk and complexity\nTo guide what assurance is needed it is necessary to take a structured approach when reviewing business risks. Business risk should be viewed as the combination of the potential impact of analysis errors, and the likelihood of errors occurring. In situations where the potential business impact is high, it is more important that the likelihood of errors is reduced.\nThis can be visualised by considering the situation as a risk matrix, illustrated in Table 3-2. The impact of the analysis will usually be beyond the control of the analyst to change, so there will be few options to move an assessment down the table. However, there will usually be treatments (or mitigations), involving additional assurance measures, that will allow the assessed business risk to move to the left.\n\n\nTable 3-2 - Example of a risk matrix\n\n\n\n\n\n\n\nLikelihood of errors occurring\n\n\n\nImpact of errors occurring\n\n\n\n\n\n\nHighly unlikely\n\n\nUnlikely\n\n\nRealistic possibility\n\n\nLikely or probably\n\n\nHighly likely\n\n\n\n\n\n\nCritical\n\n\nMedium\n\n\nMedium\n\n\nHigh\n\n\nHigh\n\n\nHigh\n\n\n\n\n\n\nSevere\n\n\nLow\n\n\nMedium\n\n\nMedium\n\n\nHigh\n\n\nHigh\n\n\n\n\n\n\nMajor\n\n\nLow\n\n\nMedium\n\n\nMedium\n\n\nMedium\n\n\nHigh\n\n\n\n\n\n\nModerate\n\n\nVery Low\n\n\nLow\n\n\nMedium\n\n\nMedium\n\n\nMedium\n\n\n\n\n\n\nMinor\n\n\nVery Low\n\n\nVery Low\n\n\nLow\n\n\nLow\n\n\nMedium\n\n\n\nTable 3-3 shows appropriate responses to a risk assessment. Where business risk is high, appropriate treatment(s) must be considered to reduce the probability of errors occurring. The choice of treatment will depend on the mitigations already in place and on the complexity of the analysis (see Figure 3-1).\nFor a situation where simple analysis is being employed, a review by an appropriate expert may be sufficient as the additional mitigation. However, for complex analysis that is already employing a wide range internal assurance measures, options like external peer review may be necessary.\nIn cases where there is a need for analysis, but there are also significant time and/or resource constraints, it may not be possible to do as much assurance as usual. In these situations, the focus should be on areas of greatest risk. These risks and limitations must also be communicated, along with appropriate caveats.\n\nTable 3-3 - Responses to risk assessment levels\n\n\n\n\n\n\nAssessed risk\nMitigations to consider\n\n\n\n\nHigh\nThe risk should not be tolerated. New assurance measures must be considered to treat (mitigate) the likelihood of errors occurring. If treatment isn’t an option, consideration must be be given to terminating or transferring the (analysis) risk. If it remains necessary to tolerate the risk the SRO needs to fully understand the risk.\n\n\nMedium\nThe risk should not be tolerated without SRO agreement. New assurance measures should be put in place to treat (mitigate) the likelihood of errors occurring. Continue with planned or existing mitigations.\n\n\nLow\nThe risk can be tolerated. Existing or planned mitigations should be continued, and new treatments may be considered.\n\n\nVery Low\nThe risk can be tolerated. Existing/planned mitigations measures should be continued.\n\n\n\nFor further guidance on risk management, refer to the Orange book which covers risk management principles and risk control frameworks.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "proportionality.html#externally-commissioned-work",
    "href": "proportionality.html#externally-commissioned-work",
    "title": "3  Proportionality",
    "section": "3.3 Externally commissioned work",
    "text": "3.3 Externally commissioned work\nProportionate assurance of externally commissioned work is just as important as for internally produced analysis. For the commissioner, to use the work they should be fully informed of the business risk associated with it. This should be provided by an appropriate mix of documented risk assessments provided as part of the work, and by joint risk assessments planned throughout the life of the project. For commissioned work the options for mitigation will be similar to those for internal analysis.\nThe difference will be in ensuring the assessment of risks and the applied mitigations are fully understood by the commissioner.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "proportionality.html#artificial-intelligence-and-business-risk",
    "href": "proportionality.html#artificial-intelligence-and-business-risk",
    "title": "3  Proportionality",
    "section": "3.4 Artificial intelligence and business risk",
    "text": "3.4 Artificial intelligence and business risk\nIncreasingly analysis may be underpinned by Artificial Intelligence (AI). With AI-informed analysis the need to understand business risk remains, and the same structured approach to assessing business risk should be taken. The challenges in providing this assessment will be in ensuring the transparency of the analysis, availability of a suitable mix of experts, and developing understanding of what mitigations are possible.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html",
    "href": "quality_assurance_culture.html",
    "title": "4  Quality assurance culture",
    "section": "",
    "text": "4.1 Leadership\nA quality assurance culture starts with senior leaders. They are accountable for the quality of analysis carried out in their departments. A key element of discharging this accountability is to clearly set out the priority of quality within their teams and create processes for embedding quality assurance.\nThe guidance in Annex 4.2 of Managing Public Money (https://www.gov.uk/government/publications/managing-public-money) assigns accountability for ensuring approporiate assurance processes are in place to the Accounting Officer. In practice the Accounting Officer may assign the responisbility to a senior leader reporting to the senior management board. The Accounting Officer may collect information on the state of assurance processes and include this in their annual report. The Department of Energy Strategy and Net Zero reports this annually - page 91 of (https://assets.publishing.service.gov.uk/media/6532741b26b9b1000faf1ca7/CCS0123681176-001_PN6763756_BEIS_2022-23_Annual_Report_Web_Accessible.pdf).\nSenior leaders should ensure there is clear messaging and standards on quality assurance, through guidance, training, and regular updates. Senior leaders can demonstrate the importance of quality assurance through long term initiatives, like setting up and embedding quality assurance processes within the team and creating roles and teams to support quality assurance. Senior leaders should also regularly talk about quality with their teams and highlight quality successes.\nAs part of a strong quality assurance culture, senior leaders should empower all those in the analytical process to identify any risks to the quality of the work, ensure people at any level can raise any quality concerns, and be able to discuss and constructively challenge each other if they feel those standards are not being met. To underpin this, senior leaders should ensure teams have a common understanding of the quality standards required for their work.\nCreating transparency at all levels can help embed a culture of quality assurance. This includes peer review, open source of code (where possible), external publication of models or methods and publication of the register of Business Critical Models.\nSenior leaders should also develop processes so teams can report when things go wrong, be open and honest when issues occur, carry out reviews to understand the failures in the assurance process and share the lessons learnt across the analytical community.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#leadership",
    "href": "quality_assurance_culture.html#leadership",
    "title": "4  Quality assurance culture",
    "section": "",
    "text": "Sharing best practice on quality assurance\n\n\n\nHM Revenue and Customs have developed a Quality Champions network, made up of analysts from across the department. The network discuss quality assurance initiatives, quality issues and how they were resolved and shares wider best practice.\n\n\n\n\n\n\n\n\n\n\n\nAn open culture when things go wrong\n\n\n\nWhen the Department for Education made an error producing the schools national funding formula allocations for 2024-25, they ran a detailed internal review to understand what went wrong and why it was not detected by the QA process. The department also commissioned and published an external, independent review to assess the error and put forward recommendations. The independent review praised the team for its open learning culture and a culture of taking responsibility for mistakes.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#capacity-and-capability",
    "href": "quality_assurance_culture.html#capacity-and-capability",
    "title": "4  Quality assurance culture",
    "section": "4.2 Capacity and capability",
    "text": "4.2 Capacity and capability\nSenior leaders should create the conditions in which quality assurance processes can operate effectively, by ensuring staff have time built-in for quality assurance and documentation, can draw on expertise and experience, and have the access to the tools and data they need.\n\n4.2.1 Capacity\nThere is a risk that work, and time pressures mean teams cut corners on quality or mistakes are made as analysis is rushed. Senior leaders can mitigate this through strong prioritisation, supporting teams to push back on lower value work or by making tough choices on team wide priorities. Through this prioritisation, senior leaders can emphasise the importance of quality. Team leaders can support quality assurance, by ensuring it is considered throughout the lifecycle of a project and not simply considered at the end, and making time for adequate quality assurance even when timescales are tight.\nIf time constraints mean insufficient assurance has taken place, senior leaders should ensure this is explicitly acknowledged and reported. This should be reported via an assurance statement that sets out the known limitations and conditions associated with the analysis.\nWhere analysis requires peer review, this should be carried out by independent, skilled and competent individuals or groups. However, it can be difficult to identify available experts who are able to provide a review. There are several approaches to support and embed independent review, such as setting up specific teams to review and audit a sample of analytical projects, developing assurance networks of analysts who can provide reviews when needed, partnering with another Department, or procuring an an independant review from an independant source such as the Government Actuary’s Department (GAD) (https://www.gov.uk/government/publications/gad-services/government-actuarys-department-services), an academic institution or contractor. Team leaders can support this by making time for analysts to carry out peer reviews and ensuring analysts are clear that supporting peer reviews is part of their role.\n\n\n\n\n\n\nHM Revenue and Customs independent review team\n\n\n\nHMRC has a small analytical team which independently reviews analysis from across the department, including a sample HMRC’s business-critical models. The reviews provide assurance for high profile analysis and support the sharing of best practice.\n\n\n\n\n4.2.2 Capability\nThere is a risk that errors occur because of a lack of skills or experience. Senior leaders can identify common skills gaps, creating training or mentoring to help fill gaps in analysts’ knowledge. Processes to support knowledge sharing, innovation and dissemination of best practice will all help develop capability. Rolling out training on departmental assurance processes can also mitigate this risk.\nThere are various cross-government resources designed to provide support and guidance for commissioners and users of analysis. For example, the Analysis Function’s Advice for policy professionals using statistics and analysis aims to help policy professionals to work effectively with analysts and analysis. It introduces some important statistical ideas and concepts to help policy professionals ask the right questions when working with statistical evidence.\n\n\n\n\n\n\nBuilding assurance capability\n\n\n\nThe Department for Energy Security and Net Zero are building assurance capacity with a programme of quality assurance Colleges. The Colleges run regular virtual sessions, open to colleagues across Government and Partner Organisations.\nThese sessions include an interactive activity looking at a purposefully sabotaged model, used to introduce and familiarise colleagues with the quality assurance logbook and the departmental system of actively monitoring models through these logbooks.\nCollege participants also join the Modelling Integrity Network, as potential Assuring Analysts where these cannot be found by Lead Analysts in their own policy areas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#quality-assurance-champions",
    "href": "quality_assurance_culture.html#quality-assurance-champions",
    "title": "4  Quality assurance culture",
    "section": "4.3 Quality assurance champions",
    "text": "4.3 Quality assurance champions\nIn an organisations with large analytical community, it is good practice for the senior leaders to appoint a quality assurance champion. This person can share best practice in implementation of quality assurancem and provide advice on issues such as proportionality and communication of assurance.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#tools",
    "href": "quality_assurance_culture.html#tools",
    "title": "4  Quality assurance culture",
    "section": "4.4 Tools",
    "text": "4.4 Tools\nThere is a risk that technology or analytical tools are out of date meaning analysts cannot follow best practice or must spend time fixing processing issues instead of focussing on quality. Senior leaders can support teams by making funding available for new tools or improving existing tools, working with digital/IT teams to escalate issues and gathering cross team issues.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#data",
    "href": "quality_assurance_culture.html#data",
    "title": "4  Quality assurance culture",
    "section": "4.5 Data",
    "text": "4.5 Data\nThere is a risk that data quality and data understanding cause quality issues with analysis. Senior leaders can escalate data quality issues with wider data teams, and champion and oversee changes to improve data quality.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#governance-and-control",
    "href": "quality_assurance_culture.html#governance-and-control",
    "title": "4  Quality assurance culture",
    "section": "4.6 Governance and control",
    "text": "4.6 Governance and control\nGovernance supports a strong quality assurance culture, by overseeing the management and assurance of analysis. The [Analysis Function Standard] (https://www.gov.uk/government/publications/government-analysis-functional-standard–2) sets out the requirements for a governance framework for analysis. Each organisation should have a defined and established approach to assurance, which should be applied proportionately to the risk and value of the activity and integrated with the organisation’s overall assurance framework. \nProject level governance can provide oversight over a particular model or work area, allowing the Approver to ensure the analysis is fit for purpose. For example, formally agreeing assumptions will reduce the need for reworking the analysis providing more time for assurance. Projects governance can also fit within wider programme level governance. \nAnalytical governance boards for new, high-profile or complex pieces of analysis, can allow senior analytical leaders and experts to provide oversight and challenge of analysis and ensure best practice is followed. These groups are multi-disciplinary and can cover a range of analytical approaches based on their expertise and experience. This can help ensure that innovations and new approaches are disseminated across teams, and standards are applied equally across similar work.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#transparency",
    "href": "quality_assurance_culture.html#transparency",
    "title": "4  Quality assurance culture",
    "section": "4.7 Transparency",
    "text": "4.7 Transparency\nTransparency at all levels can help embed a culture of quality assurance. For example peer review, sharing lessons learnt, and making analysis open (where possible), all contribute to an open culture of high quality work.\n\n4.7.1 Externally commissioned analysis\nWhen commissioning analysis externally, either qualitative or quantitative research, or the production of models, then the accountability for the quality sits with the commissioning department. It is the commissioning analyst’s role to ensure that quality standards are clear and being met and documented to the commissioning departments requirements. Further information can be found in the commissioning chapter.\nFor Arm’s Length Bodies (ALBs), the commissioner of analysis is accountable for ensuring the requirements set out in the AQuA Book are met.\nUser groups for types of analysis can also provide assurance by setting standards and ensuring projects follow topic specific or specialised guidance, such as coding best practice.\nWhen working with third parties, the commissioner shall ensure it is clear which role or roles in which stages of the analytical lifecycle that third party is responsible for. See Roles and Responsibilities for details on the roles.\nFor example, the third party may only undertake the analyst role in the analysis phase or they may undertake the analyst, assurer and approver roles in all stages of the lifecycle.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "analytical_lifecycle.html",
    "href": "analytical_lifecycle.html",
    "title": "5  Roles and the analytical lifecycle",
    "section": "",
    "text": "5.1 Roles and responsibilities\nOrganisations may have their own titles for the main functional roles involved in analysis that are set out here.\nEach role may be fulfilled by a team or committee of people. However, a single individual will have overall accountability (such as the chair of a committee) for each role.\nThe AQuA book defines the following roles:\nThe roles of Analyst and Assurer shall be distinct from each other. The Analyst should carry out their own assurance but responsibility for formal assurance to the Commissioner lies with the Assurer. In some instances, particularly for quick and / or simple analysis, an individual may deliver more than one of the roles apart from the Assurer and Analyst roles which shall be separate from one another in all cases.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Roles and the analytical lifecycle</span>"
    ]
  },
  {
    "objectID": "analytical_lifecycle.html#roles-and-responsibilities",
    "href": "analytical_lifecycle.html#roles-and-responsibilities",
    "title": "5  Roles and the analytical lifecycle",
    "section": "",
    "text": "Commissioner (may be known as customer)\n\nRequests the analysis and sets out their requirements\n\nAgrees what the analyst is going to do will satisfy the need\n\nAccepts the analysis and assurance as fit for purpose\n\nAnalyst\n\nDesigns the approach, including the assurance, to meet the commissioner’s requirements\nAgrees the approach with the Commissioner\nCarries out the analysis\nCarries out their own assurance\n\nActs on findings from the Assurer\nCan be a group of analysts, in which case the lead analyst is responsible\n\nAssurer (may be known as Analytical Assurer, Assuring Analyst)\n\nReviews the assurance completed by the Analyst\n\nCarries out any further validation and verification they may see as appropriate\nReports errors and areas for improvement to the analyst\n\nRe-reviews as required\n\nConfirms the work has been appropriately scoped, executed, validated and verified and documented to the Approver\n\nCan be a group of assurers. In which case the leader of the group is responsible. They must be independent from the analysts.\n\nApprover (may be known as Senior Analyst or Senior Responsible Officer (“SRO”))\n\nScrutinises the work of the Analyst and Assurer\n\nConfirms (if necessary) to the Analyst, Assurer and Commissioner that the work has been appropriately assured",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Roles and the analytical lifecycle</span>"
    ]
  },
  {
    "objectID": "analytical_lifecycle.html#the-analytical-lifecycle",
    "href": "analytical_lifecycle.html#the-analytical-lifecycle",
    "title": "5  Roles and the analytical lifecycle",
    "section": "5.2 The analytical lifecycle",
    "text": "5.2 The analytical lifecycle\nQuality assurance activities should take place throughout all stages of an analytical project. An effective quality assurance process involves ongoing engagement between the commissioner and the analyst to ensure an appropriate balance is maintained between time, resource and quality, and to ensure a shared understanding of the assurance activities required and risks involved.\n\n\n\nFigure 2 - The analytical cycle\n\n\nFigure 2 is adapted from the Government Functional Standard for Analysis. Analytical quality assurance activities should take place during every phase of the cycle and should consider proportionality, although analytical quality considerations may vary depending on project governance and the specific phase of the cycle. All projects will involve some element of every phase of the cycle, even if this is not clearly defined.\nIt is important that proportionality is considered and that there is transparency of the analytical decisions, process, limitations and changes made at each stage to enable effective assurance and communication. This should be enabled by:\n\nClear documentation of the analysis, assumptions and data,\nClear records of the analytical decisions made; and\nClear records of the quality assurance processes and checks completed.\n\n\n5.2.1 Engagement and scoping\nAnalytical projects typically start with customer engagement although other events may trigger analytical projects. Scoping ensures that an appropriate, common understanding of the problem is defined and that expectations are aligned with what can be delivered. During this phase the Commissioner plays an important role in communicating the questions to be addressed and working with the Analyst to ensure the requirements and scope are defined and understood.\nWhere analysis requires multiple cycles, for example to develop, use and update analytical models, this phase may follow on from the Delivery and Communication phase. In these cases, the focus of this phase will be on the scope of the questions to be addressed in the next stage of the analytical project.\nMore effort may be needed to define the requirements and scope in this phase for research, evaluation or other projects that may need to seek a wider range of perspectives or for which subsequent phases and work may be delivered through a product or service.\n\n\n5.2.2 Design\nDuring the design phase, the Analyst will convert the commission into an analytical plan, including the assurance required and ensuring it is sufficient to answer the questions posed. This phase includes the communication and approval of plans produced, and some iteration between the Commissioner and the Analyst is to be expected as the analytical solution is developed and limitations understood.\nFor larger projects or those that require multiple cycles, the design phase may include consideration of the staging of work over the whole scope of the project as well as work required in each stage. Analysis plans for work that is dependent on insights from earlier stages may be high-level and necessitate a return to the design phase at a later date.\n\n\n5.2.3 Analysis\nThe analysis phase is where planned analysis is undertaken, and progress and relevance are monitored. During work, the design and plan may be amended to account for changing circumstances, emerging information or unexpected difficulties or limitations encountered, and this phase also includes maintaining appropriate records of the analysis conducted, changes, decisions and assumptions made. In some cases, changes or limitations encountered may necessitate a return to either the design or scoping phase.\nThroughout this phase, traceable documentation of the assurance activities undertaken shall also be produced.\nIn larger analytical projects, some outputs of the analysis may be completed at different times as work progresses, and aspects of other phases may therefore take place concurrently.\n\n\n5.2.4 Delivery, communication and sign-off\nDuring the delivery stage, insights and analytical assurances are communicated to the Approver and the Commissioner. The aim is ensuring that these are sufficiently understood in order for the Approver and Commissioner to determine whether the work has been appropriately assured and meets their requirements. This may then trigger additional analysis and further assurance as analytical projects frequently need further iteration or extension to satisfy the Commissioner’s needs.\nWork in this stage can vary considerably depending on the commission, impact, approval processes and the nature of the project. Delivery and communication activities may include producing summary packs and reports, launching dashboards or websites and presentations to boards.\nAfter analysis results have been determined to meet the requirements, they are formally approved for dissemination during sign-off. Sign-off includes confirmation that the commission was met, documentation and evidence was captured, and appropriate assurance was conducted. This approval may be phased as work progresses and insights are produced.\n\n\n5.2.5 Maintenance and continuous review\nThe analytical lifecycle is not a linear process. Where analysis is used on an ongoing basis, all aspects of the lifecycle should be regularly updated. For example, consideration should be made whether The inputs used remain appropriate The initial communication methods remain the best way to deliver the information *Any software relied on continues to be supported and up to date\nAdditionally, a robust version control process should be in place to ensure any changes to the analysis are appropriately assured.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Roles and the analytical lifecycle</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html",
    "href": "engagement_and_scoping.html",
    "title": "6  Engagement and scoping",
    "section": "",
    "text": "6.1 Introduction and overview\nThe first stage of the analytical lifecycle is initial engagement and scoping out what the Commissioner requires. This information constrains what is relevant for the analysis. The Analyst works with the Commissioner to develop sufficient understanding of the problem to design a requisite analysis.\nDuring engagement and scoping, the Commissioner and the Analyst shape the analysis by developing a shared understanding of the problem and the context. This shared understanding will be used as the basis for designing analysis that suits the Commissioner’s requirements.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#roles-and-responsibilities-in-the-engagement-and-scoping-stage",
    "href": "engagement_and_scoping.html#roles-and-responsibilities-in-the-engagement-and-scoping-stage",
    "title": "6  Engagement and scoping",
    "section": "6.2 Roles and responsibilities in the engagement and scoping stage",
    "text": "6.2 Roles and responsibilities in the engagement and scoping stage\n\n6.2.1 The Commissioner’s responsibilities during the engagement and scoping stage\nThe Commissioner:\n\nShould communicate to the Analyst the key aspects of the problem, scope, and programme constraints.\n\nShould be available to engage with the Analyst to appropriately shape the work.\nShould ensure that they understand risks where time and resource pressures constrain the approach.\nShould communicate to the Analyst any sources of uncertainty they have identified as part of their wider considerations.\n\nShould, if possible, indicate the consequences for decision-making of different degrees of uncertainty, as this may enable the Analyst to conduct their analysis at a proportionate level.\n\nShould sign-off on the specification document produced by the analyst.\n\n\n\n6.2.2 The Analyst’s responsibilities during the engagement and scoping stage\nThe Analyst:\n\nShould engage with the Commissioner to identify the question, the context, and the boundaries of the analysis, as well as constraints (e.g. deadlines, available resource), assumptions, risks, identified uncertainties and business-criticality.\nShould create a specification document which captures the Commissioner’s requirements. It should provide a definition of the scope and project constraints. It should state the acceptable level of risk, the required level of assurance. It may also state the degree of uncertainty allowed for decision-making, and record identified sources of uncertainty. The Analyst should share this specification with the Commisioner for sign-off.\n\n\n\n6.2.3 The Assurer’s responsibilities during the engagement and scoping stage\nThe Assurer may confirm that the engagement process has been sufficient to fully understand the problem. For more business critical projects, they may wish to confirm that the specification document adequately captures the outcomes of the engagement process.\n\n\n6.2.4 The Approver’s responsibilities during the engagement and scoping stage\nThe Approver should note the new project, confirm that resources and plans are in place for the appropriate assurance to take place. For example, they should ensure that the Analyst and Assurer are aware of local assurance protocols. The Approver might provide support in securing a sufficiently qualified and experienced Assurer.\nThe Approver should ensure that there is sufficient governance in place to support the analyst and their role in the wider project or programme. This is particularly important if the analysis supports business critical decisions. This may need to be revisited at the design stage if a novel or riskier approach is required (for example if AI models are used).",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#assurance-activities-in-the-engagement-and-scoping-stage",
    "href": "engagement_and_scoping.html#assurance-activities-in-the-engagement-and-scoping-stage",
    "title": "6  Engagement and scoping",
    "section": "6.3 Assurance activities in the engagement and scoping stage",
    "text": "6.3 Assurance activities in the engagement and scoping stage\nThe engagement and scoping stage provides the Analyst with an understanding of the Commissioner’s requirements. In some cases, the Commissioner may present a well-defined problem, while in other instances, the engagement stage may require problem structuring methods. Techniques such as the Strategic Choice Approach, Rich Pictures and Systems Thinking can help the Analyst and Commissioner to reach a joint understanding of the problem (see the Systems Thinking Toolkit for further information). The engagement will lead to the Analyst and Commissioner being able to define the scope of the project in terms of the context and bounds of the analysis. In cases where the engagement and scoping techniques are complex and/or the project is deemed business critical, the Assurer might provide assurance of the engagement methodology (https://publications.tno.nl/publication/100301/Zs2SUz/wijnmalen-2012-natoclient.pdf)\nIn addition to understanding the problem, the engagement and scoping stage should lead to agreement between the Analyst and Commissioner about the outputs to be delivered, including acceptable levels of accuracy, precision and margins of error. This will inform the handling of uncertainty and the assurance thereof in later stages.\nThe Commissioner should communicate to the Analyst what is known about data sources and data quality. This will be used to guide the design of data processing.\nThe Analyst and Commissioner should also clarify risks and potential impacts of the project which will inform the decisions around proportionate assurance. Constraints around resource and timelines should also be clarified and agreed.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#documention-in-the-engagement-and-scoping-stage",
    "href": "engagement_and_scoping.html#documention-in-the-engagement-and-scoping-stage",
    "title": "6  Engagement and scoping",
    "section": "6.4 Documention in the engagement and scoping stage",
    "text": "6.4 Documention in the engagement and scoping stage\nThe output of this stage should be a specfication document that captures the joint understanding. This document provides a reference for later validation assurance activities (i.e. that the analysis meets the specification). This document also provides evidence for the Approver during the delivery stage that the analysis meets the specification. The document should be signed off by the Commissioner, and might be reviewed by the Assurer.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#treatment-of-uncertainty-in-the-engagement-and-scoping-stage",
    "href": "engagement_and_scoping.html#treatment-of-uncertainty-in-the-engagement-and-scoping-stage",
    "title": "6  Engagement and scoping",
    "section": "6.5 Treatment of uncertainty in the engagement and scoping stage",
    "text": "6.5 Treatment of uncertainty in the engagement and scoping stage\nThe following aspects of the engagement and scoping stage will inform the treatment of uncertainty:\n\nA clear definition of the analytical question\nIdentification of sources of high and/or intractable uncertainty\nEstablishing an understanding of how the analysis will inform decisions\n\nFuther details on Uncertainty in engagement and scoping can be found in the Uncertainty Toolkit",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#black-box-models-and-the-engagement-and-scoping-stage",
    "href": "engagement_and_scoping.html#black-box-models-and-the-engagement-and-scoping-stage",
    "title": "6  Engagement and scoping",
    "section": "6.6 Black box models and the engagement and scoping stage",
    "text": "6.6 Black box models and the engagement and scoping stage\nWhere the Commissioner has engaged with the Analyst to deliver black box models models such as AI/ML, the engagement and scoping stage should include discussions around ethics and risks in order to assess whether such models would be appropriate for addressing the given problem. For example, discussions might include considerations of regulations such as UK GDPR, organisational skills, and internal governance and risk management. For further details see https://www.gov.uk/government/publications/introduction-to-ai-assurance/introduction-to-ai-assurance.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#multi-use-models-and-the-engagement-and-scoping-stage",
    "href": "engagement_and_scoping.html#multi-use-models-and-the-engagement-and-scoping-stage",
    "title": "6  Engagement and scoping",
    "section": "6.7 Multi-use models and the engagement and scoping stage",
    "text": "6.7 Multi-use models and the engagement and scoping stage\nIn the case of multi-use models, the Analyst may be required to engage with a group of end-users to develop an understanding of their respective requirements. As requirements might differ or contradict, techniques such as Strategic Options Development and Analysis (SODA) and [Soft Systems Methodology] (https://en.wikipedia.org/wiki/Soft_systems_methodology) may be used to develop a shared understanding across multiple groups.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "design.html",
    "href": "design.html",
    "title": "7  Design",
    "section": "",
    "text": "7.1 Introduction and overview\nThe design stage is where the Analyst translates the scope for the analysis agreed with the Commissioner into an actionable analytical plan. This chapter sets out recommended practices around designing the analysis and associated assurance activities, documenting the design and assuring the design. It also discusses considerations around the treatment of uncertainty in design, and design of multi-use and AI models.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#introduction-and-overview",
    "href": "design.html#introduction-and-overview",
    "title": "7  Design",
    "section": "",
    "text": "7.1.1 The design stage\nThe development of the analytical plan should consider:\n\nMethodology for producing results, including the treatment of uncertainty;\nProject management approach (for example Agile, Waterfall or a combination of approaches);\nSourcing of inputs and assumptions;\nData and file management;\nChange management and version control;\nProgramming language and/or software;\nCode management, documentation and testing;\nCommunication between stakeholders;\nVerification and validation procedures during the project lifetime;\nDocumentation to be delivered;\nProcess for updating the analytical Plan;\nEthics;\nReporting;\nDownstream application.\n\nThe use of Reproducible Analytical Pipelines (RAP) is encouraged as a means of effective project design.\nIteration between the Commissioner and the Analyst is normal and expected whilst the analytical design develops.\n\n\n\n\n\n\nReproducible analytical pipelines\n\n\n\nThe recommended approach for developing analysis in code is to use a Reproducible Analytical Pipeline (RAP). Reproducible Analytical Pipelines shall:\n\nFollow the practices set out in the Analysis Function Quality Assurance of Code for Analysis and Research manual.\nMeet the requirements of the Reproducible Analytical Pipelines minimum viable product.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#roles-and-responsibilities-in-the-design-stage",
    "href": "design.html#roles-and-responsibilities-in-the-design-stage",
    "title": "7  Design",
    "section": "7.2 Roles and responsibilities in the design stage",
    "text": "7.2 Roles and responsibilities in the design stage\n\n7.2.1 The Commissioner’s responsibilities during the design stage\nThe Commissioner should confirm that the analytical approach will satisfy their needs. To assist in this, the Commissioner may review the analytical plan.\nThe Commissioner’s domain expertise can be a useful resource for the analyst in the design stage. The Commissioner might provide information regarding the input assumptions, data requirements and the most effective ways to present the outputs, all of which can inform the design.\n\n\n7.2.2 The Analyst’s responsibilities during the design stage\nThe Analyst should:\n\ndevelop the method and plan to address the Commissioner’s needs,\ndevelop the assurance requirements will be and\nplan in sufficient time for the assurance activity.\ndocument the analytical plan in a proportionate manner.\nfollow any organisation governance procedures for project design.\n\n\n\n7.2.3 The Assurer’s responsibilities during the design stage\nThe Assurer should review the analytical plan to ensure that they are able to conduct the required assurance activities. They may provide feedback on the analytical plan. The Assurer should plan sufficient time for the assurance activity.\n\n\n7.2.4 The Approver’s responsibilities during the design stage\nIn smaller projects, the Approver may not be heavily involved in the design stage. However, for business critical analysis, the Approver may want to confirm that organisational governance procedures for design have been followed.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#assurance-activities-in-the-design-stage",
    "href": "design.html#assurance-activities-in-the-design-stage",
    "title": "7  Design",
    "section": "7.3 Assurance activities in the design stage",
    "text": "7.3 Assurance activities in the design stage\nDesigning the assurance activities for subsequent analytical stages is a key part of the design stage. The design of the assurance should take into account the principles of proportionality. Assurance of data quality should be considered in the analytical plan.\nOn completion of the design stage, the Assurer should be aware of the quality assurance tasks that will be required of them during the project lifetime and have assured the necessary elements of the analytical plan.\nThe assurance of the design stage should consider whether the analytical plan:\n\nDelivers as intended\nAdequately addresses the complexities of the customer issue for this purpose\nIs well-structured for the purpose, data driven, and reflects a robust overall design.\n\nThe assurance of the design stage may be carried out by the Assurer. For more complex analysis, it is good practice to engage subject matter experts to provide independent assurance, and to ensure the accuracy and limitations of the chosen methods are understood, ideally with tests baselining their response against independent reference cases.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#documention-in-the-design-stage",
    "href": "design.html#documention-in-the-design-stage",
    "title": "7  Design",
    "section": "7.4 Documention in the design stage",
    "text": "7.4 Documention in the design stage\nThe design process should be documented in a proportionate manner. A design document that records the analytical plan should be produced by the Analyst, and signed-off by the Commissioner. The design document may be reviewed by the Assurer.\nIt is best practice to use formal version control to track changes in the design document.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#treatment-of-uncertainty-in-the-design-stage",
    "href": "design.html#treatment-of-uncertainty-in-the-design-stage",
    "title": "7  Design",
    "section": "7.5 Treatment of uncertainty in the design stage",
    "text": "7.5 Treatment of uncertainty in the design stage\nDuring the design stage, Analysts should examine the planned analysis systematically for possible sources and types of uncertainty, to maximise the chance of identifying all that are sufficiently large to breach the acceptable margin of error. This is discussed in Chapter 3 of the Uncertainty Toolkit for Analysts",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#black-box-models-and-the-design-stage",
    "href": "design.html#black-box-models-and-the-design-stage",
    "title": "7  Design",
    "section": "7.6 Black box models and the design stage",
    "text": "7.6 Black box models and the design stage\nUsing black box models places greater weight on the design of the analysis and the assurance and validation of outputs by domain experts.\nThis guidance outlines considerations for the design of AI models, including risk assessment, impact assessment, bias audits and compliance audits.\nIn the Design of AI/ML models, the Analyst should:\n\ndefine the situation they wish to model\nthe prediction they wish to make\nthe data that could be used to make the prediction\nconsider how to separate the data for the design and testing of models - it’s usual to design a model with a fraction of the data and then test it with the data that was not used in the design\nidentify potential modelling methods",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#multi-use-models-and-the-design-stage",
    "href": "design.html#multi-use-models-and-the-design-stage",
    "title": "7  Design",
    "section": "7.7 Multi-use models and the design stage",
    "text": "7.7 Multi-use models and the design stage\nDesigning multi-use models should take into account the needs of all users of the analysis. An Analysis Steering Group can be an effective means for communication about the design with a range of user groups.\nThe design of multi-use models may entail a modular structure with different Analysts and Assurers responsible for different elements. The design of assurance activities should capture both the assurance of individual modules and their integration.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "8  Analysis",
    "section": "",
    "text": "8.1 Introduction and overview\nThe analysis stage is where planned analysis is undertaken and assured, and progress and relevance are monitored. During this stage, the design may be amended to account for changing circumstances, emerging information or unexpected difficulties or limitations encountered. This stage also includes maintaining appropriate and traceable records of the analysis and assurance activities conducted, changes, decisions and assumptions made. In some cases, changes or limitations encountered may necessitate a return to either the design or scoping stage.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#introduction-and-overview",
    "href": "analysis.html#introduction-and-overview",
    "title": "8  Analysis",
    "section": "",
    "text": "8.1.1 The Analyst’s responsibilities during the analysis stage\n\nThe Analyst shall follow the assurance plan, and conduct the specified verification and validation. They shall provide traceable documentation of the assurance they have undertaken. They shall respond to recommendations from the Assurer and act on them as appropriate.\nThe Analyst shall produce documentation of the data and methods used. The Analyst shall ensure these are sufficient for the Assurer to understand the approach.\nThe Analyst shall document any changes to the analytical plan in a proportionate manner.\nThe Analyst shall maintain appropriate contact with Commissioner and Assurer. This provides and opportunity for them to advise on whether the analysis is still meeting the Commissioner’s needs or whether there are any new requirements.\n\n\n\n8.1.2 The Assurer’s responsibilities during the analysis stage\nThe Assurer shall review the assurance completed by the Analyst, carry out any further validation and verification they may see as appropriate, and report errors and areas for improvement to the Analyst. The Assurer may then need to re-review the analytical work completed, as required.\nThe Assurer may be required to provide feedback on changes to the analytical plan, and consider whether they are qualified to provide rigorous assurance on the revised methodology.\n\n\n8.1.3 The Commissioner’s responsibilities during the analysis stage\n\nThe Commissioner should be available to provide input and clarifications to the Analyst.\nThe Commissioner’s should review any changes in design or methodology that the Analyst brings to their attention.\n\n\n\n8.1.4 The Analyst’s responsibilities during the analysis stage\n\nThe Analyst shall follow the conduct the verification and validation activities that were designed as part of the analytical plan in the design stage. They shall provide traceable documentation of the assurance they have undertaken. They shall respond to recommendations from the Assurer and act on them as appropriate.\nWhen the analysis includes coding, the Analyst shall proportionately follow best practice for code development.\nThe Analyst shall produce documentation of the data and methods used. The Analyst shall ensure these are sufficient for the Assurer to understand the approach.\nThe Analyst shall document any changes to the analytical plan in a proportionate manner.\nThe Analyst shall maintain appropriate contact with Commissioner and Assurer. This provides and opportunity for them to advise on whether the analysis is still meeting the Commissioner’s needs or whether there are any new requirements.\n\n\n\n8.1.5 The Assurer’s responsibilities during the analysis stage\n\nThe Assurer shall review the assurance completed by the Analyst, carry out any further validation and verification they may see as appropriate, and report errors and areas for improvement to the Analyst. The Assurer may then need to re-review the analytical work completed, as required.\nWhen the analysis includes coding, the Assurer shall review that the work proportionately adheres to coding best practice.\nThe Assurer may be required to provide feedback on changes to the analytical plan, and consider whether they are qualified to provide rigorous assurance on the revised methodology.\n\n\n\n8.1.6 The Approver’s responsibilities during the analysis stage\nThe Approver should be aware of the progress of the analysis and ensure that they are available for approving the work at the delivery stage.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#assurance-activities-in-the-analysis-stage",
    "href": "analysis.html#assurance-activities-in-the-analysis-stage",
    "title": "8  Analysis",
    "section": "8.2 Assurance activities in the analysis stage",
    "text": "8.2 Assurance activities in the analysis stage\n\n8.2.1 Verification and validation\nVerification that the implemented methodology meets the intended plan should be incorporated as part the analysis. Whitener and Balci (1989) review verification techniques in relation to simulation modelling, but these techniques extend to analysis more broadly. These include:\n\nInformal analysis: techniques that rely on human reasoning and subjectivity.\nStatic analysis: tests that the implementation of the analysis before it is run. For example, checking that code adheres to code conventions, structural analysis of the code by examining graphs of control and data flows, .\nDynamic analysis: tests the behaviour of the system or code to find errors that arise during execution. This includes unit testing, integration testing and stress testing\nSymbolic analysis: particularly relevant to modelling and tests the transformation of symbolic proxies of model inputs into outputs during the execution of a model. Includes path tracing and cause-effect testing (see Whitener and Balci (1989) )\nConstraint analysis: particularly relevant to modelling and tests the implementation of constraints during model execution. This includes checking the assertions of the model and boundary analysis.\nFormal analysis: tests logical correctness through formal verification such as logic or mathematical proofs\n\nValidation refers to testing whether the product meets the requirements of users. Hence, it is important to involve the users in the process. Methods for validation include quantification and judgment of acceptable sensitivity, specificity, accuracy, precision and reproducibility.\nValidation of models includes testing the validity of the conceptual model, and testing the operational validity of any computerized model. Techniques that may be useful in validation of models are reviewed by Sargent (2011).\nThe Analyst has primary responsibility for conducting verification and validation. The Assurer is responsible for reviewing the verification and validation that is carried out by the Analyst, and for conducting or recommending additional verification and validation as required. The Assurer may refer to the specification document to assure that the analysis meets the specification.\n\n\n8.2.2 Data validity and data considerations\nTesting data validity (i.e. that data meet the specification for which they are used) is a key part of analysis. Procedures for assuring data validity include testing for internal consistency, screening for data characteristics (outliers, trends, expected distributions etc), and assuring robust data management practices (e.g. automating data creation and data sourcing).\nIt is rare to have the perfect dataset for an analytical commission. Reasons for this include:\n\nThe data is not available in the time frame required for the ideal analysis;\n\nThe data definition does not perfectly align with the commission;\n\nThere are data or coverage gaps;\n\nThe data may be experimental or there are other reasons why it is not ‘mature’.\n\nOften, no data is available that are directly and precisely relevant to the parameter and conditions of interest. In such cases, it is often possible to use surrogate data. This is measurements of another parameter, or of the parameter of interest under different conditions, that is related to the parameter and conditions of interest. This implies an extrapolation between parameters, or between conditions for the same parameter. The use of surrogate data introduces further uncertainty, additional to that associated with the data itself. It may be possible to quantify this additional uncertainty using expert knowledge of the relationship between the surrogate and the parameter of interest.\nThe impact of using a proxy dataset should be explored and, if the uncertainty associated with the dataset has a large impact on the analysis, its appropriateness should be revisited. This exploration, and the decision to use a particular dataset or input, should be recorded for the benefit of the Assurer.\n\n\n8.2.3 Assurance of code\nThe Duck Book provides detailed guidance on developing and assurance for delivering quality code. This includes guidance on structuring code, producing documentation, using version control, data management, testing, peer review, and automation.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#documention-in-the-analysis-stage",
    "href": "analysis.html#documention-in-the-analysis-stage",
    "title": "8  Analysis",
    "section": "8.3 Documention in the analysis stage",
    "text": "8.3 Documention in the analysis stage\nThe Analyst should:\n\nMaintain appropriate records of the work;\nFully document any code following agreed standards;\nLog the data, assumptions and inputs used in the analysis, and decisions made (see documentation);\nRecord the verification and validation that has been undertaken, documenting any activities that are outstanding and noting what remedial action has been taken and its impact on the analysis;\nProduce user and technical documentation).",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#treatment-of-uncertainty-in-the-analysis-stage",
    "href": "analysis.html#treatment-of-uncertainty-in-the-analysis-stage",
    "title": "8  Analysis",
    "section": "8.4 Treatment of uncertainty in the analysis stage",
    "text": "8.4 Treatment of uncertainty in the analysis stage\nWhile the Scoping and Design stages identified and described risks and uncertainties, the Analysis stage aims to assess and quantify the impact of uncertainty on the analytical outcome and their contribution to the range and likelihoods of possible outcomes. The Uncertainty Toolkit for Analysts reviews methods of quantifying uncertainty. The verification and validation by the Analyst and Assurer should assure the appropriate treatment of uncertainty.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#black-box-models-and-the-analysis-stage",
    "href": "analysis.html#black-box-models-and-the-analysis-stage",
    "title": "8  Analysis",
    "section": "8.5 Black box models and the analysis stage",
    "text": "8.5 Black box models and the analysis stage\nBblack box models such as AI and ML models are not as transparent as traditionally coded models. This adds challenge to the assurance of these models as compared to other forms of analysis. Assurance activities during the Analysis stage include performance testing and formal verification. See the Introduction to AI Assurance for further details.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#multi-use-models-and-the-analysis-stage",
    "href": "analysis.html#multi-use-models-and-the-analysis-stage",
    "title": "8  Analysis",
    "section": "8.6 Multi-use models and the analysis stage",
    "text": "8.6 Multi-use models and the analysis stage\nIn multi-use models, analysis and edits may be carried out on individual elements of the model at differing times. This calls for mechanisms for assuring that the changes integrate into the larger model as expected, for example, through the use of test-suites.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html",
    "href": "delivery_and_communication.html",
    "title": "9  Delivery, communication and sign-off",
    "section": "",
    "text": "9.1 Introduction and summary\nThe successful delivery of analysis to its Commissioner marks its transition from being a product under development to one that is fit and ready to be used to inform decision making in your organisation and possibly inform the public.\nThis chapter provides information on the processes around assurance of communication of analysis and delivery of analytical output.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#introduction-and-summary",
    "href": "delivery_and_communication.html#introduction-and-summary",
    "title": "9  Delivery, communication and sign-off",
    "section": "",
    "text": "9.1.1 The Analyst’s responsibilities during delivery, communication and sign-off\n\nThe Analyst shall follow organisational governance procedures for delivery and sign-off, including, where appropriate, updating the business-critical analysis register, and making the analysis publicly available.\nThe Analyst should ensure that communication meets audience requirements, including accessibility.\nThe Analyst may be required to communicate the assurance state to the Approver, if not done directly by the Assurer.\nThe Analyst should be prepared to respond to challenge from the Approver. For example, this challenge might arise through project or programme boards.\n\n\n\n9.1.2 The Assurer’s responsibilities during delivery, communication and sign-off\nThe Assurer shall communicate the assurance state to the Approver. This includes confirmation that the work has been appropriately scoped, executed, validated, verified, documented, and provides adequate handling of uncertainty. This communication may go via the Analyst.\n\n\n9.1.3 The Commissioner’s responsibilities during delivery, communication and sign-off\nThe Commissioner shall use the analysis as specified at the start of the analytical cycle, applying any limitations to its use as described by the Analyst.\n\n\n9.1.4 The Approver’s responsibilities during delivery, communication and sign-off\n\nThe Approver shall review the assurance evidence that has been provided to them.\nThe Approver should provide sufficient challenge to the analysts to gain assurance that the analysis is fit for purpose.\nWhen they are satisfied with the validity and robustness of the analysis, the Approver should provide the Analyst with evidence that the analysis outputs have been properly reviewed and formally approved.\nThe Approver shall follow organisation governance procedures for sign-off.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#assurance-activities-in-the-delivery-communication-and-sign-off-stage",
    "href": "delivery_and_communication.html#assurance-activities-in-the-delivery-communication-and-sign-off-stage",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.2 Assurance activities in the delivery, communication and sign-off stage",
    "text": "9.2 Assurance activities in the delivery, communication and sign-off stage",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#delivery",
    "href": "delivery_and_communication.html#delivery",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.3 Delivery",
    "text": "9.3 Delivery\nWhen delivering a piece of analysis, the Analyst and/or Assurer should communicate its assurance state to the Approver and provide evidence that the analysis and associated outputs have undergone proportionate quality assurance and to demonstrate that the analysis is ready for delivery, for example:\n\nIt uses suitable data and assumptions;\n\nIt meets the purpose of its commission;\n\nIt has been carried out correctly and to its agreed specification;\n\nIt has a risk assessment and statement against the programme risk register;\nIf meets analytical standards, such as those around coding standards and documentation;\nIt adheres to any professional codes of practice (e.g. The Code of Practice for Statistics\nWhere appropriate the analysis is accompanied by a completed assurance statement.\n\nThough not strictly assurance, the analyst should also consider areas such as security ratings, retention policies, intellectual property, ethics and related concerns.\nThe Approver should scrutinise the evidence delivered and approve the work if the analysis meets specified organisational criteria. The Approver should then feedback the outcome of any approval activities to the analyst so that the analysis can be updated if required.\nThe exact nature of any scrutiny made by the Approver should be proportionate to the impact of the analysis, the governance process of their programme/ organisation, and follow the principles of proportionality described in Chapter 3 of this document.\nTo ensure that the analysis is used as intended, the Commissioner should use the analysis as specified at the start of the analytical cycle, applying any limitations to its use as described by the Analyst.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#communication",
    "href": "delivery_and_communication.html#communication",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.4 Communication",
    "text": "9.4 Communication\nThe effective and transparent communication is essential to enable analysis to be adopted and trusted by the Commissioner and onward users. Depending on its final use and likelihood of publication, any analysis may be communicated to a wide audience including:\n\nCommissioners and users of the analysis;\n\nExternal scrutiny including the Public Accounts Committee, the National Audit Office, internal and external audit;\n\nThe public, through publications and Freedom of Information Act requests;\n\nAcademic experts, possibly through a departmental Areas of Research Interest document.\nGovernmental partners - both national and international\n\nThe form of communication should be tailored to the audience. The communication should be quality assured in a proportionate manner to ensure an accurate reflection of the analytical results.\nThe Analysis Function’s Making Analytical Publications Accessible Toolkit gives guidance to help ensure that any that websites, tools, and technologies produced from analysis are designed and developed so that people with disabilities can use them. More specifically, people can: perceive, understand, navigate, and interact with the web.\nIf publishing the outcome of any analysis is required, the analyst should follow departmental and statutory guidance.Some examples are given below:\n\nIf you are publishing statistics you will need to follow your organisation’s guidance and the regulatory guidance for publishing official statistics and national statistics ;\n\nIf you are publishing research, you shall follow your organisations guidance and the Government Social Research Publication protocol;\n\nIf you are publishing an evaluation, refer to any recommendations from the Evaluation Task Force;\n\n\n9.4.1 Sign-off\nThe exact nature of the approval process may vary depending on:\n\nThe impact of the analysis;\n\nThe approval process of the organisation, and\n\nThe nature of the programme, project or board approving the analysis.\n\nThe formality of the sign-off process should be governed by organisational procedures, and be proportionate to the analysis.\nThe Approver should provide the Analyst with evidence that the analysis outputs have been properly reviewed and formally approved. For example, through the notes of a project/programme board where the decision to approve the analysis was made or similar.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#documentation",
    "href": "delivery_and_communication.html#documentation",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.5 Documentation",
    "text": "9.5 Documentation\nWhen the Analyst and Assurer are satisfied that the analysis is ready to hand over to the Commissioner, they should ensure that any associated documentation supporting the analysis is ready and has also undergone quality assurance. Supporting documentation might include:\n\nSpecification and design documentation\nLogs of data, assumptions and decisions including their source, ownership, reliability and any sensitivity analysis carried out;\nUser and technical documentation\nAdvice on uncertainty and its impact on the outputs of the analysis;\n\nA description of the limits of the analysis and what it can and cannot be used for;\n\nAny materials for presenting the analysis to the Commissioner, for example slide decks or reports;\n\nA record of the analysis including methods used, dependencies, process maps, change and version control logs and error reporting;\n\nThe code-base, when it has been agreed to publish the analysis openly\nThe test plan and results of the tests made against that plan;\n\nA statement of assurance;\n\nA statement that ethical concerns have been addressed, especially for the application of black-box models;",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#treatment-of-uncertainty-in-the-delivery-communication-and-sign-off-stage",
    "href": "delivery_and_communication.html#treatment-of-uncertainty-in-the-delivery-communication-and-sign-off-stage",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.6 Treatment of uncertainty in the delivery, communication and sign-off stage",
    "text": "9.6 Treatment of uncertainty in the delivery, communication and sign-off stage\nGovernment has produced a range of guidance to support analysts in presenting and communicating uncertainty in analysis. This includes:\n\nThe Office for Statistical Regulation’s Approaches to presenting uncertainty in the statistical system;\nThe Uncertainty Toolkit for Analysts;\n\nThe Government Analysis Function guidance note Communicating quality, uncertainty and change;\n\nEach provides valuable advice on how to estimate and present uncertainty when describing the limitations of use of a piece of analysis.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#black-box-models-and-the-delivery-communication-and-sign-off-stage",
    "href": "delivery_and_communication.html#black-box-models-and-the-delivery-communication-and-sign-off-stage",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.7 Black-box models and the delivery, communication and sign-off stage",
    "text": "9.7 Black-box models and the delivery, communication and sign-off stage\nThe Approver is responsible for signing-off that all risks and ethical considerations around the use of black-box models have been addressed. The aspects to be considered are detailed in the Introduction to AI assurance.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#multi-use-models-and-the-delivery-communication-and-sign-off-stage",
    "href": "delivery_and_communication.html#multi-use-models-and-the-delivery-communication-and-sign-off-stage",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.8 Multi-use models and the delivery, communication and sign-off stage",
    "text": "9.8 Multi-use models and the delivery, communication and sign-off stage\nThere is a greater risk that multi-use models may be used for purposes outside the intended scope. This places a greater onus on the Analyst to clearly communicate to all users the limitations and intended use. The Analyst may consider testing communication with different user groups to ensure that the analytical outputs are used as intended.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#analytical-transparency",
    "href": "delivery_and_communication.html#analytical-transparency",
    "title": "9  Delivery, communication and sign-off",
    "section": "9.9 Analytical transparency",
    "text": "9.9 Analytical transparency\nEnabling the public to understand and scrutinise analysis promotes public confidence in decisions. This includes providing the the public with information on models used for business-critical decisions and making analysis open. Further guidance on transparency can be found here.\n\n9.9.1 Business-critical analysis register\nThis section applies to publishing lists of business critical analysis (BCA), including models.\n\nDepartments and Arm’s Length Bodies1 (ALBs) should publish a list of BCA in use within their organisations at least annually.\nEach department and ALB should decide what is defined as business critical based on the extent to which they influence significant financial and funding decisions; are necessary to the achievement of a departmental business plan, or where an error could lead to serious financial, legal or reputational damage.\nDepartments and ALBs should align their definitions and thresholds of business criticality with their own risk framework respectively. The thresholds should be agreed by the Director of Analysis or equivalent.\nALB’s are responsible for publishing their own BCA list, unless agreed otherwise with the department. The ALB’s Accounting Officer is accountable for ensuring publication and the sponsor department’s AO oversees this.\nThe BCA lists should include all business-critical analysis unless there is an internally documented reason that the analysis should be excluded, agreed with the Director of Analysis (or equivalent) and the agreement documented.\nJustification for not publishing a model in the list may include exemptions under the Freedom of Information (FOI) Act 2000 where relevant, for example, including, but not limited to: National Security, policy under development or prejudicing commercial interests.\nIn addition to these exemptions, there may be further reasons where the risk of negative consequence is deemed to outweigh the potential benefits resulting from publication of the model. One example is where population behaviour may change in response to awareness of a model or modelling.\nFor clarity, the name of model/analysis and what it is used for should be included, alongside links to published material.\nTo ensure the list is accessible, content and structure should follow guidance for writing plainly\n\n\n\n9.9.2 Open publishing of analysis\nTo facilitate public scrutiny, departments may choose to make analysis/models (e.g. source code or spreadsheets) and details which may include data, assumptions, methodology and outputs open to the public. Open publishing source code and other elements of analysis allows others to reuse and build on the work (https://www.gov.uk/service-manual/service-standard/point-12-make-new-source-code-open). Practical guidance to open coding can be found here.\nPublication of analysis should also draw on the guidance for BCA lists related to accessibility and justification for when publication may not be appropriate. For analysis that is extremely complex in nature, it may be more appropriate to publish summary information instead, to aid the accessibility.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#footnotes",
    "href": "delivery_and_communication.html#footnotes",
    "title": "9  Delivery, communication and sign-off",
    "section": "",
    "text": "ALBs include executive agencies, non-departmental public bodies and non-ministerial departments, please see Cabinet Office guidance on Classification of Public Bodies↩︎",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery, communication and sign-off</span>"
    ]
  },
  {
    "objectID": "additional_resources.html",
    "href": "additional_resources.html",
    "title": "10  Additional resources",
    "section": "",
    "text": "10.1 Written resources\nThe additional resources referred to within the AQuA Book are collated here for easy reference.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Additional resources</span>"
    ]
  },
  {
    "objectID": "additional_resources.html#written-resources",
    "href": "additional_resources.html#written-resources",
    "title": "10  Additional resources",
    "section": "",
    "text": "10.1.1 Guidance and advice for performing analysis\n\nUncertainty Toolkit for Analysts in Government;\n\nThe National Audit Office Framework to review models is relevant throughout. It provides a structured approach to review models which organisations can use to determine whether the modelling outputs they produce are reasonable, robust and have a minimal likelihood of errors being made;\n\nAdvice for policy professionals using statistics and analysis – Government Analysis Function (Chapter 9) This guidance aims to help policy professionals work effectively with statisticians and other analysts. It introduces some important statistical ideas and concepts to help policy professionals ask the right questions when working with statistical evidence.\n\nData Ethics Framework (Chapter 9). The Data Ethics Framework guides appropriate and responsible data use in government and the wider public sector. It helps public servants understand ethical considerations, address these within their projects, and encourages responsible innovation.\n\nGovernment Data Quality Framework (Chapter 4) The framework developed by Government to support and enable the production of sustainable high quality data.\n\nUrgent data quality assurance guidance (Chapter 4) This guidance covers the minimum steps you should do for urgent data work. It is intended as a last resort, it does not replace full and thorough quality assurance practices.\n\n\n\n10.1.2 Reproducible analytical pipelines\n\nQuality assurance of code for analysis and research (Chapters 2 and 7) sets out good practices for writing reproducible and well documented code for analytical workflows.\n\nReproducible Analytical Pipelines (Chapters 2 and 7) sets out what a Reproducible Analytical Pipeline is and points to resources for analysts who need to build them.\n\n\n\n10.1.3 Model quality assurance\n\nDepartment for Energy Security and Net Zero modelling tools and QA guidance provides resources to help quality assure new and existing models, including those developed by third parties;\n\nArtificial Intelligence Quality Assurance;\n\nCross government guidance on roles and responsibilities.\n\n\n\n10.1.4 Guidance and advice for communicating analysis\nThe Office for Statistical Regulation’s Approaches to presenting uncertainty in the statistical system;\n* The Uncertainty Toolkit for Analysts;\n* The Government Analysis Function guidance note Communicating quality, uncertainty and change;\nThe Analysis Function’s Making Analytical Publications Accessible Toolkit gives guidance to help ensure that any that websites, tools, and technologies produced from analysis are designed and developed so that people with disabilities can use them. More specifically, people can: perceive, understand, navigate, and interact with the web.\nIf you are publishing statistics you will need to follow your organisation’s guidance and the regulatory guidance for publishing official statistics and national statistics;\n* If you are publishing research, you shall follow your organisations guidance and the Government Social Research Publication protocol;\n* If you are publishing an evaluation, refer to any recommendations from the Evaluation Task Force;\n* If you are publishing information about business-critical models you should follow PLACEHOLDER.\n\n\n10.1.5 External sources of quality assurance\nThe Government Actuary’s Department (GAD) can provide expert quality assurance reviews of models across the public sector. GAD are a team of financial risk professionals and are experts in reviewing models on all modern platforms, including Excel, R, and Python. As a non-ministerial department, GAD can offer unique support from within government.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Additional resources</span>"
    ]
  },
  {
    "objectID": "accessibility_statement.html",
    "href": "accessibility_statement.html",
    "title": "Accessibility statement",
    "section": "",
    "text": "Important\n\n\n\nThis version of the AQuA book is a preliminary ALPHA draft. It is still in development, and we are still working to ensure that it meets user needs. At this stage, the site does not fully incorporate requirements from accessibility legislation.\nThe draft currently has no official status. It is a work in progress and is subject to further revision and reconfiguration (possibly substantial change) before it is finalised.\n\n\nThis accessibility statement applies to this online version of the AQuA Book. Please note that this does not include third-party content that is referenced from this guidance.\nThe website is managed by the Quality and Improvement division of the Office for National Statistics.\nWe would like this guidance to be accessible for as many people as possible. This means that you should be able to:\n\nchange colours, contrast levels and fonts\nzoom in up to 300% without the text spilling off the screen\nnavigate most of the website using just a keyboard\nnavigate most of the website using speech recognition software\nlisten to most of the website using a screen reader (including the most recent versions of JAWS, NVDA and VoiceOver)\n\nFor keyboard navigation, {kbd}Up Arrow and {kbd}Down Arrowkeys can be used to scroll up and down on the current page. {kbd}Left Arrow and {kbd}Right Arrow keys can be used to move forwards and backwards through the pages of the book. Tabbed content (including code example) can be focused using the {kbd}Tab key. {kbd}Left Arrow and {kbd}Right Arrow keys are then used to focus the required tab option, where {kbd}Enter can be used to select that option and display the associated content.\n\nHelp us improve this book\nWe’re always looking to improve the accessibility of our guidance.\nIf you find any problems not listed on this page or think that we’re not meeting accessibility requirements, please contact us by emailing AQUA Book. Please also get in touch if you are unable to access any part of this guidance, or require the content in a different format.\nWe will consider your request and aim to get back to you within five working days.\n\n\nEnforcement procedure\nThe Equality and Human Rights Commission (EHRC) is responsible for enforcing the Public Sector Bodies (Websites and Mobile Applications) (No. 2) Accessibility Regulations 2018 (the ‘accessibility regulations’). If you’re not happy with how we respond to your complaint, you should contact the Equality Advisory and Support Service (EASS).",
    "crumbs": [
      "Accessibility statement"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Glover, Paul. 2014. Verification and Validation for the AQuA\nBook. DSTL Portsdown West Portsdown Hill Road Fareham PO17 6AD: HM\nGovernment. https://www.gov.uk/government/publications/verification-and-validation-for-the-aqua-book.\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.\n\n\n(For information, not part of the draft: example of a citation reference linked to references.bib file: See Knuth (1984) for additional discussion of literate programming. )",
    "crumbs": [
      "References"
    ]
  }
]