[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "The AQuA Book",
    "section": "",
    "text": "Important\n\n\n\nThis version of the AQuA book is a preliminary ALPHA draft. It is still in development, and we are still working to ensure that it meets user needs.\nThe draft currently has no official status. It is a work in progress and is subject to further revision and reconfiguration (possibly substantial change) before it is finalised.\n\n\n\nPreface\nThe last version of the Analytical Quality Assurance (AQuA) Handbook was published in 2015, following Sir Nicholas Macpherson’s Review of quality assurance of government models. Since then, assurance has become part of the fabric of good practice for developing evidence to support policy development, delivery and operational excellence. The AQuA Book has made a significant contribution to the cultural change in assurance practices in government.\nThe AQuA Book is about the process for assuring analytical evidence in all forms. It sets out the core framework for assuring all forms of analytical evidence. It describes what you need to do but not how to do it, aqlthough it does contain many worked examples. Large organisations will have their own processes and practices covering “the how”. For those of you who do not work in places with bespoke guidance you will find a collection of helpful resources in chapter 10.\nThe AQuA Book is a key supporting guide for the Analysis Function Standard. It is referred to by the Green Book, Magenta Book and Finance Function Standards.\n\n\nAcknowledgements\nThe AQuA Book is the work of many authors from across the Government Analysis Function. The original version of the book was compiled by the Quality Assurance Working Group set up after Sir Nicholas Macpherson’s review of modelling in government. This revised edition of the book was produced by a task and finish group drawn from across the Analysis Function community. We would like to thank everybody who has given of their time and expertise to produce this revised edition.",
    "crumbs": [
      "Preface"
    ]
  },
  {
    "objectID": "forward.html",
    "href": "forward.html",
    "title": "Forward",
    "section": "",
    "text": "Important\n\n\n\nThis version of the AQuA book is a preliminary ALPHA draft. It is still in development, and we are still working to ensure that it meets user needs.\nThe draft currently has no official status. It is a work in progress and is subject to further revision and reconfiguration (possibly substantial change) before it is finalised.\n\n\nThis guidance uses the following terms to indicate whether recommendations are mandatory or advisory.\nThe terms are:\n\n‘shall’ denotes a requirement, which applies in all circumstances, at all times\n‘should’ denotes a recommendation, to be met on a ‘comply or explain’ basis\n‘may’ denotes approval\n‘might’ denotes a possibility\n‘can’ denotes both capability and possibility\nis/are is used for a description\n\nThese are the same terms as those in the UK Government functional standards.",
    "crumbs": [
      "Forward"
    ]
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "1.1 Who is the AQuA Book for?\nIn this edition we have tried to make our guidance relevant to anyone who commissions, uses, undertakes or assures analysis. It is about the whole process of producing analysis that is fit for purpose and not just about the checks after the analysis has been completed.\nWe would like to see analysts from all backgrounds using this book. Our intended audience includes;",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#who-is-the-aqua-book-for",
    "href": "intro.html#who-is-the-aqua-book-for",
    "title": "1  Introduction",
    "section": "",
    "text": "customers – helping you to get the most out of your commission;\nmembers of the government analytical professions. This might include:\n\nfinance professionals making spending forecasts\nsocial researchers carrying out qualitative research\ndata scientists developing advanced analytics;\nand anyone else carrying out analysis.\n\nsenior leaders with an interest in analytical assurance.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#why-should-i-pay-attention-to-this-guidance",
    "href": "intro.html#why-should-i-pay-attention-to-this-guidance",
    "title": "1  Introduction",
    "section": "1.2 Why should I pay attention to this guidance?",
    "text": "1.2 Why should I pay attention to this guidance?\nHere are a few reasons why.\n\nYour analytical insights will be used for major decisions and operations. You need to do your best to get them right, thus minimising the risk of being complicit in causing operational, business or reputational damage;\nTrust is hard to obtain but easy to lose. A simple error that could have been prevented by assurance could lead to your and your team’s work being doubted;\nPrevention is better than cure. Analysis is more likely to be right first time when you consider quality from the start. Having appropriate quality assurance in place helps to manage mistakes, handle changes to requirements and ensure appropriate re-use;\nDelivering quality analysis provides the confidence that is needed for transparency and public openness;\nAssurance is required for audit purposes2; and,\n\nProfessional pride in your work.\n\n(For information, not part of the draft: example of a citation reference linked to references.bib file: See Knuth (1984) for additional discussion of literate programming. )\n\n\n\n\nKnuth, Donald E. 1984. “Literate Programming.” Comput. J. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "intro.html#footnotes",
    "href": "intro.html#footnotes",
    "title": "1  Introduction",
    "section": "",
    "text": "Black box: system which can be viewed in terms of its inputs and outputs (or transfer characteristics), without any knowledge of its internal workings.↩︎\nManaging Public Money, Annex 4.2 Use of models↩︎",
    "crumbs": [
      "<span class='chapter-number'>1</span>  <span class='chapter-title'>Introduction</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html",
    "href": "definitions_and_key_concepts.html",
    "title": "2  Definitions and key concepts",
    "section": "",
    "text": "Analysis\nAnalysis is the collection, manipulation and interpretation of information and data for use in decision making. Analysis can vary widely between situations and many different types of analysis may be used to form the evidence base that supports the decision-making process.\nExamples of types of analysis that are frequently encountered in government are:",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#analysis",
    "href": "definitions_and_key_concepts.html#analysis",
    "title": "2  Definitions and key concepts",
    "section": "",
    "text": "actuarial\n\ndata science\neconomic\nfinancial\n\ngeographical\noperational research\nscientific, technical and engineering research\n\nstatistical\n\nsocial research",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#assurance",
    "href": "definitions_and_key_concepts.html#assurance",
    "title": "2  Definitions and key concepts",
    "section": "Assurance",
    "text": "Assurance\nAnalytical assurance is the process and set of practices to ensure that the analysis is fit for purpose.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#assurance-activities",
    "href": "definitions_and_key_concepts.html#assurance-activities",
    "title": "2  Definitions and key concepts",
    "section": "Assurance activities",
    "text": "Assurance activities\nAssurance activities are anything that is undertaken to validate and verify analysis\nFor example:\n\nanalyst testing\n\npeer review\n\nanalytical audits",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#business-critical-analysis",
    "href": "definitions_and_key_concepts.html#business-critical-analysis",
    "title": "2  Definitions and key concepts",
    "section": "Business critical analysis",
    "text": "Business critical analysis\nBusiness critical analysis is defined as analysis which plays such a role in decision making that it influences significant financial and funding decisions, is necessary to the achievement of a Departmental business plan, or an error could have a significant reputational, economic or legal impact for the public sector.\nVersion 1 of the AQuA book described business critical models. This has been generalised to business critical analysis, as it is possible for analysis to be business critical without including a model. Some departments may continue to use the term business critical models (BCM).",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#change-control",
    "href": "definitions_and_key_concepts.html#change-control",
    "title": "2  Definitions and key concepts",
    "section": "Change control",
    "text": "Change control\nChange control is the set of processes followed when changes are made to a piece of analysis. For example, version numbering, documentation, assurance of changes.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#documentation",
    "href": "definitions_and_key_concepts.html#documentation",
    "title": "2  Definitions and key concepts",
    "section": "Documentation",
    "text": "Documentation\n\nSpecification documentation\nThis documentation captures the initial engagement with the commissioner and identifies the question, the context, and any boundaries of the analysis. It provides a definition of the scope and a mechanism for agreeing the project constraints, e.g., deadlines, available resources, and capturing what level of assurance is required by the commissioner.\n\n\nDesign documentation\nThis document outlines the design of the analysis, including conceptual models to illustrate the analytical problem, and forms an important tool for ensuring that the analytical assurer has the confidence that the analyst can deliver quality analysis.\n\n\nAssumptions log\nA register of assumptions whether provided by the commissioner or derived by the analysis that have been risk assessed and signed off by an appropriate governance group or stakeholder. Assumption logs should describe each assumption, quantify its impact and reliability and set out when it was made, why it was made, who made it and who signed it off.\n\n\nDecisions log\nA register of decisions whether provided by the commissioner or derived by the analysis that have been risk assessed and signed off by an appropriate governance group or stakeholder. Decisions logs should describe each decision and set out when it was made, why it was made, who made it and who signed it off.\n\n\nData log\nA register of data provided by the commissioner or derived by the analysis that have been risked assessed and signed-off by an appropriate governance group or stakeholder.\n\n\nQuality assurance plan\nA detailed plan of what verification and validation activities should be produced identifying the key risk areas within the analysis. This should be thought about throughout the analytical lifecycle, from initial scoping, designing the analysis, to delivering the analysis. The areas identified in the plan can also form the basis of a log for those analysts conducting the verification and validation checks. Any additional verification and validation checks that have been performed should be recorded on the quality assurance plan.\n\n\nUser / technical documentation\nAll analysis shall have user-documentation, even if the user is only the analyst leading the analysis. This is to ensure that they have captured sufficient material to assist them if the analysis is revisited in due course. For analysis that is likely to be revisited or updated in the future, documentation should be provided to assist a future analyst and should be more comprehensive. This documentation should include a summary of the analysis including the context to the question being asked, what analytical methods were considered, what analysis was planned and why, what challenges were encountered and how they were overcome and what verification and validation steps were performed. In addition, guidance on what should be considered if the analysis is to be revisited or updated is beneficial.\n\n\nVersion control\nIt is important to ensure that changes that have been made to analysis can be easily seen and quality assured by the analytical assurer, and the latest version of the analysis is being used. Tools and templates can be used to support with evidencing updates and the checks completed throughout a project providing a log of changes that have occurred, why, when, and by whom.\n\n\nAssurance statement\nA brief description of the analytical assurance that have been performed to assure the analysis. The statement should refer to known limitations and conditions associated with the analysis.\n\n\n\n\n\n\nExample of publishing quality assurance tools\n\n\n\nThe Department for Energy Security and Net Zero and Department for Business and Trade have published a range of quality assurance tools and guidance to help people with Quality Assurance of analytical models. Modelling Quality Assurance tools and guidance are used across the two departments to ensureanalysis meets the standards set out in the AQuA book and provide assurance to users of the analysis that proportionate quality assurance has been completed.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#materiality",
    "href": "definitions_and_key_concepts.html#materiality",
    "title": "2  Definitions and key concepts",
    "section": "Materiality",
    "text": "Materiality\nMateriality is a concept or convention in auditing and accounting relating to the importance of a feature. Information is said to be material if omitting it or misstating it could influence decisions that users make. Materiality is “an entity-specific aspect of relevance, based on size, magnitude or both”.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#multi-use-models",
    "href": "definitions_and_key_concepts.html#multi-use-models",
    "title": "2  Definitions and key concepts",
    "section": "Multi-use models",
    "text": "Multi-use models\nSome models, often complex and large, are used by more than one user or group of users for related but differing purposes, these are known as multi-use models.\nOften, a Steering Group is created to oversee the analysis. This Steering Group would be chaired by the senior officer in charge of the area that maintains the model, and contain senior, ideally empowered, representatives of each major user area.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#principles-of-analytical-quality-assurance",
    "href": "definitions_and_key_concepts.html#principles-of-analytical-quality-assurance",
    "title": "2  Definitions and key concepts",
    "section": "Principles of analytical quality assurance",
    "text": "Principles of analytical quality assurance\nNo single piece of guidance provides a definitive assessment of whether a piece of analysis is of sufficient quality for an intended purpose. However, the following principles support commissioning and production of fit-for-purpose analysis:\nProportionate: Quality assurance effort should be appropriate to the risk associated with the intended use of the analysis and the complexity of the analytical approach. These risks include financial, legal, operational and reputational impacts. More details can be found in chapter [3]\nAssurance throughout development: Quality assurance should be considered throughout the life cycle of the analysis and not just at the end. Effective communication is crucial when understanding the problem, designing the analytical approach, conducting the analysis and relaying the outputs. More details on the analysis life cycle can be seen in chapter [5].\nVerification and validation: Analytical quality assurance is more than checking that the analysis is error-free and satisfies its specification (verification). It should also include checks that the analysis is appropriate, i.e. fit for the purpose for which it is being used (validation). Validation and verification are covered in more depth in chapters [5-9].\nAccept that uncertainty is inherent in the inputs and outputs of any piece of analysis. Chapter [8] covers assurance of the analytical phase of the project, including the treatment of uncertainty . Further support can be found in the Uncertainty Toolkit for Analysts in Government (analystsuncertaintytoolkit.github.io)\nAnalysis with RIGOUR: One acronym some users find helpful to consider when completing analysis is RIGOUR. This is described in the box below.\n\n\n\n\n\n\nRIGOUR\n\n\n\n\n\nThroughout all the stages of an analytical project, the analyst should ask questions of their own analysis. The helpful mnemonic “RIGOUR” may assist:\n\nRepeatable\nIndependent\nGrounded in reality\nObjective\nUncertainty-managed\nRobust\n\nRepeatable: For an analytical process to be considered valid we might reasonably expect that the analysis produces the same outputs for the same inputs and constraints. Different analysts might approach the analytical problem in different ways, while methods might include randomised processes. In such cases, exact matches are not guaranteed or expected. Taking this into account, repeatability means that if an approach is repeated the results should be as expected.\nIndependent: Analysis should be free of prejudice or bias. Care should be taken to balance views appropriately across all stakeholders and experts.\nGrounded in reality: Quality analysis takes the Commissioner and Analyst on a journey as views and perceptions are challenged and connections are made between the analysis and its real consequences. Connecting with reality like this guards against failing to properly grasp the context of the problem that is being analysed.\nObjective: Effective engagement and suitable challenge reduce the risk of bias and enables the Commissioner and the Analyst to be clear about the interpretation of results.\nUncertainty-managed: Uncertainty is identified, managed and communicated throughout the analytical process.\nRobust: Analytical results are error free in the context of residual uncertainty and accepted limitations that make sure the analysis is used appropriately.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#quality-analysis",
    "href": "definitions_and_key_concepts.html#quality-analysis",
    "title": "2  Definitions and key concepts",
    "section": "Quality analysis",
    "text": "Quality analysis\nQuality analysis is analysis which is fit for the purpose(s) it was commissioned to meet. It should be accurate, have undergone appropriate assurance, be evidenced, proportionate to its impact, adequately communicated, documented and accepted by its commissioners.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#reproducible-analytical-pipelines",
    "href": "definitions_and_key_concepts.html#reproducible-analytical-pipelines",
    "title": "2  Definitions and key concepts",
    "section": "Reproducible analytical pipelines",
    "text": "Reproducible analytical pipelines\nReproducible Analytical Pipelines (RAPs) are automated analytical processes. They incorporate elements of software engineering best practice to ensure that the pipelines are reproducible, auditable, efficient, and high quality.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#roles-and-responsibilities",
    "href": "definitions_and_key_concepts.html#roles-and-responsibilities",
    "title": "2  Definitions and key concepts",
    "section": "Roles and responsibilities",
    "text": "Roles and responsibilities\nOrganisations may have their own titles for the main functional roles involved in analysis that are* set out here.\nEach role may be fulfilled by a team or committee of people. However, a single individual will have overall accountability (such as the chair of a committee) for each role.\nThe AQuA book defines the roles as:\n\nCommissioner (may be known as customer)\n\nRequests the analysis and sets out their requirements\n\nAgrees what the analyst is going to do will satisfy the need\n\nAccepts the analysis and assurance as fit for purpose\n\nAnalyst\n\nDesigns the approach, including the assurance, to meet the commissioner’s requirements\nAgrees the approach with the commissioner\nCarries out the analysis\nCarries out their own assurance\n\nActs on findings from the assurer\nCan be a group of analysts, in which case the lead analyst is responsible\n\nAssurer (may be known as Analytical Assurer, Assuring Analyst, or Model Senior Responsible Owner (“SRO”))\n\nReviews the assurance completed by the analyst\n\nCarries out any further validation and verification they may see as appropriate\n\nReports errors and areas for improvement to the analyst\n\nRe-reviews as required\n\nConfirms the work has been appropriately scoped, executed, validated and verified and documented to the approver\n\nCan be a group of assurers. In which case the leader of the group is responsible. They must be independent from the analysts.\n\nApprover (may be known as Senior Analyst or Senior Responsible Officer (“SRO”))\n\nScrutinises the work of the analyst and assurer\n\nConfirms (if necessary) to the analyst, assurer and commissioner that the work has been appropriately assured\n\nThe roles of analyst and analytical assurer shall be distinct from each other. The analyst should carry out their own assurance but responsibility for formal assurance to the commissioner lies with the assurer.\n\nIn instances, particularly for quick and / or simple analysis, an individual may deliver more than one of the roles.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#uncertainty",
    "href": "definitions_and_key_concepts.html#uncertainty",
    "title": "2  Definitions and key concepts",
    "section": "Uncertainty",
    "text": "Uncertainty\nThe outcome of a decision is never known perfectly in advance. For each option within analysis, a range of real outcomes is possible: the outcome is uncertain.\n\n\n\n\n\n\nDefining uncertainty\n\n\n\nWikipedia defines uncertainty as referring to epistemic situations involving imperfect or unknown information. It applies to predictions of future events, to physical measurements that are already made, or to the unknown.\n\n\nThere are different types of uncertainty. A common classification divides uncertainty into known knowns, known unknowns, and unknown unknowns. The type of uncertainty will impact the analytical approach and assurance activities required.\nThe Uncertainty Toolkit for Analysts in Government is a tool produced by a cross government group to help assessing and communicating uncertainty.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#validation",
    "href": "definitions_and_key_concepts.html#validation",
    "title": "2  Definitions and key concepts",
    "section": "Validation",
    "text": "Validation\nAdd definition of validation.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "definitions_and_key_concepts.html#verification",
    "href": "definitions_and_key_concepts.html#verification",
    "title": "2  Definitions and key concepts",
    "section": "Verification",
    "text": "Verification\nAdd definition of verification.",
    "crumbs": [
      "<span class='chapter-number'>2</span>  <span class='chapter-title'>Definitions and key concepts</span>"
    ]
  },
  {
    "objectID": "proportionality.html",
    "href": "proportionality.html",
    "title": "3  Proportionality",
    "section": "",
    "text": "3.1 Introduction\nThink about and deliver appropriate (proportionate) levels of assurance for your analysis. There is a need to be confident in analysis delivered, but there is no point spending months assuring simple analysis that will inform a decision that will make minimal impact.\nTable 1 provides a list of key factors that should be considered when determining what level of assurance is appropriate.\nFurther detail and considerations may be found on the Analysis Function’s Quality Questions and Red Flags page.\nFigure 1 shows some assurance techniques that might be considered for different levels of analysis complexity and business risk. The key message is the need for more assurance interventions increases with the complexity of, and the business risk associated with analysis.\nThe interventions in Figure 1 must not be viewed in isolation. Some complex and risky analysis that would benefit from an external review will still require the interventions closer to the axes, for example version control and analyst led testing.\nOne way to view assurance interventions would be to consider individual interventions in a layer. An individual intervention will reduce risks in a particular area, but will leave many other risks unmitigated. Adding more interventions (layers) will start to increase coverage and reduce overall risk.\nThe total elimination of risk will never be achievable, and the balance needs to be found that reduces the overall business risk to an acceptable level. The diagram indicates a few practical assurance techniques. In practice there are many different techniques that need to be considered and implemented as appropriate. Refer to the table in chapter 10.\nMany of these interventions are mentioned elsewhere in the AQUA Book, and are not repeated here.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "proportionality.html#introduction",
    "href": "proportionality.html#introduction",
    "title": "3  Proportionality",
    "section": "",
    "text": "Table 1 - Factors for determining appropriate assurance\n\n\n\n\n\n\nFactor\nComments\n\n\n\n\nBusiness criticality\nDifferent issues will vary their financial, legal, operational, political and reputational impacts.\n\n\nRelevance of the analysis to the decision making process\nWhen analysis forms only one component of a broad evidence base, less assurance is required for that specific analysis than if the decision is heavily dependent on the analysis alone. Significant assurance is still likely to be required for the evidence base.\n\n\nType and complexity of analysis\nHighly complex analysis requires more effort to assure. The nature of that analysis may also require the engagement of appropriate subject matter experts.\n\n\nNovelty of approach\nA previously untried method requires more assurance. Confidence will grow as the technique is repeatedly tested.\n\n\nPrecision of the analysis outputs\nImprecise analysis can require different assurance than precise analysis, e.g. because of inherent limitations of the analytical technique, or lack of data on assumptions.\n\n\nAmount of resource available for the analysis and assurance\nThe value for money of any additional assurance must be balanced alongside the benefits and risk appetite that exists. Approaches that underpin a lot of different things may require greater levels of QA than might be suggested by any individual decision they support.\n\n\nLongevity of the analysis\nChange control.\n\n\nRepeat runs for the same analysis\nControl and assurance of data and parameters for each run\n\n\n\n\n\n\n\nFigure 1 - Types of quality assurance",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "proportionality.html#structured-assessment-of-business-risk-and-complexity",
    "href": "proportionality.html#structured-assessment-of-business-risk-and-complexity",
    "title": "3  Proportionality",
    "section": "3.2 Structured assessment of business risk and complexity",
    "text": "3.2 Structured assessment of business risk and complexity\nTo guide what assurance is needed it is necessary to take a structured approach when reviewing business risks. Business risk should be viewed as the combination of the potential impact of analysis errors, and the likelihood of errors occurring. In situations where the potential business impact is high, it is more important that the likelihood of errors is reduced.\nThis can be visualised by considering the situation as a risk matrix, illustrated in Figure 2. The impact of the analysis will usually be beyond the control of the analyst to change, so there will be few options to move an assessment down the table. However, there will usually be treatments (or mitigations), involving additional assurance measures, that will allow the assessed business risk to move to the left.\n\n\n\n\n\n\n\nLikelihood of errors occurring\n\n\n\nImpact of errors occurring\n\n\n\n\n\n\nHighly Unlikely\n\n\nUnlikely\n\n\nRealistic possibility\n\n\nLikely or probably\n\n\nHighly likely\n\n\n\n\n\n\nCritical\n\n\nMedium\n\n\nMedium\n\n\nHigh\n\n\nHigh\n\n\nHigh\n\n\n\n\n\n\nSevere\n\n\nLow\n\n\nMedium\n\n\nMedium\n\n\nHigh\n\n\nHigh\n\n\n\n\n\n\nMajor\n\n\nLow\n\n\nMedium\n\n\nMedium\n\n\nMedium\n\n\nHigh\n\n\n\n\n\n\nModerate\n\n\nVery Low\n\n\nLow\n\n\nMedium\n\n\nMedium\n\n\nMedium\n\n\n\n\n\n\nMinor\n\n\nVery Low\n\n\nVery Low\n\n\nLow\n\n\nLow\n\n\nMedium\n\n\n\nTable X shows appropriate responses to a risk assessment. Where business risk is high, appropriate treatment(s) must be considered to reduce the probability of errors occurring. The choice of treatment will depend on the mitigations already in place and on the complexity of the analysis (see Figure 1). For a situation where simple analysis is being employed, a review by an appropriate expert may be sufficient as the additional mitigation. However, for complex analysis that is already employing a wide range internal assurance measures, options like external peer review may be necessary. For situations where the business risk is ‘very low’, there would be very little benefit in applying further assurance mitigations, . Aalthough to avoid the risk growing it remains important to ensure existing or planned mitigations aren’t lost.\nIn cases where there is a need for analysis, but there are also significant time and/or resource constraints, it may not be possible to do as much assurance as usual. In these situations, the focus should be on areas of greatest risk. These risks and limitations must also be communicated, along with appropriate caveats.\n\nTable X - Responses to risk assessment levels\n\n\n\n\n\n\nAssessed risk\nMitigations to consider\n\n\n\n\nHigh - Red\nThe risk should not be tolerated. New assurance measures must be considered to treat (mitigate) the likelihood of errors occurring. If treatment isn’t an option, consideration must be be given to terminating or transferring the (analysis) risk. If it remains necessary to tolerate the risk the SRO needs to fully understand the risk.\n\n\nMedium - Amber\nThe risk should not be tolerated without SRO agreement. New assurance measures should be put in place to treat (mitigate) the likelihood of errors occurring. Continue with planned or existing mitigations.\n\n\nLow - Yellow\nThe risk can be tolerated. Existing or planned mitigations should be continued, and new treatments may be considered.\n\n\nVery Low - Green\nThe risk can be tolerated. Existing/planned mitigations measures should be continued.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "proportionality.html#externally-commissioned-work",
    "href": "proportionality.html#externally-commissioned-work",
    "title": "3  Proportionality",
    "section": "3.3 Externally commissioned work",
    "text": "3.3 Externally commissioned work\nProportionate assurance of externally commissioned work is just as important as for internally produced analysis. For the commissioner, to use the work they should be fully informed of the business risk associated with it. This should be provided by an appropriate mix of documented risk assessments provided as part of the work, and by joint risk assessments planned throughout the life of the project. For commissioned work the options for mitigation will be similar to those for internal analysis.\nThe difference will be in ensuring the assessment of risks and the applied mitigations are fully understood by the commissioner.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "proportionality.html#artificial-intelligence",
    "href": "proportionality.html#artificial-intelligence",
    "title": "3  Proportionality",
    "section": "3.4 Artificial intelligence",
    "text": "3.4 Artificial intelligence\nIncreasingly analysis may be underpinned by Artificial Intelligence (AI). With AI-informed analysis the need to understand business risk remains, and the same structured approach to assessing business risk should be taken. The challenges in providing this assessment will be in ensuring the transparency of the analysis, availability of a suitable mix of experts, and developing understanding of what mitigations are possible.",
    "crumbs": [
      "<span class='chapter-number'>3</span>  <span class='chapter-title'>Proportionality</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html",
    "href": "quality_assurance_culture.html",
    "title": "4  Quality assurance culture",
    "section": "",
    "text": "4.1 Leadership\nA quality assurance culture starts with senior leaders. They are accountable for the quality of analysis carried out in their departments. A key element of discharging this accountability is to clearly set out the priority of quality within their teams and create processes for embedding quality assurance.\nSenior leaders should ensure there is clear messaging and standards on quality assurance, through guidance, training, and regular updates. Senior leaders can demonstrate the importance of quality assurance through long term initiatives, like setting up and embedding quality assurance processes within the team and creating roles and teams to support quality assurance. Senior leaders should also regularly talk about quality with their teams and highlight quality successes.\nAs part of a strong quality assurance culture, senior leaders should empower all those in the analytical process to identify any risks to the quality of the work, ensure people at any level can raise any quality concerns, and be able to discuss and constructively challenge each other if they feel those standards are not being met. To underpin this, senior leaders should ensure teams have a common understanding of the quality standards required for their work.\nCreating transparency at all levels can help embed a culture of quality assurance. This includes peer review, open source of code (where possible), external publication of models or methods and publication of the register of Business Critical Models.\nSenior leaders should also develop processes so teams can report when things go wrong, be open and honest when issues occur, carry out reviews to understand the failures in the assurance process and share the lessons learnt across the analytical community.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#leadership",
    "href": "quality_assurance_culture.html#leadership",
    "title": "4  Quality assurance culture",
    "section": "",
    "text": "Sharing best practice on quality assurance\n\n\n\nHM Revenue and Customs have developed a Quality Champions network, made up of analysts from across the department. The network discuss quality assurance initiatives, quality issues and how they were resolved and shares wider best practice.\n\n\n\n\n\n\n\n\n\n\n\nAn open culture when things go wrong\n\n\n\nWhen the Department for Education made an error producing the schools national funding formula allocations for 2024-25, they ran a detailed internal review to understand what went wrong and why it was not detected by the QA process. The department also commissioned and published an external, independent review to assess the error and put forward recommendations. The independent review praised the team for its open learning culture and a culture of taking responsibility for mistakes.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#capacity-and-capability",
    "href": "quality_assurance_culture.html#capacity-and-capability",
    "title": "4  Quality assurance culture",
    "section": "4.2 Capacity and capability",
    "text": "4.2 Capacity and capability\nSenior leaders should create the conditions in which quality assurance processes can operate effectively, by ensuring staff have time built-in for quality assurance and documentation, can draw on expertise and experience, and have the access to the tools and data they need.\n\n4.2.1 Capacity\nThere is a risk that work, and time pressures mean teams cut corners on quality or mistakes are made as analysis is rushed. Senior leaders can mitigate this through strong prioritisation, supporting teams to push back on lower value work or by making tough choices on team wide priorities. Through this prioritisation, senior leaders can emphasise the importance of quality. Team leaders can support quality assurance, by ensuring it is considered throughout the lifecycle of a project and not simply considered at the end, and making time for adequate quality assurance even when timescales are tight.\nIf time constraints mean insufficient assurance has taken place, senior leaders should ensure this is explicitly acknowledged and reported. This should be reported via an assurance statement that sets out the known limitations and conditions associated with the analysis.\nAnalysis should be peer reviewed by independent individuals or groups, who are independent of operational management and where the review is carried out by skilled and competent persons. However, it can be difficult to identify available experts who are able to provide a review. There are several approaches to support and embed independent review, such as setting up specific teams to review and audit a sample of analytical projects, or developing assurance networks of analysts who can provide reviews when needed. Team leaders can support this by making time for analysts to carry out peer reviews and ensuring analysts are clear that supporting peer reviews is part of their role.\n\n\n\n\n\n\nHM Revenue and Customs independent review team\n\n\n\nHMRC has a small analytical team which independently reviews analysis from across the department, including a sample HMRC’s business-critical models. The reviews provide assurance for high profile analysis and support the sharing of best practice.\n\n\n\n\n4.2.2 Capability\nThere is a risk that errors occur because of a lack of skills or experience. Senior leaders can identify common skills gaps, creating training or mentoring to help fill gaps in analyst’s knowledge. Processes to support knowledge sharing, innovation and dissemination of best practice will all help develop capability. Rolling out training on departmental assurance processes can also mitigate this risk.\n\n\n\n\n\n\nBuilding assurance capability\n\n\n\nThe Department for Energy Security and Net Zero are building assurance capacity with a programme of quality assurance Colleges. The Colleges run regular virtual sessions, open to colleagues across Government and Partner Organisations.\nThese sessions include an interactive activity looking at a purposefully sabotaged model, used to introduce and familiarise colleagues with the quality assurance logbook and the departmental system of actively monitoring models through these logbooks.\nCollege participants also join the Modelling Integrity Network, as potential Assuring Analysts where these cannot be found by Lead Analysts in their own policy areas.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#tools",
    "href": "quality_assurance_culture.html#tools",
    "title": "4  Quality assurance culture",
    "section": "4.3 Tools",
    "text": "4.3 Tools\nThere is a risk that technology or analytical tools are out of date meaning analysts cannot follow best practice or must spend time fixing processing issues instead of focussing on quality. Senior leaders can support teams by making funding available for new tools or improving existing tools, working with digital/IT teams to escalate issues and gathering cross team issues.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#data",
    "href": "quality_assurance_culture.html#data",
    "title": "4  Quality assurance culture",
    "section": "4.4 Data",
    "text": "4.4 Data\nThere is a risk that data quality and data understanding cause quality issues with analysis. Senior leaders can escalate data quality issues with wider data teams, and champion and oversee changes to improve data quality.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "quality_assurance_culture.html#governance-and-control",
    "href": "quality_assurance_culture.html#governance-and-control",
    "title": "4  Quality assurance culture",
    "section": "4.5 Governance and control",
    "text": "4.5 Governance and control\nGovernance supports a strong quality assurance culture, by overseeing the management and assurance of analysis. The analysis functional standard sets out the requirements for a governance framework for analysis. Each organisation should have a defined and established approach to assurance, which should be applied proportionately to the risk and value of the activity and integrated with the organisation’s overall assurance framework. \nA governance process should include a well understood chain of responsibility and accountability. For example, the analyst producing the analysis is expected to review their own analysis and may also be required to check other people’s analysis. Senior analysts and managers are expected to provide assurance through peer review or acting as an Analytical Assurer or Approver of the analysis and requirements. Commissioners of the analysis should ask questions about quality and ensure it is fit for purpose and understand uncertainties around the analysis. Therefore, everyone involved in the analytical process has responsibility for Quality Assurance activities. These roles are further described in Chapter 2. \nProject level governance can provide oversight over a particular model or work area, allowing the Approver to ensure the analysis is fit for purpose. For example, formally agreeing assumptions will reduce the need for reworking the analysis providing more time for assurance. These groups help to instil the quality assurance culture by providing clear routes and processes where the quality of analysis can be tested and signed off. Projects governance can also fit within wider programme level governance. \nAnalytical governance boards for new, high-profile or complex pieces of analysis, can allow senior analytical leaders and experts to provide oversight and challenge of analysis and ensure best practice is followed. These groups are often cross cutting in nature, covering a range of analytical approaches and work areas. This can help ensure that innovations and new approaches are disseminated across teams, and standards are applied equally across similar work. \nWhen commissioning analysis externally, either qualitative or quantitative research, or the production of models, then the accountability for the quality sits with the commissioning department. It is the commissioning analyst’s role to ensure that quality standards are clear and being met and documented to the commissioning departments requirements. Further information can be found in the commissioning chapter.\nFor Arm’s Length Bodies (ALBs) the Accounting Officer is accountable for ensuring the requirements set out in the AQuA Book are met.\nUser groups for types of analysis can also provide assurance by setting standards and ensuring projects follow topic specific or specialised guidance, such as coding best practice.",
    "crumbs": [
      "<span class='chapter-number'>4</span>  <span class='chapter-title'>Quality assurance culture</span>"
    ]
  },
  {
    "objectID": "analytical_lifecycle.html",
    "href": "analytical_lifecycle.html",
    "title": "5  Overview of the analytical lifecycle",
    "section": "",
    "text": "5.1 The analytical lifecycle\nQuality assurance activities should take place throughout all stages of an analytical project. An effective quality assurance process involves ongoing engagement between the commissioner and the analyst to ensure an appropriate balance is maintained between time, resource and quality, and to ensure a shared understanding of the assurance activities required and risks involved.\nFigure 2 is adapted from the Government Functional Standard for Analysis. Analytical quality assurance activities should take place during every phase of the cycle and should consider proportionality, although analytical quality considerations may vary depending on project governance and the specific phase of the cycle. All projects will involve some element of every phase of the cycle, even if this is not clearly defined.\nIt is important that proportionality is considered and that there is transparency of the analytical decisions, process, limitations and changes made at each stage to enable effective assurance and communication. This should be enabled by:",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Overview of the analytical lifecycle</span>"
    ]
  },
  {
    "objectID": "analytical_lifecycle.html#the-analytical-lifecycle",
    "href": "analytical_lifecycle.html#the-analytical-lifecycle",
    "title": "5  Overview of the analytical lifecycle",
    "section": "",
    "text": "Figure 2 - The analytical cycle\n\n\n\n\n\nClear documentation of the analysis, assumptions and data; and\nClear records of the quality assurance processes and checks completed.\n\n\n5.1.1 Engagement and scoping\nAnalytical projects typically start with customer engagement although other events may trigger analytical projects. Scoping ensures that an appropriate, common understanding of the problem is defined and that expectations are aligned with what can be delivered. During this phase the Commissioner plays an important role in communicating the questions to be addressed and working with the Analyst to ensure the requirements and scope are defined and understood.\nWhere analysis requires multiple cycles, for example to develop, use and update analytical models, this phase may follow on from the Delivery and Communication phase. In these cases, the focus of this phase will be on the scope of the questions to be addressed in the next stage of the analytical project.\nMore effort may be needed to define the requirements and scope in this phase for research, evaluation or other projects that may need to seek a wider range of perspectives or for which subsequent phases and work may be delivered through a product or service.\n\n\n5.1.2 Design\nDuring the design phase, the Analyst will convert the commission into an analytical plan, including the assurance required and ensuring it is sufficient to answer the questions posed. This phase includes the communication and approval of plans produced, and some iteration between the Commissioner and the Analyst is to be expected as the analytical solution is developed and limitations understood.\nFor larger projects or those that require multiple cycles, the design phase may include consideration of the staging of work over the whole scope of the project as well as work required in each stage. Analysis plans for work that is dependent on insights from earlier stages may be high-level and necessitate a return to the design phase at a later date.\n\n\n5.1.3 Analysis\nThe analysis phase is where planned analysis is undertaken, and progress and relevance are monitored. During work, the design and plan may be amended to account for changing circumstances, emerging information or unexpected difficulties or limitations encountered, and this phase also includes maintaining appropriate records of the analysis conducted, changes, decisions and assumptions made. In some cases, changes or limitations encountered may necessitate a return to either the design or scoping phase.\nThroughout this phase, traceable documentation of the assurance activities undertaken shall also be produced.\nIn larger analytical projects, some outputs of the analysis may be completed at different times as work progresses, and aspects of other phases may therefore take place concurrently.\n\n\n5.1.4 Delivery and communication\nDuring the delivery phase, insights and analytical assurances are communicated to the Approver and then to the Commissioner, ensuring they are sufficiently understood in order for them to determine whether the format and interpretations have been appropriately assured and meet their requirements. As analytical projects frequently involve further iteration or extension this consideration may be the trigger for additional analysis.\nDepending on the commission, impact, approval processes and the nature of the project, work in this phase can vary considerably and may include summary packs, documentation to facilitate repeatability, or consideration of governance, version control and maintenance.\n\n\n5.1.5 Sign off\nAfter analysis results have been determined to meet the requirements in the delivery phase, they are formally approved for dissemination during the sign-off phase, which includes confirmation that the commission was met, documentation and evidence was captured, and appropriate assurance was conducted. This approval may be phased as work progresses and insights are produced.\nThe analytical assurer should review evidence during and after an analytical project, to confirm the following have been completed over the life cycle of the analysis:\n\nEvidence that the requirements have been captured, agreed through an appropriate governance process, and shared with the commissioner, analysts and other stakeholders.\n\nSupplementary evidence of agreement and scrutiny of assumptions, analytical requirements and design considerations, including an analytical appraisal of options with considerations to uncertainty, limitations and weaknesses.\n\nEvidence that the commissioner and the analysts have discussed options and have agreed the verification and validation activities that are proportionate to the business-critical risks.\n\nSupporting material confirming the suitability of the deployed analytical resources to both conduct the analysis and to carry out the verification and validation activities.\n\nEvidence that there has been sufficient networking between analysts as the providers of data and other evidence sources.\n\nDetailed descriptions of the verification and validation activities and their conclusions with supporting documentary evidence of the conduct of the work.",
    "crumbs": [
      "<span class='chapter-number'>5</span>  <span class='chapter-title'>Overview of the analytical lifecycle</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html",
    "href": "engagement_and_scoping.html",
    "title": "6  Engagement and scoping",
    "section": "",
    "text": "6.1 Introduction\nIf the main purpose of analysis is to cut out irrelevance and to simplify, it is essential for to identify what is relevant for a piece of analysis. The first stage of the analytical cycle is initial customer engagement and scoping identifying what the Commissioner requires and so what is relevant for the analysis. The Analyst works with the Commissioner to develop sufficient understanding of the problem to design a requisite analysis. Problem Structuring Methods, such as the Strategic Choice Approach, Rich Pictures and Systems Thinking can aid these discussions.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#the-commissioners-responsibilities-during-engagement-and-scoping",
    "href": "engagement_and_scoping.html#the-commissioners-responsibilities-during-engagement-and-scoping",
    "title": "6  Engagement and scoping",
    "section": "6.2 The Commissioner’s responsibilities during engagement and scoping",
    "text": "6.2 The Commissioner’s responsibilities during engagement and scoping\nDuring engagement, the Commissioner and the Analyst shape the analysis by developing a shared understanding of the problem and the context.\nThe Commissioner is responsible for ensuring that:\n\nKey aspects of the problem, scope, and programme constraints, are captured and clearly communicated to the Analyst.\n\nThey are available to actively engage with the Analyst to appropriately shape the work.\n\nThere is sufficient governance in place to support the analysis and its role in the wider project or programme. This is particularly important if the analysis supports business critical decisions. This proportionality may need to be revisited at the design stage if a novel or riskier approach is required (for example if AI models are used).\n\nThey understand risks where time and resource pressures constrain the approach.\n\nThey request information on uncertainty from analysts and challenge them when it is absent, inadequate or ambiguous.\n\nCommunicate to the analyst any sources of uncertainty they have identified as part of their wider considerations.\n\nIf possible, indicate in advance the consequences for decision-making of different degrees of uncertainty, as this may enable the analyst to conduct their analysis at a proportionate level.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#the-analysts-responsibilities-during-engagement-and-scoping",
    "href": "engagement_and_scoping.html#the-analysts-responsibilities-during-engagement-and-scoping",
    "title": "6  Engagement and scoping",
    "section": "6.3 The Analyst’s responsibilities during engagement and scoping",
    "text": "6.3 The Analyst’s responsibilities during engagement and scoping\nAt this stage in the analytical lifecycle, the Commissioner and Analyst should work together to design analysis that suits the Commissioner’s requirements.\nThe Analyst should create a specification document which captures the initial engagement with the Commissioner and identifies the question, the context, and any boundaries of the analysis. It should provide a definition of the scope and project constraints, for example deadlines, available resources, capturing what level of assurance is required by the Commissioner, and the degree of uncertainty allowed for decision-making.\nThe Analyst should ensure they understand any risks, underlying assumptions, and the business criticality of the analysis. The Analyst should share this specification with the customer and seek agreement on the approach.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#the-assurers-responsibilities-during-engagement-and-scoping",
    "href": "engagement_and_scoping.html#the-assurers-responsibilities-during-engagement-and-scoping",
    "title": "6  Engagement and scoping",
    "section": "6.4 The Assurer’s responsibilities during engagement and scoping",
    "text": "6.4 The Assurer’s responsibilities during engagement and scoping\nThe assurer should understand the assurance requirements and plan time in for the assurance activity.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "engagement_and_scoping.html#the-approvers-responsibilities-during-engagement-and-scoping",
    "href": "engagement_and_scoping.html#the-approvers-responsibilities-during-engagement-and-scoping",
    "title": "6  Engagement and scoping",
    "section": "6.5 The Approver’s responsibilities during engagement and scoping",
    "text": "6.5 The Approver’s responsibilities during engagement and scoping\nThe Approver should document the new project and ensure that required mechanisms are in place for the appropriate assurance to take place. For example, they should ensure that the analyst and assurer are aware of local assurance protocols.",
    "crumbs": [
      "<span class='chapter-number'>6</span>  <span class='chapter-title'>Engagement and scoping</span>"
    ]
  },
  {
    "objectID": "design.html",
    "href": "design.html",
    "title": "7  Design",
    "section": "",
    "text": "7.1 Introduction and summary\nThis chapter describes how the Analyst translates the scope for the analysis agreed with the Commissioner into the Design, an actionable plan of work. It sets out recommended practices for documenting the Design as an Analytical Plan, making changes to the plan and keeping an audit trail of those changes, testing for reproducibility and uncertainty, and agreeing this with the Approver. An Analysis Steering Group can be an effective means for communications about the Design.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#introduction-and-summary",
    "href": "design.html#introduction-and-summary",
    "title": "7  Design",
    "section": "",
    "text": "7.1.1 The Commissioner’s responsibilities during design\nThe Commissioner reviews the Plan and agrees that what the Analyst is going to do will satisfy the Commissioner’s need.\n\n\n7.1.2 The Analyst’s responsibilities during design\nThe Analyst should develop the method and plan how to address the Commissioner’s needs, what the assurance requirements will be and plan for sufficient time for the assurance activity.\n\n\n7.1.3 The Assurer’s responsibilities during design\nThe Assurer should agree with Analyst and Commissioner what the assurance requirements will be and plan sufficient time for the assurance activity.\n\n\n7.1.4 The Approver’s responsibilities during design\nThe Approver should document the new project and ensure that required mechanisms are in place for the appropriate assurance to take place. For example, they should ensure that the Analyst and Assurer are aware of local assurance protocols.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#designing-the-analysis",
    "href": "design.html#designing-the-analysis",
    "title": "7  Design",
    "section": "7.2 Designing the analysis",
    "text": "7.2 Designing the analysis\nThe Analyst translates the scope for the analysis agreed with the Commissioner into an actionable plan of work. The Engagement and Scoping stage provides the Analyst with an understanding of the Commissioner’s requirements in terms of outputs to be delivered, including acceptable levels of accuracy, precision and margins of error. During the Design phase, the Analyst will translate the delivery of the agreed outputs into an Analytical Plan. The Analytical Plan should consider:\n\nMethodology for producing results, including the treatment of uncertainty;\nProject management approach (for example Agile, Waterfall or a combination of approaches);\nSourcing of inputs and assumptions;\nData and file management;\nChange management and version control;\nCode management, documentation and testing;\nCommunication between stakeholders;\nQuality assurance procedures during the project lifetime;\nDocumentation to be delivered;\nProcess for updating the Analytical Plan;\nEthics;\nReporting;\nDownstream application.\n\nDocumentation of the Analytical Plan should be proportionate to the Design. For larger or more complex projects, the Analyst might request assurance of the Analytical Plan.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#testing-the-methodology",
    "href": "design.html#testing-the-methodology",
    "title": "7  Design",
    "section": "7.3 Testing the methodology",
    "text": "7.3 Testing the methodology\nBest practice is to dry run with independent assurance of the proposed approach to see if the plan:\n\nDelivers as intended\nAdequately addresses the complexities of the customer issue for this purpose\nIs well-structured for the purpose, data driven, and reflects a robust overall design.\n\nIt is good practice to engage subject matter experts in this review, independent assurance, and to ensure the accuracy and limitations of the chosen methods are understood, ideally with tests baselining their response against independent reference cases.\nIf the analysis is written in code, this should include appropriate testing to ensure that the code works as intended to deliver expected outcomes. Following recommended good practices for code development is the best way to ensure that code is fit for purpose.\nOn completion of the Design phase, the Assurer should be aware of the quality assurance tasks that will be required of them during the project lifetime and have assured the necessary elements of the Analytical plan.\nIteration between the Commissioner and the Analyst is normal and expected whilst the analytical design develops. Considering analytical quality assurance and the acceptable margin of error for the Commissioner is essential to define how good is good enough.\nAgreeing the extent of the importance of the analysis output to decision making will set the level of materiality (see also Definitions and Key Concepts), which will indicate what would be proportionate assurance.\nThe Commissioner remains important through the analysis cycle, since they may well have greater expertise in the subject than the Analyst. Their contribution towards the input assumptions, data requirements and the most effective ways to present the outputs can prove invaluable.\nThe Analytical plan should be updated with formal version control to reflect revisions to the design including assurance activities.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#documenting-the-design-of-the-analysis",
    "href": "design.html#documenting-the-design-of-the-analysis",
    "title": "7  Design",
    "section": "7.4 Documenting the design of the analysis",
    "text": "7.4 Documenting the design of the analysis\nBest practice is to document the design process recording how the proposed analytical process generates the requested insights. This plan should be supported by the design documentation.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#analysing-uncertainty",
    "href": "design.html#analysing-uncertainty",
    "title": "7  Design",
    "section": "7.5 Analysing uncertainty",
    "text": "7.5 Analysing uncertainty\nDuring the design phase, Analysts should examine the planned analysis systematically for possible sources and types of uncertainty, to maximise the chance of identifying all that are sufficiently large to breach the acceptable margin of error.\nAnalysts should make sure that they report identified sources of uncertainty appropriately and proportionately to enable an assessment of whether results are within the Commissioner’s acceptable margin of error.\nThe Uncertainty Toolkit for Analysts provides advice on the treatment of uncertainty. Other authorities provide guidance for specific purposes, such as the Office for Statistics Regulation’s Approaches to presenting uncertainty in the statistical system.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#reproducible-analytical-pipelines",
    "href": "design.html#reproducible-analytical-pipelines",
    "title": "7  Design",
    "section": "7.6 Reproducible analytical pipelines",
    "text": "7.6 Reproducible analytical pipelines\nThe recommended approach for developing analysis in code is to use a Reproducible Analytical Pipeline (RAP). Reproducible Analytical Pipelines shall:\n\nFollow the practices set out in the Analysis Function Quality Assurance of Code for Analysis and Research manual.\nMeet the requirements of the Reproducible Analytical Pipelines minimum viable product.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "design.html#artificial-intelligence-and-machine-learning",
    "href": "design.html#artificial-intelligence-and-machine-learning",
    "title": "7  Design",
    "section": "7.7 Artificial intelligence and machine learning",
    "text": "7.7 Artificial intelligence and machine learning\nArtificial Intelligence (AI) and some classes of Machine Learning (ML) methods have opaque algorithms processing their inputs. These belong to a class of models known as “black boxes” - devices, systems, or objects which produce useful information without revealing any information about their internal workings.\nUsing a black box model places greater weight on the design of the analysis and the assurance and validation of outputs by domain experts, particularly Assurers, Approvers and Commissioners. Validate AI offers resources.",
    "crumbs": [
      "<span class='chapter-number'>7</span>  <span class='chapter-title'>Design</span>"
    ]
  },
  {
    "objectID": "analysis.html",
    "href": "analysis.html",
    "title": "8  Analysis",
    "section": "",
    "text": "8.1 Introduction\nThe analysis phase is where planned analysis is undertaken, and progress and relevance are monitored. During work, the design and plan may be amended to account for changing circumstances, emerging information or unexpected difficulties or limitations encountered, and this phase also includes maintaining appropriate records of the analysis conducted, changes, decisions and assumptions made. In some cases, changes or limitations encountered may necessitate a return to either the design or scoping phase.\nThroughout this phase, traceable documentation of the assurance activities undertaken shall also be produced.\nIn larger analytical projects, some outputs of the analysis may be completed at different times as work progresses, and aspects of other phases may therefore take place concurrently.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#the-analysts-responsibilities-during-the-analysis-phase",
    "href": "analysis.html#the-analysts-responsibilities-during-the-analysis-phase",
    "title": "8  Analysis",
    "section": "8.2 The Analyst’s responsibilities during the analysis phase",
    "text": "8.2 The Analyst’s responsibilities during the analysis phase\nAs the analyst manages their analysis and follows their analytical plan, they must provide documentation of the data and methods used to the assurers. The analyst shall ensure these are sufficient for the assurer to understand the approach.\nWhen the analysts are following the analytical plan, they must record any changes to their plan if they encounter difficulties or unexpected limitations. The analyst will also carry out the assurance plan and shall provide traceable documentation of the assurance they have undertaken. They shall act on any findings from the assurer. Analysts shall maintain regular and agreed contact with the commissioner, for example through regular update reports on large projects. This provides an opportunity for the commissioner to advise on whether the analysis is still meeting their needs or whether there are any new requirements.\nWhen conducting the analysis, it is important that it is transparent that the Analytical Plan has been followed and, any changes have been recorded. The analyst shall inform the commissioner and approver of such changes. The commissioner and approver can then comment on whether the analysis is still meeting the needs of the commission. Best practice includes:\n\nMaintaining a record of the work in a report;\nLogging the data, assumptions and inputs used in the analysis. The log should detail the source, ownership and a fitness-for-purpose risk assessment;\nRecording the verification and validation that has been undertaken, documenting any activities that are outstanding and noting what remedial action has been taken and its impact on the analysis.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#the-assurers-responsibilities-during-the-analysis-phase",
    "href": "analysis.html#the-assurers-responsibilities-during-the-analysis-phase",
    "title": "8  Analysis",
    "section": "8.3 The Assurer’s responsibilities during the analysis phase",
    "text": "8.3 The Assurer’s responsibilities during the analysis phase\nThe analytical assurer shall review the assurance completed by the analyst, carry out any further validation and verification they may see as appropriate, and report errors and areas for improvement to the analyst. The assurer may then need to re-review the assurance completed, as required.\nThe assurer shall also confirm the work has been appropriately scoped, executed, validated, and verified and documented to the approver.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#the-commissioners-responsibilities-during-the-analysis-phase",
    "href": "analysis.html#the-commissioners-responsibilities-during-the-analysis-phase",
    "title": "8  Analysis",
    "section": "8.4 The Commissioner’s responsibilities during the analysis phase",
    "text": "8.4 The Commissioner’s responsibilities during the analysis phase\nThe commissioner’s role is to review the analysis and assurance as fit for the purposes of the commission.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#the-approvers-responsibilities-during-the-analysis-phase",
    "href": "analysis.html#the-approvers-responsibilities-during-the-analysis-phase",
    "title": "8  Analysis",
    "section": "8.5 The Approver’s responsibilities during the analysis phase",
    "text": "8.5 The Approver’s responsibilities during the analysis phase\nThe Approver scrutinises the work of the analyst and assurer and shall be confident that the analysis:\n\nMeets its design requirements;\nIs of sufficient quality and\nIs adequately documented.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#uncertainty",
    "href": "analysis.html#uncertainty",
    "title": "8  Analysis",
    "section": "8.6 Uncertainty",
    "text": "8.6 Uncertainty\nIt is not sufficient to identify and describe risks and uncertainties. It is essential also to assess their impact on the outcome of the analysis and their contribution to the range and likelihoods of possible outcomes. Guidance on how to identify, mitigate, measure and communicate uncertainty can be found in the Uncertainty Toolkit for Analysts.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "analysis.html#limitations-of-data",
    "href": "analysis.html#limitations-of-data",
    "title": "8  Analysis",
    "section": "8.7 Limitations of data",
    "text": "8.7 Limitations of data\nIt is important to consider how well available data meet the needs of the analysis. It is rare to have the perfect dataset for an analytical commission. Reasons for this include:\n\nThe data is not available in the time frame required for the ideal analysis;\n\nThe data definition does not perfectly align with the commission;\n\nThere are data or coverage gaps;\n\nThe data may be experimental or there are other reasons why it is not ‘mature’.\n\nOften, no data are available that are directly and precisely relevant to the parameter and conditions of interest. In such cases, it is often possible to use surrogate data. These are measurements of another parameter, or of the parameter of interest under different conditions, that are related to the parameter and conditions of interest. This implies an extrapolation between parameters, or between conditions for the same parameter, which introduces further uncertainty, additional to that associated with the data themselves. It may be possible to quantify this additional uncertainty using expert knowledge of the relationship between the surrogate and the parameter of interest.\nThe impact of using a proxy dataset should be explored and, if the uncertainty associated with the dataset has a large impact on the analysis, its appropriateness should be revisited. This exploration, and the decision to use a particular dataset or input, should be recorded for the benefit of the analytical assurer.",
    "crumbs": [
      "<span class='chapter-number'>8</span>  <span class='chapter-title'>Analysis</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html",
    "href": "delivery_and_communication.html",
    "title": "9  Delivery and communication",
    "section": "",
    "text": "9.1 Introduction\nThe successful delivery of analysis to its Commissioner marks its transition from being a product under development to one that is fit and ready to be used to inform decision making in your organisation and possibly inform the public.\nThis chapter gives the Analyst, the Commissioner of analysis and other interested groups advice and information on how best to advise on the assurance and communicate analysis.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery and communication</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#delivering-the-analysis",
    "href": "delivery_and_communication.html#delivering-the-analysis",
    "title": "9  Delivery and communication",
    "section": "9.2 Delivering the analysis",
    "text": "9.2 Delivering the analysis\nWhen delivering a piece of analysis, the Analyst and Assurer should communicate its assurance state to the Approver and provide evidence that the analysis and associated outputs have undergone proportionate quality assurance and there is adequate evidence to demonstrate that the analysis is ready for delivery, for example:\n\nThat the analysis has undergone appropriate analytical governance (sign offs);\n\nIt uses data and assumptions as agreed with the commissioner;\n\nIt meets the purpose of its commission;\n\nIt has been carried out correctly to its agreed specification;\n\nIt has a risk assessment and statement against the programme risk register;\n\nWhere appropriate the analysis is accompanied by a completed assurance statement.\n\nThough not strictly assurance, the analyst should also consider areas such as security ratings, retention policies, intellectual property, ethics and related concerns.\nWhen the Analyst and Assurer are satisfied that the analysis is ready to hand over to the Commissioner, they should also ensure that any associated documentation supporting the analysis is ready and has also undergone quality assurance. Supporting documentation could include:\n\nLogs of data, assumptions and decisisions including their source, ownership, reliability and any sensitivity analysis carried out;\n\nAdvice on uncertainty and its impact on the outputs of the analysis;\n\nA description of the limits of the analysis and what it can and cannot be used for;\n\nAny materials for presenting the analysis to the Commissioner, for example slide decks or reports;\n\nA record of the analysis including methods used, dependencies, process maps, change and version control logs and error reporting;\n\nWhen appropriate, make the code base available to the Commissioner or more widely;\n\nThe test plan and results of the tests made against that plan;\n\nA statement of assurance;\n\nAny ethical concerns that have been addressed, especially for the application of Artificial Intelligence and machine learning algorithms;\n\nWhere applicable ensuring that the analysis meets the accessibility requirements for public bodies and / or\nWhere applicable the code of practice for publications has been followed.\n\nSome groups find it helpful to communicate the assurance state to the commissioner in a formal assurance statement covering these points. Here is an example of an assurance statement.\nThe exact nature of the approval process may vary depending on:\n\nThe impact of the analysis;\n\nThe approval process of the organisation, and\n\nThe nature of the programme, project or board approving the analysis.\n\nFor example, as well as delivering the required materials the analyst may also need to produce a summary slide pack for delivery at a project / programme board and be prepared to respond to challenge from the commissioner / board. The approver should provide sufficient challenge to the analysts to gain assurance that the analysis is fit for purpose.\nOn delivery, the Approver should scrutinise the evidence delivered with the analysis to undertake a formal review of the analysis and approve it if the analysis meets the agreed criteria. The Approver should then feedback the outcome of any approval activities to the analyst so that the analysis can be updated if required. The Approver should also provide the analyst with evidence that the analysis outputs have been properly reviewed and formally approved. For example, through the notes of a project / programme board where the decision to approve the analysis was made or similar.\nThe exact nature of any scrutiny made by the Approver should be proportionate to the impact of the analysis, the governance process of their programme / organisation and follow the principles of proportionality described in section Chapter 3 of this document. The analyst / lead analyst, Approver and Commissioner should liaise regularly through the development of the analysis to help mutual understanding of the ask and progress of the analysis to help ensure successful assurance of the analysis at delivery.\nTo ensure that the analysis is used as intended, the Commissioner should use the analysis as specified at the start of the analytical cycle, applying any limitations to its use as described by the Analyst.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery and communication</span>"
    ]
  },
  {
    "objectID": "delivery_and_communication.html#communicating-the-analysis",
    "href": "delivery_and_communication.html#communicating-the-analysis",
    "title": "9  Delivery and communication",
    "section": "9.3 Communicating the analysis",
    "text": "9.3 Communicating the analysis\nThe effective and transparent communication of is essential to enable analysis to be adopted and trusted by its commissioners and onward users. Depending on its final use and likelihood of publication, any analysis may be communicated to a wide audience including:\n\nCommissioners and Approvers of the analysis;\n\nExternal scrutiny including the Public Accounts Committee, the National Audit Office, internal and external audit;\n\nThe public, through publications and Freedom of Information Act requests;\n\nAcademic experts, possibly through a departmental Areas of Research Interest document.\n\nGovernment has produced a range of guidance to support analysts in presenting and communicating their analysis. This includes:\n\nThe Office for Statistical Regulation’s Approaches to presenting uncertainty in the statistical system;\n\nThe Uncertainty Toolkit for Analysts;\n\nThe Government Analysis Function guidance note Communicating quality, uncertainty and change;\n\nEach provides valuable advice on how to estimate and present uncertainty when describing the limitations of use of a piece of analysis.\nThe Analysis Function’s Making Analytical Publications Accessible Toolkit gives guidance to help ensure that any that websites, tools, and technologies produced from analysis are designed and developed so that people with disabilities can use them. More specifically, people can: perceive, understand, navigate, and interact with the web.\nGovernment has also produced guidance to support commissioners and users of analysis. The Analysis Function’s Advice for policy professionals using statistics and analysis aims to help policy professionals to work effectively with analysts and analysis. It introduces some important statistical ideas and concepts to help policy professionals ask the right questions when working with statistical evidence.\nIf publishing the outcome of any analysis is required, the analyst should follow departmental and statutory guidance. The analyst must comply with the code of practice when they publish official statistics. Some examples are given below:\n\nIf you are publishing statistics you will need to follow your organisation’s guidance and the regulatory guidance for publishing official statistics and national statistics;\n\nIf you are publishing research, you shall follow your organisations guidance and the Government Social Research Publication protocol;\n\nIf you are publishing an evaluation, refer to any recommendations from the Evaluation Task Force;\n\nIf you are publishing information about business-critical models you should follow PLACEHOLDER.",
    "crumbs": [
      "<span class='chapter-number'>9</span>  <span class='chapter-title'>Delivery and communication</span>"
    ]
  },
  {
    "objectID": "additional_resources.html",
    "href": "additional_resources.html",
    "title": "10  Additional resources",
    "section": "",
    "text": "10.1 Written resources\nThe additional resources referred to within the AQuA Book are collated here for easy reference.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Additional resources</span>"
    ]
  },
  {
    "objectID": "additional_resources.html#written-resources",
    "href": "additional_resources.html#written-resources",
    "title": "10  Additional resources",
    "section": "",
    "text": "10.1.1 Guidance and advice for performing analysis\n\nUncertainty Toolkit for Analysts in Government;\n\nThe National Audit Office Framework to review models is relevant throughout. It provides a structured approach to review models which organisations can use to determine whether the modelling outputs they produce are reasonable, robust and have a minimal likelihood of errors being made;\n\nAdvice for policy professionals using statistics and analysis – Government Analysis Function (Chapter 9) This guidance aims to help policy professionals work effectively with statisticians and other analysts. It introduces some important statistical ideas and concepts to help policy professionals ask the right questions when working with statistical evidence.\n\nData Ethics Framework (Chapter 9). The Data Ethics Framework guides appropriate and responsible data use in government and the wider public sector. It helps public servants understand ethical considerations, address these within their projects, and encourages responsible innovation.\n\nGovernment Data Quality Framework (Chapter 4) The framework developed by Government to support and enable the production of sustainable high quality data.\n\nUrgent data quality assurance guidance (Chapter 4) This guidance covers the minimum steps you should do for urgent data work. It is intended as a last resort, it does not replace full and thorough quality assurance practices.\n\n\n\n10.1.2 Reproducible analytical pipelines\n\nQuality assurance of code for analysis and research (Chapters 2 and 7) sets out good practices for writing reproducible and well documented code for analytical workflows.\n\nReproducible Analytical Pipelines (Chapters 2 and 7) sets out what a Reproducible Analytical Pipeline is and points to resources for analysts who need to build them.\n\n\n\n10.1.3 Model quality assurance\n\nDepartment for Energy Security and Net Zero modelling tools and QA guidance provides resources to help quality assure new and existing models, including those developed by third parties;\n\nArtificial Intelligence Quality Assurance;\n\nCross government guidance on roles and responsibilities.\n\n\n\n10.1.4 Guidance and advice for communicating analysis\nThe Office for Statistical Regulation’s Approaches to presenting uncertainty in the statistical system;\n* The Uncertainty Toolkit for Analysts;\n* The Government Analysis Function guidance note Communicating quality, uncertainty and change;\nThe Analysis Function’s Making Analytical Publications Accessible Toolkit gives guidance to help ensure that any that websites, tools, and technologies produced from analysis are designed and developed so that people with disabilities can use them. More specifically, people can: perceive, understand, navigate, and interact with the web.\nIf you are publishing statistics you will need to follow your organisation’s guidance and the regulatory guidance for publishing official statistics and national statistics;\n* If you are publishing research, you shall follow your organisations guidance and the Government Social Research Publication protocol;\n* If you are publishing an evaluation, refer to any recommendations from the Evaluation Task Force;\n* If you are publishing information about business-critical models you should follow PLACEHOLDER.\n\n\n10.1.5 External sources of quality assurance\nThe Government Actuary’s Department (GAD) can provide expert quality assurance reviews of models across the public sector. GAD are a team of financial risk professionals and are experts in reviewing models on all modern platforms, including Excel, R, and Python. As a non-ministerial department, GAD can offer unique support from within government.",
    "crumbs": [
      "<span class='chapter-number'>10</span>  <span class='chapter-title'>Additional resources</span>"
    ]
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "11  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever.",
    "crumbs": [
      "<span class='chapter-number'>11</span>  <span class='chapter-title'>Summary</span>"
    ]
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Knuth, Donald E. 1984. “Literate Programming.” Comput.\nJ. 27 (2): 97–111. https://doi.org/10.1093/comjnl/27.2.97.",
    "crumbs": [
      "References"
    ]
  }
]