::: {.callout-important}
This version of the AQuA book is a preliminary ALPHA draft.  It is still in development, and we are still working to ensure that it meets user needs. 

The draft currently has no official status. It is a work in progress and is subject to further revision and reconfiguration (possibly substantial change) before it is finalised. 
:::

# Definitions and concepts

This chapter sets out definitions and concepts that are used throughout the rest of the book. 

## Analysis {.unnumbered}

Analysis is the collection, manipulation and interpretation of information and data for use in decision making. Analysis can vary widely between situations and many different types of analysis may be used to form the evidence base that supports the decision-making process.  

Examples of types of analysis that are frequently encountered in government are:  

*  actuarial  
*  data science 
*  economic 
*  financial  
*  geographical 
*  operational research 
*  scientific, technical and engineering research  
*  statistical  
*  social research  

## Assurance {.unnumbered}

Analytical assurance is the process and set of practices to ensure that the analysis is fit for purpose. 

## Assurance activities {.unnumbered}

Assurance activities are any actions carried out in order to validate and verify analysis. 

For example:   

* analyst testing    
* peer review  
* reconciliation of results to independent sources  

## Artificial Intelligence {.unnumbered}

Artificial intelligence (AI) attempts to simulate human intelligence using techniques and methods such as machine learning, natural language processing, and robotics. AI aims to perform tasks that typically require human intelligence, such as problem-solving, decision-making, and language understanding. Artificial Intelligence models are a subset of [black box models](#black_box_models)


## Black box models {.unnumbered}

Black box models internal workings are not visible or easily understood. These models take input and produce output without providing clarity about the process used to arrive at the output. [Artificial Intelligence](#Artificial Intelligence) models (including [Machine Learning](#Machine Learning)) are the most common type of black box models used today. Other forms of black box models may arise in future.  


## Business critical analysis {.unnumbered}

Business critical analysis is analysis which plays such a role in decision making that it influences significant financial and funding decisions, is necessary to the achievement of a Departmental business plan, or where an error could have a significant reputational, economic or legal implications. 

The first edition of the AQuA book described business critical models. This has been generalised to business critical analysis, as it is possible for analysis to be business critical without including a model. Some departments may continue to use the term business critical models (BCM). 

## Documentation {.unnumbered}

### Specification documentation {.unnumbered}

Specifications capture initial engagements with the commissioner. They describe the question, the context, and any boundaries of the analysis. This provides a definition of the scope and a mechanism for agreeing project constraints such as deadlines, available resources, and capturing what level of assurance is required by the commissioner.

### Design documentation {.unnumbered}

Design documents describe the analytical plan, including the methodology, inputs, and software. They also contain details of the planned [verification](#verification) and [validation](#validation) of the analysis. They provide a basis for the Analytical Assurer to verify whether the analysis meets the specified requirements. For more information on the design documentation, see the [Design](design.qmd) chapter.

### Assumptions log {.unnumbered}

A register of assumptions, whether provided by the Commissioner or derived by the analysis, that have been risk assessed and signed off by an appropriate governance group or stakeholder. Assumption logs should describe each assumption, quantify its effect and reliability and set out when it was made, why it was made, who made it and who signed it off.

### Decisions log {.unnumbered}

A register of decisions, whether provided by the Commissioner or derived by the analysis. Decisions logs should describe each decision and set out when it was made, why it was made, who made it and who signed it off.

### Data log {.unnumbered}

A register of data provided by the Commissioner or derived by the analysis that has been risked assessed and signed-off by an appropriate governance group or stakeholder.  


### User / technical documentation {.unnumbered}

All analysis shall have user-documentation, even if the user is only the analyst leading the analysis. This is to ensure that they have captured sufficient material to assist them if the analysis is revisited in due course. For analysis that is likely to be revisited or updated in the future, documentation should be provided to assist a future analyst and should be more comprehensive. This documentation should include a summary of the analysis including the context to the question being asked, what analytical methods were considered, what analysis was planned and why, what challenges were encountered and how they were overcome and what verification and validation steps were performed. In addition, guidance on what should be considered if the analysis is to be revisited or updated is beneficial.  For modelling, the Analyst may include a model map that describes data flows and transformations.

### Assurance statement {.unnumbered}

A brief description of the analytical assurance that have been performed to assure the analysis. The statement should refer to known limitations and conditions associated with the analysis.

::: {.callout-tip}
# Example of publishing quality assurance tools
The Department for Energy Security and Net Zero and Department for Business and Trade have published a range of quality assurance tools and guidance to help people with Quality Assurance of analytical models. [Modelling Quality Assurance tools and guidance](https://www.gov.uk/government/publications/energy-security-and-net-zero-modelling-quality-assurance-qa-tools-and-guidance) are used across the two departments to ensure analysis meets the standards set out in the AQuA book and provide assurance to users of the analysis that proportionate quality assurance has been completed. 

:::

## Multi-use models {.unnumbered}

Some models, often complex and large, are used by more than one user or group of users for related but differing purposes, these are known as **multi-use models**.  

Often, a Steering Group is created to oversee the analysis. This Steering Group would be chaired by the senior officer in charge of the area that maintains the model, and contain senior, ideally empowered, representatives of each major user area. 

## Quality analysis {.unnumbered}

Quality analysis is analysis which is fit for the purpose(s) it was commissioned to meet. It should be accurate, have undergone appropriate assurance, be evidenced, proportionate to its effect, adequately communicated, documented and accepted by its commissioners. 

## Roles and responsibilities {.unnumbered}

The AQuA book defines the following roles:

* **Commissioner**
* **Analyst**  
* **Assurer** 
* **Approver** 

See [Roles and Responsibilities](analytical_lifecycle.qmd/#roles_and_responsibilities) for details.

## Third party {.unnumbered}
Any individual, or group of individuals that is not a member of the same group as the those commissioning analysis. E.g. working for a different government department, a different function or an outside company.

## Uncertainty {.unnumbered}

Uncertainties are things that are not known, or are in a state of doubt, or are things whose effect is difficult to know. They have the potential to have major consequences for a project, programme, piece of analysis meeting its objectives.[^1]

[^1]: https://www.nao.org.uk/wp-content/uploads/2023/08/Good-practice-guide-Managing-uncertainty.pdf

There are different types of uncertainty. A common classification divides uncertainty into known knowns, known unknowns, and unknown unknowns. The type of uncertainty will influence the analytical approach and assurance activities required. 

The [Uncertainty Toolkit for Analysts in Government](https://analystsuncertaintytoolkit.github.io/UncertaintyWeb/index.html) is a tool produced by a cross government group to help assessing and communicating uncertainty.

## Validation <a name="def_validation"></a>{.unnumbered}

Ensuring the analysis meets the needs of its intended users and the intended use environment.  See @glover2014 for more information.

## Verification {.unnumbered}

Ensuring the analysis meets it specified design requirements. See @glover2014 for more information.

## Version control {.unnumbered}

It is important to ensure that changes that have been made to analysis can be easily seen and quality assured by the analytical assurer, and the latest version of the analysis is being used. Tools and templates can be used to support with evidencing updates and the checks completed throughout a project providing a log of changes that have occurred, why, when, and by whom. 

